{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/A/2j7pR/BeOiV5G5hD9n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yugonsan/pytorch_practice/blob/main/%E7%AC%AC7%E7%AB%A0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeOkl2GX_YRc",
        "outputId": "e2c36f30-4592-4c90-9f3b-abc0fd6d142c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed japanize_matplotlib-1.1.3\n",
            "Successfully installed torchviz-0.0.2\n",
            "Successfully installed torchinfo-1.7.1\n"
          ]
        }
      ],
      "source": [
        "# 必要ライブラリの導入\n",
        "\n",
        "!pip install japanize_matplotlib | tail -n 1\n",
        "!pip install torchviz | tail -n 1\n",
        "!pip install torchinfo | tail -n 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 必要ライブラリのインポート\n",
        "\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "id": "AvgAEELJCwgZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch関連ライブラリのインポート\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchinfo import summary\n",
        "from torchviz import make_dot"
      ],
      "metadata": {
        "id": "O1PyB0IsCyd0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# デフォルトフォントサイズ変更\n",
        "plt.rcParams['font.size'] = 14\n",
        "\n",
        "# デフォルトグラフサイズ変更\n",
        "plt.rcParams['figure.figsize'] = (6,6)\n",
        "\n",
        "# デフォルトで方眼表示ON\n",
        "plt.rcParams['axes.grid'] = True\n",
        "\n",
        "# numpyの表示桁数設定\n",
        "np.set_printoptions(suppress=True, precision=4)"
      ],
      "metadata": {
        "id": "WA-SAW5SC0mB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習用データ準備\n",
        "\n",
        "# ライブラリのインポート\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# データ読み込み\n",
        "iris = load_iris()\n",
        "\n",
        "# 入力データと正解データ取得\n",
        "x_org, y_org = iris.data, iris.target\n",
        "\n",
        "# 結果確認\n",
        "print('元データ', x_org.shape, y_org.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kChIDA4lC3x7",
        "outputId": "e412f13c-ff2e-42f3-ba61-43ea7659e22a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "元データ (150, 4) (150,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# データ絞り込み\n",
        "\n",
        "# 入力データに関しては、sepal length(0)とpetal length(2)のみ抽出\n",
        "x_select = x_org[:,[0,2]]\n",
        "\n",
        "# 結果確認\n",
        "print('元データ', x_select.shape, y_org.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkNbXG76C8TQ",
        "outputId": "6e8807ca-c0f9-4566-b4c6-3f42b4a762a5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "元データ (150, 2) (150,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 訓練データ、検証データに分割 (シャフルも同時に実施)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x_select, y_org, train_size=75, test_size=75, \n",
        "    random_state=123)\n",
        "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "in5n04YoC-T5",
        "outputId": "45357403-31e1-45cf-f3fc-83cf1d3452d5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(75, 2) (75, 2) (75,) (75,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# データを正解値ごとに分割\n",
        "\n",
        "x_t0 = x_train[y_train == 0]\n",
        "x_t1 = x_train[y_train == 1]\n",
        "x_t2 = x_train[y_train == 2]"
      ],
      "metadata": {
        "id": "RcnT7rRSDDtN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 散布図の表示\n",
        "\n",
        "plt.scatter(x_t0[:,0], x_t0[:,1], marker='x', c='k', s=50, label='0 (setosa)')\n",
        "plt.scatter(x_t1[:,0], x_t1[:,1], marker='o', c='b', s=50, label='1 (versicolour)')\n",
        "plt.scatter(x_t2[:,0], x_t2[:,1], marker='+', c='k', s=50, label='2 (virginica)')\n",
        "plt.xlabel('sepal_length')\n",
        "plt.ylabel('petal_length')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "eVhQd6cWDFpd",
        "outputId": "3c25ce1e-8031-40e0-de20-d4af6606f27f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習用パラメタ設定\n",
        "# 入力次元数\n",
        "n_input = x_train.shape[1]\n",
        "# 出力次元数\n",
        "# 分類クラス、今回は3になる\n",
        "n_output = len(list(set(y_train)))\n",
        "# 結果確認\n",
        "print(f'n_input: {n_input}  n_output: {n_output}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1RD4OQaHD9m",
        "outputId": "1ae26fb6-a7e5-4995-a65a-a689116d72ce"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_input: 2  n_output: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの定義\n",
        "# 入力2出力3のロジスティック回帰モデル\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, n_input, n_output):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.Linear(n_input, n_output)\n",
        "\n",
        "        # 初期値を全部1にする\n",
        "        self.l1.weight.data.fill_(1.0)\n",
        "        self.l1.bias.data.fill_(1.0)\n",
        "\n",
        "    # 活性化関数の部分がなくなり単純に線形関数の結果を返している\n",
        "    # 損失関数側でこの線形関数の結果を返している\n",
        "    def forward(self, x):\n",
        "        x1 = self.l1(x)\n",
        "        return x1\n",
        "#インスタンスの生成\n",
        "net = Net(n_input, n_output) "
      ],
      "metadata": {
        "id": "F1op7-vEH1xo"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# モデル内のパラメタ確認\n",
        "# l1.weightが行列に、l1.biasがベクトルになっている\n",
        "\n",
        "for parameter in net.named_parameters():\n",
        "    print(parameter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdJk6NiFKf8Y",
        "outputId": "310c9447-bb46-43ad-809a-176e53d327cc"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('l1.weight', Parameter containing:\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]], requires_grad=True))\n",
            "('l1.bias', Parameter containing:\n",
            "tensor([1., 1., 1.], requires_grad=True))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの概要表示\n",
        "\n",
        "print(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z144zsdoOWmR",
        "outputId": "e386e290-85cd-4aa9-c5da-6773713a2c6c"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (l1): Linear(in_features=2, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルのサマリー表示\n",
        "\n",
        "summary(net, (2,))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efv76RaXObPa",
        "outputId": "7212334d-37db-4722-c00a-6edfe872155b"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Net                                      [3]                       --\n",
              "├─Linear: 1-1                            [3]                       9\n",
              "==========================================================================================\n",
              "Total params: 9\n",
              "Trainable params: 9\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 0.00\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.00\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.00\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 損失関数： 交差エントロピー関数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 学習率\n",
        "lr = 0.01\n",
        "\n",
        "# 最適化関数: 勾配降下法\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "dRW_cKKgLlug"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 入力変数x_trainと正解値 y_trainのテンソル変数化\n",
        "\n",
        "inputs = torch.tensor(x_train).float()\n",
        "labels = torch.tensor(y_train).long()\n",
        "\n",
        "# 検証用変数のテンソル変数化\n",
        "\n",
        "inputs_test = torch.tensor(x_test).float()\n",
        "labels_test = torch.tensor(y_test).long()"
      ],
      "metadata": {
        "id": "inWDC2fYM66H"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 予測計算\n",
        "print(inputs)\n",
        "outputs = net(inputs)\n",
        "print(labels)\n",
        "print(outputs)\n",
        "\n",
        "#  損失計算\n",
        "loss = criterion(outputs, labels)\n",
        "\n",
        "# 損失の計算グラフ可視化\n",
        "g = make_dot(loss, params=dict(net.named_parameters()))\n",
        "display(g)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jVPINlR9Oq6A",
        "outputId": "8dca5d6d-5b8c-4154-e217-cda118b49790"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[6.3000, 4.7000],\n",
            "        [7.0000, 4.7000],\n",
            "        [5.0000, 1.6000],\n",
            "        [6.4000, 5.6000],\n",
            "        [6.3000, 5.0000],\n",
            "        [5.0000, 1.6000],\n",
            "        [4.9000, 1.4000],\n",
            "        [6.1000, 4.0000],\n",
            "        [6.5000, 4.6000],\n",
            "        [6.3000, 6.0000],\n",
            "        [5.8000, 1.2000],\n",
            "        [4.6000, 1.4000],\n",
            "        [5.5000, 3.8000],\n",
            "        [5.0000, 1.6000],\n",
            "        [5.9000, 4.8000],\n",
            "        [6.9000, 5.4000],\n",
            "        [4.8000, 1.6000],\n",
            "        [6.7000, 5.8000],\n",
            "        [5.7000, 1.5000],\n",
            "        [5.7000, 1.7000],\n",
            "        [6.7000, 5.0000],\n",
            "        [4.6000, 1.0000],\n",
            "        [5.4000, 1.5000],\n",
            "        [6.6000, 4.6000],\n",
            "        [7.3000, 6.3000],\n",
            "        [6.6000, 4.4000],\n",
            "        [5.6000, 3.6000],\n",
            "        [5.6000, 3.9000],\n",
            "        [4.6000, 1.5000],\n",
            "        [5.0000, 1.3000],\n",
            "        [6.8000, 4.8000],\n",
            "        [6.1000, 5.6000],\n",
            "        [4.9000, 1.5000],\n",
            "        [5.2000, 1.5000],\n",
            "        [5.6000, 4.2000],\n",
            "        [6.0000, 4.5000],\n",
            "        [6.2000, 4.3000],\n",
            "        [7.1000, 5.9000],\n",
            "        [6.9000, 4.9000],\n",
            "        [5.8000, 4.0000],\n",
            "        [5.7000, 4.1000],\n",
            "        [7.6000, 6.6000],\n",
            "        [5.0000, 1.5000],\n",
            "        [5.3000, 1.5000],\n",
            "        [5.9000, 4.2000],\n",
            "        [6.9000, 5.7000],\n",
            "        [6.4000, 5.5000],\n",
            "        [7.2000, 6.0000],\n",
            "        [6.5000, 5.2000],\n",
            "        [5.1000, 1.5000],\n",
            "        [5.4000, 4.5000],\n",
            "        [4.7000, 1.3000],\n",
            "        [5.8000, 4.1000],\n",
            "        [5.7000, 4.5000],\n",
            "        [5.0000, 1.4000],\n",
            "        [6.2000, 4.5000],\n",
            "        [6.7000, 5.6000],\n",
            "        [6.0000, 4.5000],\n",
            "        [6.7000, 5.7000],\n",
            "        [6.4000, 5.3000],\n",
            "        [5.2000, 1.5000],\n",
            "        [6.1000, 4.7000],\n",
            "        [4.6000, 1.4000],\n",
            "        [6.2000, 5.4000],\n",
            "        [5.7000, 5.0000],\n",
            "        [5.7000, 4.2000],\n",
            "        [4.9000, 3.3000],\n",
            "        [6.3000, 4.9000],\n",
            "        [4.9000, 4.5000],\n",
            "        [6.0000, 5.1000],\n",
            "        [5.1000, 1.4000],\n",
            "        [5.1000, 3.0000],\n",
            "        [5.6000, 4.5000],\n",
            "        [6.2000, 4.8000],\n",
            "        [7.2000, 6.1000]])\n",
            "tensor([1, 1, 0, 2, 2, 0, 0, 1, 1, 2, 0, 0, 1, 0, 1, 2, 0, 2, 0, 0, 1, 0, 0, 1,\n",
            "        2, 1, 1, 1, 0, 0, 1, 2, 0, 0, 1, 1, 1, 2, 1, 1, 1, 2, 0, 0, 1, 2, 2, 2,\n",
            "        2, 0, 1, 0, 1, 1, 0, 1, 2, 1, 2, 2, 0, 1, 0, 2, 2, 1, 1, 2, 2, 1, 0, 1,\n",
            "        1, 2, 2])\n",
            "tensor([[12.0000, 12.0000, 12.0000],\n",
            "        [12.7000, 12.7000, 12.7000],\n",
            "        [ 7.6000,  7.6000,  7.6000],\n",
            "        [13.0000, 13.0000, 13.0000],\n",
            "        [12.3000, 12.3000, 12.3000],\n",
            "        [ 7.6000,  7.6000,  7.6000],\n",
            "        [ 7.3000,  7.3000,  7.3000],\n",
            "        [11.1000, 11.1000, 11.1000],\n",
            "        [12.1000, 12.1000, 12.1000],\n",
            "        [13.3000, 13.3000, 13.3000],\n",
            "        [ 8.0000,  8.0000,  8.0000],\n",
            "        [ 7.0000,  7.0000,  7.0000],\n",
            "        [10.3000, 10.3000, 10.3000],\n",
            "        [ 7.6000,  7.6000,  7.6000],\n",
            "        [11.7000, 11.7000, 11.7000],\n",
            "        [13.3000, 13.3000, 13.3000],\n",
            "        [ 7.4000,  7.4000,  7.4000],\n",
            "        [13.5000, 13.5000, 13.5000],\n",
            "        [ 8.2000,  8.2000,  8.2000],\n",
            "        [ 8.4000,  8.4000,  8.4000],\n",
            "        [12.7000, 12.7000, 12.7000],\n",
            "        [ 6.6000,  6.6000,  6.6000],\n",
            "        [ 7.9000,  7.9000,  7.9000],\n",
            "        [12.2000, 12.2000, 12.2000],\n",
            "        [14.6000, 14.6000, 14.6000],\n",
            "        [12.0000, 12.0000, 12.0000],\n",
            "        [10.2000, 10.2000, 10.2000],\n",
            "        [10.5000, 10.5000, 10.5000],\n",
            "        [ 7.1000,  7.1000,  7.1000],\n",
            "        [ 7.3000,  7.3000,  7.3000],\n",
            "        [12.6000, 12.6000, 12.6000],\n",
            "        [12.7000, 12.7000, 12.7000],\n",
            "        [ 7.4000,  7.4000,  7.4000],\n",
            "        [ 7.7000,  7.7000,  7.7000],\n",
            "        [10.8000, 10.8000, 10.8000],\n",
            "        [11.5000, 11.5000, 11.5000],\n",
            "        [11.5000, 11.5000, 11.5000],\n",
            "        [14.0000, 14.0000, 14.0000],\n",
            "        [12.8000, 12.8000, 12.8000],\n",
            "        [10.8000, 10.8000, 10.8000],\n",
            "        [10.8000, 10.8000, 10.8000],\n",
            "        [15.2000, 15.2000, 15.2000],\n",
            "        [ 7.5000,  7.5000,  7.5000],\n",
            "        [ 7.8000,  7.8000,  7.8000],\n",
            "        [11.1000, 11.1000, 11.1000],\n",
            "        [13.6000, 13.6000, 13.6000],\n",
            "        [12.9000, 12.9000, 12.9000],\n",
            "        [14.2000, 14.2000, 14.2000],\n",
            "        [12.7000, 12.7000, 12.7000],\n",
            "        [ 7.6000,  7.6000,  7.6000],\n",
            "        [10.9000, 10.9000, 10.9000],\n",
            "        [ 7.0000,  7.0000,  7.0000],\n",
            "        [10.9000, 10.9000, 10.9000],\n",
            "        [11.2000, 11.2000, 11.2000],\n",
            "        [ 7.4000,  7.4000,  7.4000],\n",
            "        [11.7000, 11.7000, 11.7000],\n",
            "        [13.3000, 13.3000, 13.3000],\n",
            "        [11.5000, 11.5000, 11.5000],\n",
            "        [13.4000, 13.4000, 13.4000],\n",
            "        [12.7000, 12.7000, 12.7000],\n",
            "        [ 7.7000,  7.7000,  7.7000],\n",
            "        [11.8000, 11.8000, 11.8000],\n",
            "        [ 7.0000,  7.0000,  7.0000],\n",
            "        [12.6000, 12.6000, 12.6000],\n",
            "        [11.7000, 11.7000, 11.7000],\n",
            "        [10.9000, 10.9000, 10.9000],\n",
            "        [ 9.2000,  9.2000,  9.2000],\n",
            "        [12.2000, 12.2000, 12.2000],\n",
            "        [10.4000, 10.4000, 10.4000],\n",
            "        [12.1000, 12.1000, 12.1000],\n",
            "        [ 7.5000,  7.5000,  7.5000],\n",
            "        [ 9.1000,  9.1000,  9.1000],\n",
            "        [11.1000, 11.1000, 11.1000],\n",
            "        [12.0000, 12.0000, 12.0000],\n",
            "        [14.3000, 14.3000, 14.3000]], grad_fn=<AddmmBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7fa8fb301e80>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"216pt\" height=\"391pt\"\n viewBox=\"0.00 0.00 216.00 391.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 387)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-387 212,-387 212,4 -4,4\"/>\n<!-- 140363742454704 -->\n<g id=\"node1\" class=\"node\">\n<title>140363742454704</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"130.5,-31 76.5,-31 76.5,0 130.5,0 130.5,-31\"/>\n<text text-anchor=\"middle\" x=\"103.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 140363745466496 -->\n<g id=\"node2\" class=\"node\">\n<title>140363745466496</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"160,-86 47,-86 47,-67 160,-67 160,-86\"/>\n<text text-anchor=\"middle\" x=\"103.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">NllLossBackward0</text>\n</g>\n<!-- 140363745466496&#45;&gt;140363742454704 -->\n<g id=\"edge8\" class=\"edge\">\n<title>140363745466496&#45;&gt;140363742454704</title>\n<path fill=\"none\" stroke=\"black\" d=\"M103.5,-66.79C103.5,-60.07 103.5,-50.4 103.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"107,-41.19 103.5,-31.19 100,-41.19 107,-41.19\"/>\n</g>\n<!-- 140363745467168 -->\n<g id=\"node3\" class=\"node\">\n<title>140363745467168</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"169,-141 38,-141 38,-122 169,-122 169,-141\"/>\n<text text-anchor=\"middle\" x=\"103.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">LogSoftmaxBackward0</text>\n</g>\n<!-- 140363745467168&#45;&gt;140363745466496 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140363745467168&#45;&gt;140363745466496</title>\n<path fill=\"none\" stroke=\"black\" d=\"M103.5,-121.75C103.5,-114.8 103.5,-104.85 103.5,-96.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"107,-96.09 103.5,-86.09 100,-96.09 107,-96.09\"/>\n</g>\n<!-- 140363745464864 -->\n<g id=\"node4\" class=\"node\">\n<title>140363745464864</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"154,-196 53,-196 53,-177 154,-177 154,-196\"/>\n<text text-anchor=\"middle\" x=\"103.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n</g>\n<!-- 140363745464864&#45;&gt;140363745467168 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140363745464864&#45;&gt;140363745467168</title>\n<path fill=\"none\" stroke=\"black\" d=\"M103.5,-176.75C103.5,-169.8 103.5,-159.85 103.5,-151.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"107,-151.09 103.5,-141.09 100,-151.09 107,-151.09\"/>\n</g>\n<!-- 140363745465632 -->\n<g id=\"node5\" class=\"node\">\n<title>140363745465632</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-251 0,-251 0,-232 101,-232 101,-251\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 140363745465632&#45;&gt;140363745464864 -->\n<g id=\"edge3\" class=\"edge\">\n<title>140363745465632&#45;&gt;140363745464864</title>\n<path fill=\"none\" stroke=\"black\" d=\"M59.25,-231.75C66.97,-224.03 78.4,-212.6 87.72,-203.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"90.31,-205.64 94.91,-196.09 85.36,-200.69 90.31,-205.64\"/>\n</g>\n<!-- 140363742338560 -->\n<g id=\"node6\" class=\"node\">\n<title>140363742338560</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"80,-317 21,-317 21,-287 80,-287 80,-317\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-305\" font-family=\"monospace\" font-size=\"10.00\">l1.bias</text>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\"> (3)</text>\n</g>\n<!-- 140363742338560&#45;&gt;140363745465632 -->\n<g id=\"edge4\" class=\"edge\">\n<title>140363742338560&#45;&gt;140363745465632</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-286.84C50.5,-279.21 50.5,-269.7 50.5,-261.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-261.27 50.5,-251.27 47,-261.27 54,-261.27\"/>\n</g>\n<!-- 140363745465824 -->\n<g id=\"node7\" class=\"node\">\n<title>140363745465824</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"196,-251 119,-251 119,-232 196,-232 196,-251\"/>\n<text text-anchor=\"middle\" x=\"157.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n</g>\n<!-- 140363745465824&#45;&gt;140363745464864 -->\n<g id=\"edge5\" class=\"edge\">\n<title>140363745465824&#45;&gt;140363745464864</title>\n<path fill=\"none\" stroke=\"black\" d=\"M148.58,-231.75C140.72,-224.03 129.07,-212.6 119.58,-203.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"121.84,-200.6 112.25,-196.09 116.94,-205.59 121.84,-200.6\"/>\n</g>\n<!-- 140363745466256 -->\n<g id=\"node8\" class=\"node\">\n<title>140363745466256</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"208,-311.5 107,-311.5 107,-292.5 208,-292.5 208,-311.5\"/>\n<text text-anchor=\"middle\" x=\"157.5\" y=\"-299.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 140363745466256&#45;&gt;140363745465824 -->\n<g id=\"edge6\" class=\"edge\">\n<title>140363745466256&#45;&gt;140363745465824</title>\n<path fill=\"none\" stroke=\"black\" d=\"M157.5,-292.37C157.5,-284.25 157.5,-271.81 157.5,-261.39\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"161,-261.17 157.5,-251.17 154,-261.17 161,-261.17\"/>\n</g>\n<!-- 140363742338800 -->\n<g id=\"node9\" class=\"node\">\n<title>140363742338800</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"193,-383 122,-383 122,-353 193,-353 193,-383\"/>\n<text text-anchor=\"middle\" x=\"157.5\" y=\"-371\" font-family=\"monospace\" font-size=\"10.00\">l1.weight</text>\n<text text-anchor=\"middle\" x=\"157.5\" y=\"-360\" font-family=\"monospace\" font-size=\"10.00\"> (3, 2)</text>\n</g>\n<!-- 140363742338800&#45;&gt;140363745466256 -->\n<g id=\"edge7\" class=\"edge\">\n<title>140363742338800&#45;&gt;140363745466256</title>\n<path fill=\"none\" stroke=\"black\" d=\"M157.5,-352.8C157.5,-343.7 157.5,-331.79 157.5,-321.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"161,-321.84 157.5,-311.84 154,-321.84 161,-321.84\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.max関数呼び出し\n",
        "# 2つめの引数は軸を意味している。1だと行ごとの集計。\n",
        "print(torch.max(outputs, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4ZSJRq_PHKG",
        "outputId": "11c277c7-730c-4f28-8a76-8da7e3969c60"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.return_types.max(\n",
            "values=tensor([19.3516, 20.3705, 17.1432, 22.8695, 20.2321, 18.5511, 17.3232, 17.8635,\n",
            "        19.0201, 25.2665, 22.4940, 17.9557, 16.3036, 18.3109, 18.6709, 21.4751,\n",
            "        17.0725, 22.8369, 22.9168, 20.7264, 19.9045, 19.3484, 20.2519, 19.3188,\n",
            "        24.0230, 19.2352, 16.8196, 16.6673, 16.8777, 19.2095, 19.6914, 20.8235,\n",
            "        17.4474, 19.2538, 17.1437, 18.8075, 18.4111, 23.4675, 20.2692, 17.1755,\n",
            "        17.3235, 25.9793, 18.5648, 20.0620, 17.9321, 23.2272, 21.0638, 22.5230,\n",
            "        20.6556, 18.7547, 17.4180, 17.7467, 17.4081, 17.6913, 18.4406, 17.7716,\n",
            "        23.4008, 18.2521, 23.8959, 21.1174, 21.1432, 18.5205, 17.3718, 22.1374,\n",
            "        20.8673, 17.5293, 14.9095, 19.2452, 18.2414, 19.4791, 19.2144, 15.0499,\n",
            "        17.7340, 18.7771, 24.8598], grad_fn=<MaxBackward0>),\n",
            "indices=tensor([1, 1, 0, 2, 2, 0, 0, 1, 1, 2, 0, 0, 1, 0, 1, 2, 0, 2, 0, 0, 1, 0, 0, 1,\n",
            "        2, 1, 1, 1, 0, 0, 1, 2, 0, 0, 1, 1, 1, 2, 1, 1, 1, 2, 0, 0, 1, 2, 2, 2,\n",
            "        2, 0, 1, 0, 1, 1, 0, 1, 2, 1, 2, 2, 0, 1, 0, 2, 2, 1, 1, 2, 2, 2, 0, 1,\n",
            "        1, 2, 2]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ラベル値の配列を取得\n",
        "torch.max(outputs, 1)[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqZBvYBSR704",
        "outputId": "44cb93f0-fa8c-450d-ae36-169be0852d65"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 0, 2, 2, 0, 0, 1, 1, 2, 0, 0, 1, 0, 1, 2, 0, 2, 0, 0, 1, 0, 0, 1,\n",
              "        2, 1, 1, 1, 0, 0, 1, 2, 0, 0, 1, 1, 1, 2, 1, 1, 1, 2, 0, 0, 1, 2, 2, 2,\n",
              "        2, 0, 1, 0, 1, 1, 0, 1, 2, 1, 2, 2, 0, 1, 0, 2, 2, 1, 1, 2, 2, 2, 0, 1,\n",
              "        1, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習率\n",
        "lr = 0.01\n",
        "\n",
        "# 初期化\n",
        "net = Net(n_input, n_output)\n",
        "\n",
        "# 損失関数： 交差エントロピー関数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 最適化関数: 勾配降下法\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
        "\n",
        "# 繰り返し回数\n",
        "num_epochs = 10000\n",
        "\n",
        "# 評価結果記録用\n",
        "history = np.zeros((0,5))"
      ],
      "metadata": {
        "id": "3lYr8b5eSYCs"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 繰り返し計算メインループ\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # 訓練フェーズ\n",
        "    \n",
        "    #勾配の初期化\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 予測計算\n",
        "    outputs = net(inputs)\n",
        "\n",
        "    # 損失計算\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # 勾配計算\n",
        "    loss.backward()\n",
        "    \n",
        "    # パラメータ修正\n",
        "    optimizer.step()\n",
        "\n",
        "    # 予測ラベル算出\n",
        "    predicted = torch.max(outputs, 1)[1]\n",
        "\n",
        "    # 損失と精度の計算\n",
        "    train_loss = loss.item()\n",
        "    train_acc = (predicted == labels).sum()  / len(labels)\n",
        "\n",
        "    #予測フェーズ\n",
        "\n",
        "    # 予測計算\n",
        "    outputs_test = net(inputs_test)\n",
        "\n",
        "    # 損失計算\n",
        "    loss_test = criterion(outputs_test, labels_test)\n",
        "\n",
        "    # 予測ラベル算出\n",
        "    predicted_test = torch.max(outputs_test, 1)[1]\n",
        "\n",
        "    # 損失と精度の計算\n",
        "    val_loss =  loss_test.item()\n",
        "    val_acc =  (predicted_test == labels_test).sum() / len(labels_test)\n",
        "    \n",
        "    if ((epoch) % 10 == 0):\n",
        "        print (f'Epoch [{epoch}/{num_epochs}], loss: {train_loss:.5f} acc: {train_acc:.5f} val_loss: {val_loss:.5f}, val_acc: {val_acc:.5f}')\n",
        "        item = np.array([epoch, train_loss, train_acc, val_loss, val_acc])\n",
        "        history = np.vstack((history, item))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQ3sKhgnTYX6",
        "outputId": "7b22017d-ad25-4d1d-93a4-08149518ecf5"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/10000], loss: 1.09861 acc: 0.30667 val_loss: 1.09158, val_acc: 0.26667\n",
            "Epoch [10/10000], loss: 1.01848 acc: 0.40000 val_loss: 1.04171, val_acc: 0.26667\n",
            "Epoch [20/10000], loss: 0.96854 acc: 0.40000 val_loss: 0.98850, val_acc: 0.26667\n",
            "Epoch [30/10000], loss: 0.92459 acc: 0.65333 val_loss: 0.93996, val_acc: 0.57333\n",
            "Epoch [40/10000], loss: 0.88568 acc: 0.70667 val_loss: 0.89704, val_acc: 0.62667\n",
            "Epoch [50/10000], loss: 0.85120 acc: 0.70667 val_loss: 0.85918, val_acc: 0.62667\n",
            "Epoch [60/10000], loss: 0.82059 acc: 0.70667 val_loss: 0.82572, val_acc: 0.62667\n",
            "Epoch [70/10000], loss: 0.79335 acc: 0.72000 val_loss: 0.79607, val_acc: 0.62667\n",
            "Epoch [80/10000], loss: 0.76900 acc: 0.72000 val_loss: 0.76968, val_acc: 0.65333\n",
            "Epoch [90/10000], loss: 0.74717 acc: 0.72000 val_loss: 0.74610, val_acc: 0.65333\n",
            "Epoch [100/10000], loss: 0.72750 acc: 0.76000 val_loss: 0.72494, val_acc: 0.69333\n",
            "Epoch [110/10000], loss: 0.70970 acc: 0.77333 val_loss: 0.70585, val_acc: 0.74667\n",
            "Epoch [120/10000], loss: 0.69354 acc: 0.81333 val_loss: 0.68856, val_acc: 0.76000\n",
            "Epoch [130/10000], loss: 0.67878 acc: 0.84000 val_loss: 0.67283, val_acc: 0.76000\n",
            "Epoch [140/10000], loss: 0.66526 acc: 0.84000 val_loss: 0.65846, val_acc: 0.78667\n",
            "Epoch [150/10000], loss: 0.65283 acc: 0.86667 val_loss: 0.64528, val_acc: 0.78667\n",
            "Epoch [160/10000], loss: 0.64135 acc: 0.88000 val_loss: 0.63313, val_acc: 0.78667\n",
            "Epoch [170/10000], loss: 0.63070 acc: 0.89333 val_loss: 0.62190, val_acc: 0.81333\n",
            "Epoch [180/10000], loss: 0.62081 acc: 0.90667 val_loss: 0.61149, val_acc: 0.81333\n",
            "Epoch [190/10000], loss: 0.61157 acc: 0.90667 val_loss: 0.60179, val_acc: 0.84000\n",
            "Epoch [200/10000], loss: 0.60292 acc: 0.90667 val_loss: 0.59273, val_acc: 0.84000\n",
            "Epoch [210/10000], loss: 0.59481 acc: 0.90667 val_loss: 0.58425, val_acc: 0.88000\n",
            "Epoch [220/10000], loss: 0.58717 acc: 0.93333 val_loss: 0.57628, val_acc: 0.88000\n",
            "Epoch [230/10000], loss: 0.57996 acc: 0.93333 val_loss: 0.56877, val_acc: 0.89333\n",
            "Epoch [240/10000], loss: 0.57313 acc: 0.93333 val_loss: 0.56169, val_acc: 0.90667\n",
            "Epoch [250/10000], loss: 0.56666 acc: 0.93333 val_loss: 0.55498, val_acc: 0.90667\n",
            "Epoch [260/10000], loss: 0.56051 acc: 0.92000 val_loss: 0.54862, val_acc: 0.90667\n",
            "Epoch [270/10000], loss: 0.55465 acc: 0.92000 val_loss: 0.54257, val_acc: 0.90667\n",
            "Epoch [280/10000], loss: 0.54906 acc: 0.92000 val_loss: 0.53681, val_acc: 0.90667\n",
            "Epoch [290/10000], loss: 0.54371 acc: 0.92000 val_loss: 0.53131, val_acc: 0.90667\n",
            "Epoch [300/10000], loss: 0.53859 acc: 0.93333 val_loss: 0.52605, val_acc: 0.90667\n",
            "Epoch [310/10000], loss: 0.53368 acc: 0.93333 val_loss: 0.52102, val_acc: 0.90667\n",
            "Epoch [320/10000], loss: 0.52896 acc: 0.93333 val_loss: 0.51619, val_acc: 0.90667\n",
            "Epoch [330/10000], loss: 0.52442 acc: 0.93333 val_loss: 0.51155, val_acc: 0.90667\n",
            "Epoch [340/10000], loss: 0.52004 acc: 0.93333 val_loss: 0.50709, val_acc: 0.90667\n",
            "Epoch [350/10000], loss: 0.51582 acc: 0.93333 val_loss: 0.50280, val_acc: 0.90667\n",
            "Epoch [360/10000], loss: 0.51173 acc: 0.93333 val_loss: 0.49865, val_acc: 0.90667\n",
            "Epoch [370/10000], loss: 0.50779 acc: 0.93333 val_loss: 0.49465, val_acc: 0.90667\n",
            "Epoch [380/10000], loss: 0.50397 acc: 0.93333 val_loss: 0.49078, val_acc: 0.90667\n",
            "Epoch [390/10000], loss: 0.50026 acc: 0.93333 val_loss: 0.48703, val_acc: 0.90667\n",
            "Epoch [400/10000], loss: 0.49666 acc: 0.94667 val_loss: 0.48340, val_acc: 0.90667\n",
            "Epoch [410/10000], loss: 0.49317 acc: 0.94667 val_loss: 0.47988, val_acc: 0.90667\n",
            "Epoch [420/10000], loss: 0.48978 acc: 0.94667 val_loss: 0.47647, val_acc: 0.90667\n",
            "Epoch [430/10000], loss: 0.48647 acc: 0.96000 val_loss: 0.47315, val_acc: 0.90667\n",
            "Epoch [440/10000], loss: 0.48326 acc: 0.96000 val_loss: 0.46992, val_acc: 0.90667\n",
            "Epoch [450/10000], loss: 0.48012 acc: 0.96000 val_loss: 0.46678, val_acc: 0.90667\n",
            "Epoch [460/10000], loss: 0.47706 acc: 0.96000 val_loss: 0.46372, val_acc: 0.90667\n",
            "Epoch [470/10000], loss: 0.47408 acc: 0.96000 val_loss: 0.46073, val_acc: 0.90667\n",
            "Epoch [480/10000], loss: 0.47116 acc: 0.96000 val_loss: 0.45783, val_acc: 0.90667\n",
            "Epoch [490/10000], loss: 0.46831 acc: 0.96000 val_loss: 0.45499, val_acc: 0.90667\n",
            "Epoch [500/10000], loss: 0.46553 acc: 0.96000 val_loss: 0.45221, val_acc: 0.90667\n",
            "Epoch [510/10000], loss: 0.46280 acc: 0.96000 val_loss: 0.44951, val_acc: 0.90667\n",
            "Epoch [520/10000], loss: 0.46013 acc: 0.96000 val_loss: 0.44686, val_acc: 0.90667\n",
            "Epoch [530/10000], loss: 0.45752 acc: 0.96000 val_loss: 0.44426, val_acc: 0.90667\n",
            "Epoch [540/10000], loss: 0.45496 acc: 0.96000 val_loss: 0.44173, val_acc: 0.90667\n",
            "Epoch [550/10000], loss: 0.45245 acc: 0.96000 val_loss: 0.43924, val_acc: 0.90667\n",
            "Epoch [560/10000], loss: 0.44998 acc: 0.96000 val_loss: 0.43681, val_acc: 0.90667\n",
            "Epoch [570/10000], loss: 0.44757 acc: 0.96000 val_loss: 0.43442, val_acc: 0.90667\n",
            "Epoch [580/10000], loss: 0.44519 acc: 0.96000 val_loss: 0.43208, val_acc: 0.90667\n",
            "Epoch [590/10000], loss: 0.44286 acc: 0.96000 val_loss: 0.42979, val_acc: 0.92000\n",
            "Epoch [600/10000], loss: 0.44057 acc: 0.96000 val_loss: 0.42753, val_acc: 0.92000\n",
            "Epoch [610/10000], loss: 0.43832 acc: 0.96000 val_loss: 0.42532, val_acc: 0.92000\n",
            "Epoch [620/10000], loss: 0.43611 acc: 0.96000 val_loss: 0.42315, val_acc: 0.92000\n",
            "Epoch [630/10000], loss: 0.43393 acc: 0.96000 val_loss: 0.42101, val_acc: 0.92000\n",
            "Epoch [640/10000], loss: 0.43179 acc: 0.96000 val_loss: 0.41891, val_acc: 0.92000\n",
            "Epoch [650/10000], loss: 0.42968 acc: 0.96000 val_loss: 0.41685, val_acc: 0.92000\n",
            "Epoch [660/10000], loss: 0.42761 acc: 0.96000 val_loss: 0.41482, val_acc: 0.92000\n",
            "Epoch [670/10000], loss: 0.42556 acc: 0.96000 val_loss: 0.41282, val_acc: 0.92000\n",
            "Epoch [680/10000], loss: 0.42355 acc: 0.96000 val_loss: 0.41085, val_acc: 0.92000\n",
            "Epoch [690/10000], loss: 0.42157 acc: 0.96000 val_loss: 0.40892, val_acc: 0.92000\n",
            "Epoch [700/10000], loss: 0.41961 acc: 0.96000 val_loss: 0.40701, val_acc: 0.92000\n",
            "Epoch [710/10000], loss: 0.41768 acc: 0.96000 val_loss: 0.40513, val_acc: 0.92000\n",
            "Epoch [720/10000], loss: 0.41578 acc: 0.96000 val_loss: 0.40329, val_acc: 0.92000\n",
            "Epoch [730/10000], loss: 0.41391 acc: 0.96000 val_loss: 0.40146, val_acc: 0.92000\n",
            "Epoch [740/10000], loss: 0.41206 acc: 0.96000 val_loss: 0.39967, val_acc: 0.92000\n",
            "Epoch [750/10000], loss: 0.41024 acc: 0.96000 val_loss: 0.39789, val_acc: 0.92000\n",
            "Epoch [760/10000], loss: 0.40844 acc: 0.96000 val_loss: 0.39615, val_acc: 0.92000\n",
            "Epoch [770/10000], loss: 0.40666 acc: 0.96000 val_loss: 0.39443, val_acc: 0.93333\n",
            "Epoch [780/10000], loss: 0.40491 acc: 0.96000 val_loss: 0.39273, val_acc: 0.93333\n",
            "Epoch [790/10000], loss: 0.40317 acc: 0.96000 val_loss: 0.39105, val_acc: 0.93333\n",
            "Epoch [800/10000], loss: 0.40146 acc: 0.96000 val_loss: 0.38939, val_acc: 0.93333\n",
            "Epoch [810/10000], loss: 0.39977 acc: 0.96000 val_loss: 0.38776, val_acc: 0.93333\n",
            "Epoch [820/10000], loss: 0.39810 acc: 0.96000 val_loss: 0.38615, val_acc: 0.93333\n",
            "Epoch [830/10000], loss: 0.39646 acc: 0.96000 val_loss: 0.38456, val_acc: 0.93333\n",
            "Epoch [840/10000], loss: 0.39483 acc: 0.96000 val_loss: 0.38298, val_acc: 0.93333\n",
            "Epoch [850/10000], loss: 0.39321 acc: 0.97333 val_loss: 0.38143, val_acc: 0.94667\n",
            "Epoch [860/10000], loss: 0.39162 acc: 0.97333 val_loss: 0.37990, val_acc: 0.94667\n",
            "Epoch [870/10000], loss: 0.39005 acc: 0.97333 val_loss: 0.37838, val_acc: 0.94667\n",
            "Epoch [880/10000], loss: 0.38849 acc: 0.97333 val_loss: 0.37688, val_acc: 0.94667\n",
            "Epoch [890/10000], loss: 0.38695 acc: 0.97333 val_loss: 0.37540, val_acc: 0.94667\n",
            "Epoch [900/10000], loss: 0.38543 acc: 0.97333 val_loss: 0.37394, val_acc: 0.94667\n",
            "Epoch [910/10000], loss: 0.38392 acc: 0.97333 val_loss: 0.37249, val_acc: 0.94667\n",
            "Epoch [920/10000], loss: 0.38243 acc: 0.97333 val_loss: 0.37106, val_acc: 0.94667\n",
            "Epoch [930/10000], loss: 0.38096 acc: 0.97333 val_loss: 0.36965, val_acc: 0.94667\n",
            "Epoch [940/10000], loss: 0.37950 acc: 0.97333 val_loss: 0.36825, val_acc: 0.94667\n",
            "Epoch [950/10000], loss: 0.37806 acc: 0.97333 val_loss: 0.36686, val_acc: 0.94667\n",
            "Epoch [960/10000], loss: 0.37663 acc: 0.97333 val_loss: 0.36550, val_acc: 0.96000\n",
            "Epoch [970/10000], loss: 0.37522 acc: 0.97333 val_loss: 0.36414, val_acc: 0.96000\n",
            "Epoch [980/10000], loss: 0.37382 acc: 0.97333 val_loss: 0.36280, val_acc: 0.96000\n",
            "Epoch [990/10000], loss: 0.37243 acc: 0.97333 val_loss: 0.36148, val_acc: 0.96000\n",
            "Epoch [1000/10000], loss: 0.37106 acc: 0.97333 val_loss: 0.36017, val_acc: 0.96000\n",
            "Epoch [1010/10000], loss: 0.36970 acc: 0.97333 val_loss: 0.35887, val_acc: 0.96000\n",
            "Epoch [1020/10000], loss: 0.36836 acc: 0.97333 val_loss: 0.35758, val_acc: 0.96000\n",
            "Epoch [1030/10000], loss: 0.36703 acc: 0.97333 val_loss: 0.35631, val_acc: 0.96000\n",
            "Epoch [1040/10000], loss: 0.36571 acc: 0.97333 val_loss: 0.35505, val_acc: 0.96000\n",
            "Epoch [1050/10000], loss: 0.36440 acc: 0.97333 val_loss: 0.35381, val_acc: 0.96000\n",
            "Epoch [1060/10000], loss: 0.36311 acc: 0.97333 val_loss: 0.35258, val_acc: 0.96000\n",
            "Epoch [1070/10000], loss: 0.36183 acc: 0.97333 val_loss: 0.35135, val_acc: 0.96000\n",
            "Epoch [1080/10000], loss: 0.36056 acc: 0.97333 val_loss: 0.35014, val_acc: 0.96000\n",
            "Epoch [1090/10000], loss: 0.35930 acc: 0.97333 val_loss: 0.34895, val_acc: 0.96000\n",
            "Epoch [1100/10000], loss: 0.35805 acc: 0.97333 val_loss: 0.34776, val_acc: 0.96000\n",
            "Epoch [1110/10000], loss: 0.35682 acc: 0.97333 val_loss: 0.34659, val_acc: 0.96000\n",
            "Epoch [1120/10000], loss: 0.35559 acc: 0.97333 val_loss: 0.34542, val_acc: 0.96000\n",
            "Epoch [1130/10000], loss: 0.35438 acc: 0.97333 val_loss: 0.34427, val_acc: 0.96000\n",
            "Epoch [1140/10000], loss: 0.35318 acc: 0.97333 val_loss: 0.34313, val_acc: 0.96000\n",
            "Epoch [1150/10000], loss: 0.35199 acc: 0.97333 val_loss: 0.34199, val_acc: 0.96000\n",
            "Epoch [1160/10000], loss: 0.35081 acc: 0.97333 val_loss: 0.34087, val_acc: 0.96000\n",
            "Epoch [1170/10000], loss: 0.34964 acc: 0.97333 val_loss: 0.33976, val_acc: 0.96000\n",
            "Epoch [1180/10000], loss: 0.34848 acc: 0.97333 val_loss: 0.33866, val_acc: 0.96000\n",
            "Epoch [1190/10000], loss: 0.34732 acc: 0.97333 val_loss: 0.33757, val_acc: 0.96000\n",
            "Epoch [1200/10000], loss: 0.34618 acc: 0.97333 val_loss: 0.33649, val_acc: 0.96000\n",
            "Epoch [1210/10000], loss: 0.34505 acc: 0.97333 val_loss: 0.33542, val_acc: 0.96000\n",
            "Epoch [1220/10000], loss: 0.34393 acc: 0.97333 val_loss: 0.33435, val_acc: 0.96000\n",
            "Epoch [1230/10000], loss: 0.34282 acc: 0.97333 val_loss: 0.33330, val_acc: 0.96000\n",
            "Epoch [1240/10000], loss: 0.34172 acc: 0.97333 val_loss: 0.33226, val_acc: 0.96000\n",
            "Epoch [1250/10000], loss: 0.34062 acc: 0.97333 val_loss: 0.33122, val_acc: 0.96000\n",
            "Epoch [1260/10000], loss: 0.33954 acc: 0.97333 val_loss: 0.33020, val_acc: 0.96000\n",
            "Epoch [1270/10000], loss: 0.33846 acc: 0.97333 val_loss: 0.32918, val_acc: 0.96000\n",
            "Epoch [1280/10000], loss: 0.33740 acc: 0.97333 val_loss: 0.32817, val_acc: 0.96000\n",
            "Epoch [1290/10000], loss: 0.33634 acc: 0.97333 val_loss: 0.32717, val_acc: 0.96000\n",
            "Epoch [1300/10000], loss: 0.33529 acc: 0.97333 val_loss: 0.32618, val_acc: 0.96000\n",
            "Epoch [1310/10000], loss: 0.33425 acc: 0.97333 val_loss: 0.32520, val_acc: 0.96000\n",
            "Epoch [1320/10000], loss: 0.33321 acc: 0.97333 val_loss: 0.32422, val_acc: 0.96000\n",
            "Epoch [1330/10000], loss: 0.33219 acc: 0.97333 val_loss: 0.32325, val_acc: 0.96000\n",
            "Epoch [1340/10000], loss: 0.33117 acc: 0.97333 val_loss: 0.32229, val_acc: 0.96000\n",
            "Epoch [1350/10000], loss: 0.33016 acc: 0.97333 val_loss: 0.32134, val_acc: 0.96000\n",
            "Epoch [1360/10000], loss: 0.32916 acc: 0.97333 val_loss: 0.32040, val_acc: 0.96000\n",
            "Epoch [1370/10000], loss: 0.32817 acc: 0.97333 val_loss: 0.31946, val_acc: 0.96000\n",
            "Epoch [1380/10000], loss: 0.32719 acc: 0.97333 val_loss: 0.31853, val_acc: 0.96000\n",
            "Epoch [1390/10000], loss: 0.32621 acc: 0.97333 val_loss: 0.31761, val_acc: 0.96000\n",
            "Epoch [1400/10000], loss: 0.32524 acc: 0.97333 val_loss: 0.31670, val_acc: 0.96000\n",
            "Epoch [1410/10000], loss: 0.32428 acc: 0.97333 val_loss: 0.31579, val_acc: 0.96000\n",
            "Epoch [1420/10000], loss: 0.32332 acc: 0.97333 val_loss: 0.31490, val_acc: 0.96000\n",
            "Epoch [1430/10000], loss: 0.32237 acc: 0.97333 val_loss: 0.31400, val_acc: 0.96000\n",
            "Epoch [1440/10000], loss: 0.32143 acc: 0.97333 val_loss: 0.31312, val_acc: 0.96000\n",
            "Epoch [1450/10000], loss: 0.32050 acc: 0.97333 val_loss: 0.31224, val_acc: 0.96000\n",
            "Epoch [1460/10000], loss: 0.31957 acc: 0.97333 val_loss: 0.31137, val_acc: 0.96000\n",
            "Epoch [1470/10000], loss: 0.31865 acc: 0.97333 val_loss: 0.31050, val_acc: 0.96000\n",
            "Epoch [1480/10000], loss: 0.31774 acc: 0.97333 val_loss: 0.30964, val_acc: 0.96000\n",
            "Epoch [1490/10000], loss: 0.31683 acc: 0.97333 val_loss: 0.30879, val_acc: 0.96000\n",
            "Epoch [1500/10000], loss: 0.31593 acc: 0.97333 val_loss: 0.30795, val_acc: 0.96000\n",
            "Epoch [1510/10000], loss: 0.31504 acc: 0.97333 val_loss: 0.30711, val_acc: 0.96000\n",
            "Epoch [1520/10000], loss: 0.31415 acc: 0.97333 val_loss: 0.30628, val_acc: 0.96000\n",
            "Epoch [1530/10000], loss: 0.31327 acc: 0.97333 val_loss: 0.30545, val_acc: 0.96000\n",
            "Epoch [1540/10000], loss: 0.31240 acc: 0.97333 val_loss: 0.30463, val_acc: 0.96000\n",
            "Epoch [1550/10000], loss: 0.31153 acc: 0.97333 val_loss: 0.30382, val_acc: 0.96000\n",
            "Epoch [1560/10000], loss: 0.31067 acc: 0.97333 val_loss: 0.30301, val_acc: 0.96000\n",
            "Epoch [1570/10000], loss: 0.30981 acc: 0.97333 val_loss: 0.30221, val_acc: 0.96000\n",
            "Epoch [1580/10000], loss: 0.30896 acc: 0.97333 val_loss: 0.30141, val_acc: 0.96000\n",
            "Epoch [1590/10000], loss: 0.30812 acc: 0.97333 val_loss: 0.30062, val_acc: 0.96000\n",
            "Epoch [1600/10000], loss: 0.30728 acc: 0.97333 val_loss: 0.29984, val_acc: 0.96000\n",
            "Epoch [1610/10000], loss: 0.30645 acc: 0.97333 val_loss: 0.29906, val_acc: 0.96000\n",
            "Epoch [1620/10000], loss: 0.30562 acc: 0.97333 val_loss: 0.29828, val_acc: 0.96000\n",
            "Epoch [1630/10000], loss: 0.30480 acc: 0.97333 val_loss: 0.29752, val_acc: 0.96000\n",
            "Epoch [1640/10000], loss: 0.30399 acc: 0.97333 val_loss: 0.29675, val_acc: 0.96000\n",
            "Epoch [1650/10000], loss: 0.30318 acc: 0.97333 val_loss: 0.29600, val_acc: 0.96000\n",
            "Epoch [1660/10000], loss: 0.30237 acc: 0.97333 val_loss: 0.29525, val_acc: 0.96000\n",
            "Epoch [1670/10000], loss: 0.30158 acc: 0.97333 val_loss: 0.29450, val_acc: 0.96000\n",
            "Epoch [1680/10000], loss: 0.30078 acc: 0.97333 val_loss: 0.29376, val_acc: 0.96000\n",
            "Epoch [1690/10000], loss: 0.30000 acc: 0.97333 val_loss: 0.29302, val_acc: 0.96000\n",
            "Epoch [1700/10000], loss: 0.29922 acc: 0.97333 val_loss: 0.29229, val_acc: 0.96000\n",
            "Epoch [1710/10000], loss: 0.29844 acc: 0.97333 val_loss: 0.29157, val_acc: 0.96000\n",
            "Epoch [1720/10000], loss: 0.29767 acc: 0.97333 val_loss: 0.29085, val_acc: 0.96000\n",
            "Epoch [1730/10000], loss: 0.29690 acc: 0.97333 val_loss: 0.29013, val_acc: 0.96000\n",
            "Epoch [1740/10000], loss: 0.29614 acc: 0.97333 val_loss: 0.28942, val_acc: 0.96000\n",
            "Epoch [1750/10000], loss: 0.29538 acc: 0.97333 val_loss: 0.28872, val_acc: 0.96000\n",
            "Epoch [1760/10000], loss: 0.29463 acc: 0.97333 val_loss: 0.28801, val_acc: 0.96000\n",
            "Epoch [1770/10000], loss: 0.29389 acc: 0.97333 val_loss: 0.28732, val_acc: 0.96000\n",
            "Epoch [1780/10000], loss: 0.29315 acc: 0.97333 val_loss: 0.28663, val_acc: 0.96000\n",
            "Epoch [1790/10000], loss: 0.29241 acc: 0.97333 val_loss: 0.28594, val_acc: 0.96000\n",
            "Epoch [1800/10000], loss: 0.29168 acc: 0.97333 val_loss: 0.28526, val_acc: 0.96000\n",
            "Epoch [1810/10000], loss: 0.29095 acc: 0.97333 val_loss: 0.28458, val_acc: 0.96000\n",
            "Epoch [1820/10000], loss: 0.29023 acc: 0.97333 val_loss: 0.28391, val_acc: 0.96000\n",
            "Epoch [1830/10000], loss: 0.28951 acc: 0.97333 val_loss: 0.28324, val_acc: 0.96000\n",
            "Epoch [1840/10000], loss: 0.28880 acc: 0.97333 val_loss: 0.28258, val_acc: 0.96000\n",
            "Epoch [1850/10000], loss: 0.28809 acc: 0.97333 val_loss: 0.28192, val_acc: 0.96000\n",
            "Epoch [1860/10000], loss: 0.28739 acc: 0.97333 val_loss: 0.28126, val_acc: 0.96000\n",
            "Epoch [1870/10000], loss: 0.28669 acc: 0.97333 val_loss: 0.28061, val_acc: 0.96000\n",
            "Epoch [1880/10000], loss: 0.28599 acc: 0.97333 val_loss: 0.27996, val_acc: 0.96000\n",
            "Epoch [1890/10000], loss: 0.28530 acc: 0.97333 val_loss: 0.27932, val_acc: 0.96000\n",
            "Epoch [1900/10000], loss: 0.28462 acc: 0.97333 val_loss: 0.27868, val_acc: 0.96000\n",
            "Epoch [1910/10000], loss: 0.28394 acc: 0.97333 val_loss: 0.27805, val_acc: 0.96000\n",
            "Epoch [1920/10000], loss: 0.28326 acc: 0.97333 val_loss: 0.27742, val_acc: 0.96000\n",
            "Epoch [1930/10000], loss: 0.28258 acc: 0.97333 val_loss: 0.27679, val_acc: 0.96000\n",
            "Epoch [1940/10000], loss: 0.28192 acc: 0.97333 val_loss: 0.27617, val_acc: 0.96000\n",
            "Epoch [1950/10000], loss: 0.28125 acc: 0.97333 val_loss: 0.27555, val_acc: 0.96000\n",
            "Epoch [1960/10000], loss: 0.28059 acc: 0.97333 val_loss: 0.27494, val_acc: 0.96000\n",
            "Epoch [1970/10000], loss: 0.27993 acc: 0.97333 val_loss: 0.27433, val_acc: 0.96000\n",
            "Epoch [1980/10000], loss: 0.27928 acc: 0.97333 val_loss: 0.27372, val_acc: 0.96000\n",
            "Epoch [1990/10000], loss: 0.27863 acc: 0.97333 val_loss: 0.27312, val_acc: 0.96000\n",
            "Epoch [2000/10000], loss: 0.27799 acc: 0.97333 val_loss: 0.27252, val_acc: 0.96000\n",
            "Epoch [2010/10000], loss: 0.27735 acc: 0.97333 val_loss: 0.27193, val_acc: 0.96000\n",
            "Epoch [2020/10000], loss: 0.27671 acc: 0.97333 val_loss: 0.27134, val_acc: 0.96000\n",
            "Epoch [2030/10000], loss: 0.27608 acc: 0.97333 val_loss: 0.27075, val_acc: 0.96000\n",
            "Epoch [2040/10000], loss: 0.27545 acc: 0.97333 val_loss: 0.27016, val_acc: 0.96000\n",
            "Epoch [2050/10000], loss: 0.27482 acc: 0.97333 val_loss: 0.26958, val_acc: 0.96000\n",
            "Epoch [2060/10000], loss: 0.27420 acc: 0.97333 val_loss: 0.26901, val_acc: 0.96000\n",
            "Epoch [2070/10000], loss: 0.27358 acc: 0.97333 val_loss: 0.26843, val_acc: 0.96000\n",
            "Epoch [2080/10000], loss: 0.27297 acc: 0.97333 val_loss: 0.26786, val_acc: 0.96000\n",
            "Epoch [2090/10000], loss: 0.27236 acc: 0.97333 val_loss: 0.26730, val_acc: 0.96000\n",
            "Epoch [2100/10000], loss: 0.27175 acc: 0.97333 val_loss: 0.26674, val_acc: 0.96000\n",
            "Epoch [2110/10000], loss: 0.27115 acc: 0.97333 val_loss: 0.26618, val_acc: 0.96000\n",
            "Epoch [2120/10000], loss: 0.27055 acc: 0.97333 val_loss: 0.26562, val_acc: 0.96000\n",
            "Epoch [2130/10000], loss: 0.26995 acc: 0.97333 val_loss: 0.26507, val_acc: 0.96000\n",
            "Epoch [2140/10000], loss: 0.26936 acc: 0.97333 val_loss: 0.26452, val_acc: 0.96000\n",
            "Epoch [2150/10000], loss: 0.26877 acc: 0.97333 val_loss: 0.26397, val_acc: 0.96000\n",
            "Epoch [2160/10000], loss: 0.26818 acc: 0.97333 val_loss: 0.26343, val_acc: 0.96000\n",
            "Epoch [2170/10000], loss: 0.26760 acc: 0.97333 val_loss: 0.26289, val_acc: 0.96000\n",
            "Epoch [2180/10000], loss: 0.26702 acc: 0.97333 val_loss: 0.26236, val_acc: 0.96000\n",
            "Epoch [2190/10000], loss: 0.26644 acc: 0.97333 val_loss: 0.26182, val_acc: 0.96000\n",
            "Epoch [2200/10000], loss: 0.26587 acc: 0.97333 val_loss: 0.26129, val_acc: 0.96000\n",
            "Epoch [2210/10000], loss: 0.26530 acc: 0.97333 val_loss: 0.26077, val_acc: 0.96000\n",
            "Epoch [2220/10000], loss: 0.26473 acc: 0.97333 val_loss: 0.26024, val_acc: 0.96000\n",
            "Epoch [2230/10000], loss: 0.26417 acc: 0.97333 val_loss: 0.25972, val_acc: 0.96000\n",
            "Epoch [2240/10000], loss: 0.26361 acc: 0.97333 val_loss: 0.25921, val_acc: 0.96000\n",
            "Epoch [2250/10000], loss: 0.26305 acc: 0.97333 val_loss: 0.25869, val_acc: 0.96000\n",
            "Epoch [2260/10000], loss: 0.26250 acc: 0.97333 val_loss: 0.25818, val_acc: 0.96000\n",
            "Epoch [2270/10000], loss: 0.26195 acc: 0.97333 val_loss: 0.25767, val_acc: 0.96000\n",
            "Epoch [2280/10000], loss: 0.26140 acc: 0.97333 val_loss: 0.25717, val_acc: 0.96000\n",
            "Epoch [2290/10000], loss: 0.26086 acc: 0.97333 val_loss: 0.25666, val_acc: 0.96000\n",
            "Epoch [2300/10000], loss: 0.26032 acc: 0.97333 val_loss: 0.25616, val_acc: 0.96000\n",
            "Epoch [2310/10000], loss: 0.25978 acc: 0.97333 val_loss: 0.25567, val_acc: 0.96000\n",
            "Epoch [2320/10000], loss: 0.25924 acc: 0.97333 val_loss: 0.25517, val_acc: 0.96000\n",
            "Epoch [2330/10000], loss: 0.25871 acc: 0.97333 val_loss: 0.25468, val_acc: 0.96000\n",
            "Epoch [2340/10000], loss: 0.25818 acc: 0.97333 val_loss: 0.25419, val_acc: 0.96000\n",
            "Epoch [2350/10000], loss: 0.25766 acc: 0.97333 val_loss: 0.25371, val_acc: 0.96000\n",
            "Epoch [2360/10000], loss: 0.25713 acc: 0.97333 val_loss: 0.25322, val_acc: 0.96000\n",
            "Epoch [2370/10000], loss: 0.25661 acc: 0.97333 val_loss: 0.25274, val_acc: 0.96000\n",
            "Epoch [2380/10000], loss: 0.25609 acc: 0.97333 val_loss: 0.25227, val_acc: 0.96000\n",
            "Epoch [2390/10000], loss: 0.25558 acc: 0.97333 val_loss: 0.25179, val_acc: 0.96000\n",
            "Epoch [2400/10000], loss: 0.25507 acc: 0.97333 val_loss: 0.25132, val_acc: 0.96000\n",
            "Epoch [2410/10000], loss: 0.25456 acc: 0.97333 val_loss: 0.25085, val_acc: 0.96000\n",
            "Epoch [2420/10000], loss: 0.25405 acc: 0.97333 val_loss: 0.25038, val_acc: 0.96000\n",
            "Epoch [2430/10000], loss: 0.25355 acc: 0.97333 val_loss: 0.24992, val_acc: 0.96000\n",
            "Epoch [2440/10000], loss: 0.25304 acc: 0.97333 val_loss: 0.24946, val_acc: 0.96000\n",
            "Epoch [2450/10000], loss: 0.25255 acc: 0.97333 val_loss: 0.24900, val_acc: 0.96000\n",
            "Epoch [2460/10000], loss: 0.25205 acc: 0.97333 val_loss: 0.24854, val_acc: 0.96000\n",
            "Epoch [2470/10000], loss: 0.25156 acc: 0.97333 val_loss: 0.24809, val_acc: 0.96000\n",
            "Epoch [2480/10000], loss: 0.25107 acc: 0.97333 val_loss: 0.24764, val_acc: 0.96000\n",
            "Epoch [2490/10000], loss: 0.25058 acc: 0.97333 val_loss: 0.24719, val_acc: 0.96000\n",
            "Epoch [2500/10000], loss: 0.25009 acc: 0.97333 val_loss: 0.24674, val_acc: 0.96000\n",
            "Epoch [2510/10000], loss: 0.24961 acc: 0.97333 val_loss: 0.24630, val_acc: 0.96000\n",
            "Epoch [2520/10000], loss: 0.24913 acc: 0.97333 val_loss: 0.24585, val_acc: 0.96000\n",
            "Epoch [2530/10000], loss: 0.24865 acc: 0.97333 val_loss: 0.24541, val_acc: 0.96000\n",
            "Epoch [2540/10000], loss: 0.24818 acc: 0.97333 val_loss: 0.24498, val_acc: 0.96000\n",
            "Epoch [2550/10000], loss: 0.24770 acc: 0.97333 val_loss: 0.24454, val_acc: 0.96000\n",
            "Epoch [2560/10000], loss: 0.24723 acc: 0.97333 val_loss: 0.24411, val_acc: 0.96000\n",
            "Epoch [2570/10000], loss: 0.24676 acc: 0.97333 val_loss: 0.24368, val_acc: 0.96000\n",
            "Epoch [2580/10000], loss: 0.24630 acc: 0.98667 val_loss: 0.24325, val_acc: 0.96000\n",
            "Epoch [2590/10000], loss: 0.24584 acc: 0.98667 val_loss: 0.24283, val_acc: 0.96000\n",
            "Epoch [2600/10000], loss: 0.24537 acc: 0.98667 val_loss: 0.24240, val_acc: 0.96000\n",
            "Epoch [2610/10000], loss: 0.24492 acc: 0.98667 val_loss: 0.24198, val_acc: 0.96000\n",
            "Epoch [2620/10000], loss: 0.24446 acc: 0.98667 val_loss: 0.24156, val_acc: 0.96000\n",
            "Epoch [2630/10000], loss: 0.24401 acc: 0.98667 val_loss: 0.24115, val_acc: 0.96000\n",
            "Epoch [2640/10000], loss: 0.24355 acc: 0.98667 val_loss: 0.24073, val_acc: 0.96000\n",
            "Epoch [2650/10000], loss: 0.24311 acc: 0.98667 val_loss: 0.24032, val_acc: 0.96000\n",
            "Epoch [2660/10000], loss: 0.24266 acc: 0.98667 val_loss: 0.23991, val_acc: 0.96000\n",
            "Epoch [2670/10000], loss: 0.24221 acc: 0.98667 val_loss: 0.23950, val_acc: 0.96000\n",
            "Epoch [2680/10000], loss: 0.24177 acc: 0.98667 val_loss: 0.23909, val_acc: 0.96000\n",
            "Epoch [2690/10000], loss: 0.24133 acc: 0.98667 val_loss: 0.23869, val_acc: 0.96000\n",
            "Epoch [2700/10000], loss: 0.24089 acc: 0.98667 val_loss: 0.23829, val_acc: 0.96000\n",
            "Epoch [2710/10000], loss: 0.24046 acc: 0.98667 val_loss: 0.23789, val_acc: 0.96000\n",
            "Epoch [2720/10000], loss: 0.24002 acc: 0.98667 val_loss: 0.23749, val_acc: 0.96000\n",
            "Epoch [2730/10000], loss: 0.23959 acc: 0.98667 val_loss: 0.23710, val_acc: 0.96000\n",
            "Epoch [2740/10000], loss: 0.23916 acc: 0.98667 val_loss: 0.23670, val_acc: 0.96000\n",
            "Epoch [2750/10000], loss: 0.23874 acc: 0.98667 val_loss: 0.23631, val_acc: 0.96000\n",
            "Epoch [2760/10000], loss: 0.23831 acc: 0.98667 val_loss: 0.23592, val_acc: 0.96000\n",
            "Epoch [2770/10000], loss: 0.23789 acc: 0.98667 val_loss: 0.23553, val_acc: 0.96000\n",
            "Epoch [2780/10000], loss: 0.23747 acc: 0.98667 val_loss: 0.23515, val_acc: 0.96000\n",
            "Epoch [2790/10000], loss: 0.23705 acc: 0.98667 val_loss: 0.23476, val_acc: 0.96000\n",
            "Epoch [2800/10000], loss: 0.23663 acc: 0.98667 val_loss: 0.23438, val_acc: 0.96000\n",
            "Epoch [2810/10000], loss: 0.23622 acc: 0.98667 val_loss: 0.23400, val_acc: 0.96000\n",
            "Epoch [2820/10000], loss: 0.23580 acc: 0.98667 val_loss: 0.23363, val_acc: 0.96000\n",
            "Epoch [2830/10000], loss: 0.23539 acc: 0.98667 val_loss: 0.23325, val_acc: 0.96000\n",
            "Epoch [2840/10000], loss: 0.23498 acc: 0.98667 val_loss: 0.23287, val_acc: 0.96000\n",
            "Epoch [2850/10000], loss: 0.23458 acc: 0.98667 val_loss: 0.23250, val_acc: 0.96000\n",
            "Epoch [2860/10000], loss: 0.23417 acc: 0.98667 val_loss: 0.23213, val_acc: 0.96000\n",
            "Epoch [2870/10000], loss: 0.23377 acc: 0.98667 val_loss: 0.23176, val_acc: 0.96000\n",
            "Epoch [2880/10000], loss: 0.23337 acc: 0.98667 val_loss: 0.23140, val_acc: 0.96000\n",
            "Epoch [2890/10000], loss: 0.23297 acc: 0.98667 val_loss: 0.23103, val_acc: 0.96000\n",
            "Epoch [2900/10000], loss: 0.23257 acc: 0.98667 val_loss: 0.23067, val_acc: 0.96000\n",
            "Epoch [2910/10000], loss: 0.23218 acc: 0.98667 val_loss: 0.23031, val_acc: 0.96000\n",
            "Epoch [2920/10000], loss: 0.23178 acc: 0.98667 val_loss: 0.22995, val_acc: 0.96000\n",
            "Epoch [2930/10000], loss: 0.23139 acc: 0.98667 val_loss: 0.22959, val_acc: 0.96000\n",
            "Epoch [2940/10000], loss: 0.23100 acc: 0.98667 val_loss: 0.22923, val_acc: 0.96000\n",
            "Epoch [2950/10000], loss: 0.23061 acc: 0.98667 val_loss: 0.22888, val_acc: 0.96000\n",
            "Epoch [2960/10000], loss: 0.23023 acc: 0.98667 val_loss: 0.22853, val_acc: 0.96000\n",
            "Epoch [2970/10000], loss: 0.22984 acc: 0.98667 val_loss: 0.22818, val_acc: 0.96000\n",
            "Epoch [2980/10000], loss: 0.22946 acc: 0.98667 val_loss: 0.22783, val_acc: 0.96000\n",
            "Epoch [2990/10000], loss: 0.22908 acc: 0.98667 val_loss: 0.22748, val_acc: 0.96000\n",
            "Epoch [3000/10000], loss: 0.22870 acc: 0.98667 val_loss: 0.22713, val_acc: 0.96000\n",
            "Epoch [3010/10000], loss: 0.22832 acc: 0.98667 val_loss: 0.22679, val_acc: 0.96000\n",
            "Epoch [3020/10000], loss: 0.22795 acc: 0.98667 val_loss: 0.22645, val_acc: 0.96000\n",
            "Epoch [3030/10000], loss: 0.22757 acc: 0.98667 val_loss: 0.22610, val_acc: 0.96000\n",
            "Epoch [3040/10000], loss: 0.22720 acc: 0.98667 val_loss: 0.22577, val_acc: 0.96000\n",
            "Epoch [3050/10000], loss: 0.22683 acc: 0.98667 val_loss: 0.22543, val_acc: 0.96000\n",
            "Epoch [3060/10000], loss: 0.22646 acc: 0.98667 val_loss: 0.22509, val_acc: 0.96000\n",
            "Epoch [3070/10000], loss: 0.22610 acc: 0.98667 val_loss: 0.22476, val_acc: 0.96000\n",
            "Epoch [3080/10000], loss: 0.22573 acc: 0.98667 val_loss: 0.22442, val_acc: 0.96000\n",
            "Epoch [3090/10000], loss: 0.22537 acc: 0.98667 val_loss: 0.22409, val_acc: 0.96000\n",
            "Epoch [3100/10000], loss: 0.22501 acc: 0.98667 val_loss: 0.22376, val_acc: 0.96000\n",
            "Epoch [3110/10000], loss: 0.22465 acc: 0.98667 val_loss: 0.22343, val_acc: 0.96000\n",
            "Epoch [3120/10000], loss: 0.22429 acc: 0.98667 val_loss: 0.22311, val_acc: 0.96000\n",
            "Epoch [3130/10000], loss: 0.22393 acc: 0.98667 val_loss: 0.22278, val_acc: 0.96000\n",
            "Epoch [3140/10000], loss: 0.22358 acc: 0.98667 val_loss: 0.22246, val_acc: 0.96000\n",
            "Epoch [3150/10000], loss: 0.22322 acc: 0.98667 val_loss: 0.22214, val_acc: 0.96000\n",
            "Epoch [3160/10000], loss: 0.22287 acc: 0.98667 val_loss: 0.22181, val_acc: 0.96000\n",
            "Epoch [3170/10000], loss: 0.22252 acc: 0.98667 val_loss: 0.22150, val_acc: 0.96000\n",
            "Epoch [3180/10000], loss: 0.22217 acc: 0.98667 val_loss: 0.22118, val_acc: 0.96000\n",
            "Epoch [3190/10000], loss: 0.22182 acc: 0.98667 val_loss: 0.22086, val_acc: 0.96000\n",
            "Epoch [3200/10000], loss: 0.22148 acc: 0.98667 val_loss: 0.22055, val_acc: 0.96000\n",
            "Epoch [3210/10000], loss: 0.22113 acc: 0.98667 val_loss: 0.22023, val_acc: 0.96000\n",
            "Epoch [3220/10000], loss: 0.22079 acc: 0.98667 val_loss: 0.21992, val_acc: 0.96000\n",
            "Epoch [3230/10000], loss: 0.22045 acc: 0.98667 val_loss: 0.21961, val_acc: 0.96000\n",
            "Epoch [3240/10000], loss: 0.22011 acc: 0.98667 val_loss: 0.21930, val_acc: 0.96000\n",
            "Epoch [3250/10000], loss: 0.21977 acc: 0.98667 val_loss: 0.21899, val_acc: 0.96000\n",
            "Epoch [3260/10000], loss: 0.21943 acc: 0.98667 val_loss: 0.21869, val_acc: 0.96000\n",
            "Epoch [3270/10000], loss: 0.21910 acc: 0.98667 val_loss: 0.21838, val_acc: 0.96000\n",
            "Epoch [3280/10000], loss: 0.21876 acc: 0.98667 val_loss: 0.21808, val_acc: 0.96000\n",
            "Epoch [3290/10000], loss: 0.21843 acc: 0.98667 val_loss: 0.21778, val_acc: 0.96000\n",
            "Epoch [3300/10000], loss: 0.21810 acc: 0.98667 val_loss: 0.21747, val_acc: 0.96000\n",
            "Epoch [3310/10000], loss: 0.21777 acc: 0.98667 val_loss: 0.21717, val_acc: 0.96000\n",
            "Epoch [3320/10000], loss: 0.21744 acc: 0.98667 val_loss: 0.21688, val_acc: 0.96000\n",
            "Epoch [3330/10000], loss: 0.21711 acc: 0.98667 val_loss: 0.21658, val_acc: 0.96000\n",
            "Epoch [3340/10000], loss: 0.21679 acc: 0.98667 val_loss: 0.21628, val_acc: 0.96000\n",
            "Epoch [3350/10000], loss: 0.21646 acc: 0.98667 val_loss: 0.21599, val_acc: 0.96000\n",
            "Epoch [3360/10000], loss: 0.21614 acc: 0.98667 val_loss: 0.21570, val_acc: 0.96000\n",
            "Epoch [3370/10000], loss: 0.21582 acc: 0.98667 val_loss: 0.21540, val_acc: 0.96000\n",
            "Epoch [3380/10000], loss: 0.21550 acc: 0.98667 val_loss: 0.21511, val_acc: 0.96000\n",
            "Epoch [3390/10000], loss: 0.21518 acc: 0.98667 val_loss: 0.21483, val_acc: 0.96000\n",
            "Epoch [3400/10000], loss: 0.21487 acc: 0.98667 val_loss: 0.21454, val_acc: 0.96000\n",
            "Epoch [3410/10000], loss: 0.21455 acc: 0.98667 val_loss: 0.21425, val_acc: 0.96000\n",
            "Epoch [3420/10000], loss: 0.21424 acc: 0.98667 val_loss: 0.21396, val_acc: 0.96000\n",
            "Epoch [3430/10000], loss: 0.21392 acc: 0.98667 val_loss: 0.21368, val_acc: 0.96000\n",
            "Epoch [3440/10000], loss: 0.21361 acc: 0.98667 val_loss: 0.21340, val_acc: 0.96000\n",
            "Epoch [3450/10000], loss: 0.21330 acc: 0.98667 val_loss: 0.21312, val_acc: 0.96000\n",
            "Epoch [3460/10000], loss: 0.21299 acc: 0.98667 val_loss: 0.21284, val_acc: 0.96000\n",
            "Epoch [3470/10000], loss: 0.21268 acc: 0.98667 val_loss: 0.21256, val_acc: 0.96000\n",
            "Epoch [3480/10000], loss: 0.21238 acc: 0.98667 val_loss: 0.21228, val_acc: 0.96000\n",
            "Epoch [3490/10000], loss: 0.21207 acc: 0.98667 val_loss: 0.21200, val_acc: 0.96000\n",
            "Epoch [3500/10000], loss: 0.21177 acc: 0.98667 val_loss: 0.21173, val_acc: 0.96000\n",
            "Epoch [3510/10000], loss: 0.21146 acc: 0.98667 val_loss: 0.21145, val_acc: 0.96000\n",
            "Epoch [3520/10000], loss: 0.21116 acc: 0.98667 val_loss: 0.21118, val_acc: 0.96000\n",
            "Epoch [3530/10000], loss: 0.21086 acc: 0.98667 val_loss: 0.21091, val_acc: 0.96000\n",
            "Epoch [3540/10000], loss: 0.21056 acc: 0.98667 val_loss: 0.21064, val_acc: 0.96000\n",
            "Epoch [3550/10000], loss: 0.21026 acc: 0.98667 val_loss: 0.21037, val_acc: 0.96000\n",
            "Epoch [3560/10000], loss: 0.20997 acc: 0.98667 val_loss: 0.21010, val_acc: 0.96000\n",
            "Epoch [3570/10000], loss: 0.20967 acc: 0.98667 val_loss: 0.20983, val_acc: 0.96000\n",
            "Epoch [3580/10000], loss: 0.20938 acc: 0.98667 val_loss: 0.20956, val_acc: 0.96000\n",
            "Epoch [3590/10000], loss: 0.20909 acc: 0.98667 val_loss: 0.20930, val_acc: 0.96000\n",
            "Epoch [3600/10000], loss: 0.20879 acc: 0.98667 val_loss: 0.20903, val_acc: 0.96000\n",
            "Epoch [3610/10000], loss: 0.20850 acc: 0.98667 val_loss: 0.20877, val_acc: 0.96000\n",
            "Epoch [3620/10000], loss: 0.20821 acc: 0.98667 val_loss: 0.20851, val_acc: 0.96000\n",
            "Epoch [3630/10000], loss: 0.20793 acc: 0.98667 val_loss: 0.20825, val_acc: 0.96000\n",
            "Epoch [3640/10000], loss: 0.20764 acc: 0.98667 val_loss: 0.20799, val_acc: 0.96000\n",
            "Epoch [3650/10000], loss: 0.20735 acc: 0.98667 val_loss: 0.20773, val_acc: 0.96000\n",
            "Epoch [3660/10000], loss: 0.20707 acc: 0.98667 val_loss: 0.20747, val_acc: 0.96000\n",
            "Epoch [3670/10000], loss: 0.20678 acc: 0.98667 val_loss: 0.20721, val_acc: 0.96000\n",
            "Epoch [3680/10000], loss: 0.20650 acc: 0.98667 val_loss: 0.20696, val_acc: 0.96000\n",
            "Epoch [3690/10000], loss: 0.20622 acc: 0.98667 val_loss: 0.20670, val_acc: 0.96000\n",
            "Epoch [3700/10000], loss: 0.20594 acc: 0.98667 val_loss: 0.20645, val_acc: 0.96000\n",
            "Epoch [3710/10000], loss: 0.20566 acc: 0.98667 val_loss: 0.20620, val_acc: 0.96000\n",
            "Epoch [3720/10000], loss: 0.20538 acc: 0.98667 val_loss: 0.20595, val_acc: 0.96000\n",
            "Epoch [3730/10000], loss: 0.20511 acc: 0.98667 val_loss: 0.20570, val_acc: 0.96000\n",
            "Epoch [3740/10000], loss: 0.20483 acc: 0.98667 val_loss: 0.20545, val_acc: 0.96000\n",
            "Epoch [3750/10000], loss: 0.20455 acc: 0.98667 val_loss: 0.20520, val_acc: 0.96000\n",
            "Epoch [3760/10000], loss: 0.20428 acc: 0.98667 val_loss: 0.20495, val_acc: 0.96000\n",
            "Epoch [3770/10000], loss: 0.20401 acc: 0.98667 val_loss: 0.20471, val_acc: 0.96000\n",
            "Epoch [3780/10000], loss: 0.20374 acc: 0.98667 val_loss: 0.20446, val_acc: 0.96000\n",
            "Epoch [3790/10000], loss: 0.20347 acc: 0.98667 val_loss: 0.20422, val_acc: 0.96000\n",
            "Epoch [3800/10000], loss: 0.20320 acc: 0.98667 val_loss: 0.20397, val_acc: 0.96000\n",
            "Epoch [3810/10000], loss: 0.20293 acc: 0.98667 val_loss: 0.20373, val_acc: 0.96000\n",
            "Epoch [3820/10000], loss: 0.20266 acc: 0.98667 val_loss: 0.20349, val_acc: 0.96000\n",
            "Epoch [3830/10000], loss: 0.20239 acc: 0.98667 val_loss: 0.20325, val_acc: 0.96000\n",
            "Epoch [3840/10000], loss: 0.20213 acc: 0.98667 val_loss: 0.20301, val_acc: 0.96000\n",
            "Epoch [3850/10000], loss: 0.20186 acc: 0.98667 val_loss: 0.20277, val_acc: 0.96000\n",
            "Epoch [3860/10000], loss: 0.20160 acc: 0.98667 val_loss: 0.20253, val_acc: 0.96000\n",
            "Epoch [3870/10000], loss: 0.20134 acc: 0.98667 val_loss: 0.20230, val_acc: 0.96000\n",
            "Epoch [3880/10000], loss: 0.20108 acc: 0.98667 val_loss: 0.20206, val_acc: 0.96000\n",
            "Epoch [3890/10000], loss: 0.20082 acc: 0.98667 val_loss: 0.20183, val_acc: 0.96000\n",
            "Epoch [3900/10000], loss: 0.20056 acc: 0.98667 val_loss: 0.20159, val_acc: 0.96000\n",
            "Epoch [3910/10000], loss: 0.20030 acc: 0.98667 val_loss: 0.20136, val_acc: 0.96000\n",
            "Epoch [3920/10000], loss: 0.20004 acc: 0.98667 val_loss: 0.20113, val_acc: 0.96000\n",
            "Epoch [3930/10000], loss: 0.19979 acc: 0.98667 val_loss: 0.20090, val_acc: 0.96000\n",
            "Epoch [3940/10000], loss: 0.19953 acc: 0.98667 val_loss: 0.20067, val_acc: 0.96000\n",
            "Epoch [3950/10000], loss: 0.19928 acc: 0.98667 val_loss: 0.20044, val_acc: 0.96000\n",
            "Epoch [3960/10000], loss: 0.19902 acc: 0.98667 val_loss: 0.20021, val_acc: 0.96000\n",
            "Epoch [3970/10000], loss: 0.19877 acc: 0.98667 val_loss: 0.19998, val_acc: 0.96000\n",
            "Epoch [3980/10000], loss: 0.19852 acc: 0.98667 val_loss: 0.19976, val_acc: 0.96000\n",
            "Epoch [3990/10000], loss: 0.19827 acc: 0.98667 val_loss: 0.19953, val_acc: 0.96000\n",
            "Epoch [4000/10000], loss: 0.19802 acc: 0.98667 val_loss: 0.19931, val_acc: 0.96000\n",
            "Epoch [4010/10000], loss: 0.19777 acc: 0.98667 val_loss: 0.19908, val_acc: 0.96000\n",
            "Epoch [4020/10000], loss: 0.19752 acc: 0.98667 val_loss: 0.19886, val_acc: 0.96000\n",
            "Epoch [4030/10000], loss: 0.19728 acc: 0.98667 val_loss: 0.19864, val_acc: 0.96000\n",
            "Epoch [4040/10000], loss: 0.19703 acc: 0.98667 val_loss: 0.19842, val_acc: 0.96000\n",
            "Epoch [4050/10000], loss: 0.19679 acc: 0.98667 val_loss: 0.19820, val_acc: 0.96000\n",
            "Epoch [4060/10000], loss: 0.19654 acc: 0.98667 val_loss: 0.19798, val_acc: 0.96000\n",
            "Epoch [4070/10000], loss: 0.19630 acc: 0.98667 val_loss: 0.19776, val_acc: 0.96000\n",
            "Epoch [4080/10000], loss: 0.19606 acc: 0.98667 val_loss: 0.19754, val_acc: 0.96000\n",
            "Epoch [4090/10000], loss: 0.19582 acc: 0.98667 val_loss: 0.19732, val_acc: 0.96000\n",
            "Epoch [4100/10000], loss: 0.19557 acc: 0.98667 val_loss: 0.19711, val_acc: 0.96000\n",
            "Epoch [4110/10000], loss: 0.19534 acc: 0.98667 val_loss: 0.19689, val_acc: 0.96000\n",
            "Epoch [4120/10000], loss: 0.19510 acc: 0.98667 val_loss: 0.19668, val_acc: 0.96000\n",
            "Epoch [4130/10000], loss: 0.19486 acc: 0.98667 val_loss: 0.19646, val_acc: 0.96000\n",
            "Epoch [4140/10000], loss: 0.19462 acc: 0.98667 val_loss: 0.19625, val_acc: 0.96000\n",
            "Epoch [4150/10000], loss: 0.19439 acc: 0.98667 val_loss: 0.19604, val_acc: 0.96000\n",
            "Epoch [4160/10000], loss: 0.19415 acc: 0.98667 val_loss: 0.19583, val_acc: 0.96000\n",
            "Epoch [4170/10000], loss: 0.19392 acc: 0.98667 val_loss: 0.19562, val_acc: 0.96000\n",
            "Epoch [4180/10000], loss: 0.19368 acc: 0.98667 val_loss: 0.19541, val_acc: 0.96000\n",
            "Epoch [4190/10000], loss: 0.19345 acc: 0.98667 val_loss: 0.19520, val_acc: 0.96000\n",
            "Epoch [4200/10000], loss: 0.19322 acc: 0.98667 val_loss: 0.19499, val_acc: 0.96000\n",
            "Epoch [4210/10000], loss: 0.19299 acc: 0.98667 val_loss: 0.19478, val_acc: 0.96000\n",
            "Epoch [4220/10000], loss: 0.19276 acc: 0.98667 val_loss: 0.19457, val_acc: 0.96000\n",
            "Epoch [4230/10000], loss: 0.19253 acc: 0.98667 val_loss: 0.19437, val_acc: 0.96000\n",
            "Epoch [4240/10000], loss: 0.19230 acc: 0.98667 val_loss: 0.19416, val_acc: 0.96000\n",
            "Epoch [4250/10000], loss: 0.19207 acc: 0.98667 val_loss: 0.19396, val_acc: 0.96000\n",
            "Epoch [4260/10000], loss: 0.19184 acc: 0.98667 val_loss: 0.19376, val_acc: 0.96000\n",
            "Epoch [4270/10000], loss: 0.19162 acc: 0.98667 val_loss: 0.19355, val_acc: 0.96000\n",
            "Epoch [4280/10000], loss: 0.19139 acc: 0.98667 val_loss: 0.19335, val_acc: 0.96000\n",
            "Epoch [4290/10000], loss: 0.19117 acc: 0.98667 val_loss: 0.19315, val_acc: 0.96000\n",
            "Epoch [4300/10000], loss: 0.19094 acc: 0.98667 val_loss: 0.19295, val_acc: 0.96000\n",
            "Epoch [4310/10000], loss: 0.19072 acc: 0.98667 val_loss: 0.19275, val_acc: 0.96000\n",
            "Epoch [4320/10000], loss: 0.19050 acc: 0.98667 val_loss: 0.19255, val_acc: 0.96000\n",
            "Epoch [4330/10000], loss: 0.19028 acc: 0.98667 val_loss: 0.19235, val_acc: 0.96000\n",
            "Epoch [4340/10000], loss: 0.19006 acc: 0.98667 val_loss: 0.19215, val_acc: 0.96000\n",
            "Epoch [4350/10000], loss: 0.18984 acc: 0.98667 val_loss: 0.19196, val_acc: 0.96000\n",
            "Epoch [4360/10000], loss: 0.18962 acc: 0.98667 val_loss: 0.19176, val_acc: 0.96000\n",
            "Epoch [4370/10000], loss: 0.18940 acc: 0.98667 val_loss: 0.19156, val_acc: 0.96000\n",
            "Epoch [4380/10000], loss: 0.18918 acc: 0.98667 val_loss: 0.19137, val_acc: 0.96000\n",
            "Epoch [4390/10000], loss: 0.18897 acc: 0.98667 val_loss: 0.19118, val_acc: 0.96000\n",
            "Epoch [4400/10000], loss: 0.18875 acc: 0.98667 val_loss: 0.19098, val_acc: 0.96000\n",
            "Epoch [4410/10000], loss: 0.18853 acc: 0.98667 val_loss: 0.19079, val_acc: 0.96000\n",
            "Epoch [4420/10000], loss: 0.18832 acc: 0.98667 val_loss: 0.19060, val_acc: 0.96000\n",
            "Epoch [4430/10000], loss: 0.18811 acc: 0.98667 val_loss: 0.19041, val_acc: 0.96000\n",
            "Epoch [4440/10000], loss: 0.18789 acc: 0.98667 val_loss: 0.19021, val_acc: 0.96000\n",
            "Epoch [4450/10000], loss: 0.18768 acc: 0.98667 val_loss: 0.19002, val_acc: 0.96000\n",
            "Epoch [4460/10000], loss: 0.18747 acc: 0.98667 val_loss: 0.18984, val_acc: 0.96000\n",
            "Epoch [4470/10000], loss: 0.18726 acc: 0.98667 val_loss: 0.18965, val_acc: 0.96000\n",
            "Epoch [4480/10000], loss: 0.18705 acc: 0.98667 val_loss: 0.18946, val_acc: 0.96000\n",
            "Epoch [4490/10000], loss: 0.18684 acc: 0.98667 val_loss: 0.18927, val_acc: 0.96000\n",
            "Epoch [4500/10000], loss: 0.18663 acc: 0.98667 val_loss: 0.18908, val_acc: 0.96000\n",
            "Epoch [4510/10000], loss: 0.18642 acc: 0.98667 val_loss: 0.18890, val_acc: 0.96000\n",
            "Epoch [4520/10000], loss: 0.18622 acc: 0.98667 val_loss: 0.18871, val_acc: 0.96000\n",
            "Epoch [4530/10000], loss: 0.18601 acc: 0.98667 val_loss: 0.18853, val_acc: 0.96000\n",
            "Epoch [4540/10000], loss: 0.18580 acc: 0.98667 val_loss: 0.18834, val_acc: 0.96000\n",
            "Epoch [4550/10000], loss: 0.18560 acc: 0.98667 val_loss: 0.18816, val_acc: 0.96000\n",
            "Epoch [4560/10000], loss: 0.18539 acc: 0.98667 val_loss: 0.18798, val_acc: 0.96000\n",
            "Epoch [4570/10000], loss: 0.18519 acc: 0.98667 val_loss: 0.18780, val_acc: 0.96000\n",
            "Epoch [4580/10000], loss: 0.18499 acc: 0.98667 val_loss: 0.18762, val_acc: 0.96000\n",
            "Epoch [4590/10000], loss: 0.18478 acc: 0.98667 val_loss: 0.18743, val_acc: 0.96000\n",
            "Epoch [4600/10000], loss: 0.18458 acc: 0.98667 val_loss: 0.18725, val_acc: 0.96000\n",
            "Epoch [4610/10000], loss: 0.18438 acc: 0.98667 val_loss: 0.18707, val_acc: 0.96000\n",
            "Epoch [4620/10000], loss: 0.18418 acc: 0.98667 val_loss: 0.18690, val_acc: 0.96000\n",
            "Epoch [4630/10000], loss: 0.18398 acc: 0.98667 val_loss: 0.18672, val_acc: 0.96000\n",
            "Epoch [4640/10000], loss: 0.18378 acc: 0.98667 val_loss: 0.18654, val_acc: 0.96000\n",
            "Epoch [4650/10000], loss: 0.18358 acc: 0.98667 val_loss: 0.18636, val_acc: 0.96000\n",
            "Epoch [4660/10000], loss: 0.18339 acc: 0.98667 val_loss: 0.18619, val_acc: 0.96000\n",
            "Epoch [4670/10000], loss: 0.18319 acc: 0.98667 val_loss: 0.18601, val_acc: 0.96000\n",
            "Epoch [4680/10000], loss: 0.18299 acc: 0.98667 val_loss: 0.18583, val_acc: 0.96000\n",
            "Epoch [4690/10000], loss: 0.18280 acc: 0.98667 val_loss: 0.18566, val_acc: 0.96000\n",
            "Epoch [4700/10000], loss: 0.18260 acc: 0.98667 val_loss: 0.18549, val_acc: 0.96000\n",
            "Epoch [4710/10000], loss: 0.18241 acc: 0.98667 val_loss: 0.18531, val_acc: 0.96000\n",
            "Epoch [4720/10000], loss: 0.18221 acc: 0.98667 val_loss: 0.18514, val_acc: 0.96000\n",
            "Epoch [4730/10000], loss: 0.18202 acc: 0.98667 val_loss: 0.18497, val_acc: 0.96000\n",
            "Epoch [4740/10000], loss: 0.18183 acc: 0.98667 val_loss: 0.18479, val_acc: 0.96000\n",
            "Epoch [4750/10000], loss: 0.18164 acc: 0.98667 val_loss: 0.18462, val_acc: 0.96000\n",
            "Epoch [4760/10000], loss: 0.18144 acc: 0.98667 val_loss: 0.18445, val_acc: 0.96000\n",
            "Epoch [4770/10000], loss: 0.18125 acc: 0.98667 val_loss: 0.18428, val_acc: 0.96000\n",
            "Epoch [4780/10000], loss: 0.18106 acc: 0.98667 val_loss: 0.18411, val_acc: 0.96000\n",
            "Epoch [4790/10000], loss: 0.18087 acc: 0.98667 val_loss: 0.18395, val_acc: 0.96000\n",
            "Epoch [4800/10000], loss: 0.18068 acc: 0.98667 val_loss: 0.18378, val_acc: 0.96000\n",
            "Epoch [4810/10000], loss: 0.18050 acc: 0.98667 val_loss: 0.18361, val_acc: 0.96000\n",
            "Epoch [4820/10000], loss: 0.18031 acc: 0.98667 val_loss: 0.18344, val_acc: 0.96000\n",
            "Epoch [4830/10000], loss: 0.18012 acc: 0.98667 val_loss: 0.18328, val_acc: 0.96000\n",
            "Epoch [4840/10000], loss: 0.17994 acc: 0.98667 val_loss: 0.18311, val_acc: 0.96000\n",
            "Epoch [4850/10000], loss: 0.17975 acc: 0.98667 val_loss: 0.18294, val_acc: 0.96000\n",
            "Epoch [4860/10000], loss: 0.17956 acc: 0.98667 val_loss: 0.18278, val_acc: 0.96000\n",
            "Epoch [4870/10000], loss: 0.17938 acc: 0.98667 val_loss: 0.18261, val_acc: 0.96000\n",
            "Epoch [4880/10000], loss: 0.17920 acc: 0.98667 val_loss: 0.18245, val_acc: 0.96000\n",
            "Epoch [4890/10000], loss: 0.17901 acc: 0.98667 val_loss: 0.18229, val_acc: 0.96000\n",
            "Epoch [4900/10000], loss: 0.17883 acc: 0.98667 val_loss: 0.18212, val_acc: 0.96000\n",
            "Epoch [4910/10000], loss: 0.17865 acc: 0.98667 val_loss: 0.18196, val_acc: 0.96000\n",
            "Epoch [4920/10000], loss: 0.17846 acc: 0.98667 val_loss: 0.18180, val_acc: 0.96000\n",
            "Epoch [4930/10000], loss: 0.17828 acc: 0.98667 val_loss: 0.18164, val_acc: 0.96000\n",
            "Epoch [4940/10000], loss: 0.17810 acc: 0.98667 val_loss: 0.18148, val_acc: 0.96000\n",
            "Epoch [4950/10000], loss: 0.17792 acc: 0.98667 val_loss: 0.18132, val_acc: 0.96000\n",
            "Epoch [4960/10000], loss: 0.17774 acc: 0.98667 val_loss: 0.18116, val_acc: 0.96000\n",
            "Epoch [4970/10000], loss: 0.17756 acc: 0.98667 val_loss: 0.18100, val_acc: 0.96000\n",
            "Epoch [4980/10000], loss: 0.17739 acc: 0.98667 val_loss: 0.18084, val_acc: 0.96000\n",
            "Epoch [4990/10000], loss: 0.17721 acc: 0.98667 val_loss: 0.18068, val_acc: 0.96000\n",
            "Epoch [5000/10000], loss: 0.17703 acc: 0.98667 val_loss: 0.18053, val_acc: 0.96000\n",
            "Epoch [5010/10000], loss: 0.17685 acc: 0.98667 val_loss: 0.18037, val_acc: 0.96000\n",
            "Epoch [5020/10000], loss: 0.17668 acc: 0.98667 val_loss: 0.18021, val_acc: 0.96000\n",
            "Epoch [5030/10000], loss: 0.17650 acc: 0.98667 val_loss: 0.18006, val_acc: 0.96000\n",
            "Epoch [5040/10000], loss: 0.17633 acc: 0.98667 val_loss: 0.17990, val_acc: 0.96000\n",
            "Epoch [5050/10000], loss: 0.17615 acc: 0.98667 val_loss: 0.17975, val_acc: 0.96000\n",
            "Epoch [5060/10000], loss: 0.17598 acc: 0.98667 val_loss: 0.17959, val_acc: 0.96000\n",
            "Epoch [5070/10000], loss: 0.17581 acc: 0.98667 val_loss: 0.17944, val_acc: 0.96000\n",
            "Epoch [5080/10000], loss: 0.17563 acc: 0.98667 val_loss: 0.17928, val_acc: 0.96000\n",
            "Epoch [5090/10000], loss: 0.17546 acc: 0.98667 val_loss: 0.17913, val_acc: 0.96000\n",
            "Epoch [5100/10000], loss: 0.17529 acc: 0.98667 val_loss: 0.17898, val_acc: 0.96000\n",
            "Epoch [5110/10000], loss: 0.17512 acc: 0.98667 val_loss: 0.17883, val_acc: 0.96000\n",
            "Epoch [5120/10000], loss: 0.17495 acc: 0.98667 val_loss: 0.17867, val_acc: 0.96000\n",
            "Epoch [5130/10000], loss: 0.17478 acc: 0.98667 val_loss: 0.17852, val_acc: 0.96000\n",
            "Epoch [5140/10000], loss: 0.17461 acc: 0.98667 val_loss: 0.17837, val_acc: 0.96000\n",
            "Epoch [5150/10000], loss: 0.17444 acc: 0.98667 val_loss: 0.17822, val_acc: 0.96000\n",
            "Epoch [5160/10000], loss: 0.17427 acc: 0.98667 val_loss: 0.17807, val_acc: 0.96000\n",
            "Epoch [5170/10000], loss: 0.17410 acc: 0.98667 val_loss: 0.17792, val_acc: 0.96000\n",
            "Epoch [5180/10000], loss: 0.17393 acc: 0.98667 val_loss: 0.17778, val_acc: 0.96000\n",
            "Epoch [5190/10000], loss: 0.17377 acc: 0.98667 val_loss: 0.17763, val_acc: 0.96000\n",
            "Epoch [5200/10000], loss: 0.17360 acc: 0.98667 val_loss: 0.17748, val_acc: 0.96000\n",
            "Epoch [5210/10000], loss: 0.17343 acc: 0.98667 val_loss: 0.17733, val_acc: 0.96000\n",
            "Epoch [5220/10000], loss: 0.17327 acc: 0.98667 val_loss: 0.17719, val_acc: 0.96000\n",
            "Epoch [5230/10000], loss: 0.17310 acc: 0.98667 val_loss: 0.17704, val_acc: 0.96000\n",
            "Epoch [5240/10000], loss: 0.17294 acc: 0.98667 val_loss: 0.17689, val_acc: 0.96000\n",
            "Epoch [5250/10000], loss: 0.17277 acc: 0.98667 val_loss: 0.17675, val_acc: 0.96000\n",
            "Epoch [5260/10000], loss: 0.17261 acc: 0.98667 val_loss: 0.17660, val_acc: 0.96000\n",
            "Epoch [5270/10000], loss: 0.17245 acc: 0.98667 val_loss: 0.17646, val_acc: 0.96000\n",
            "Epoch [5280/10000], loss: 0.17229 acc: 0.98667 val_loss: 0.17631, val_acc: 0.96000\n",
            "Epoch [5290/10000], loss: 0.17212 acc: 0.98667 val_loss: 0.17617, val_acc: 0.96000\n",
            "Epoch [5300/10000], loss: 0.17196 acc: 0.98667 val_loss: 0.17603, val_acc: 0.96000\n",
            "Epoch [5310/10000], loss: 0.17180 acc: 0.98667 val_loss: 0.17589, val_acc: 0.96000\n",
            "Epoch [5320/10000], loss: 0.17164 acc: 0.98667 val_loss: 0.17574, val_acc: 0.96000\n",
            "Epoch [5330/10000], loss: 0.17148 acc: 0.98667 val_loss: 0.17560, val_acc: 0.96000\n",
            "Epoch [5340/10000], loss: 0.17132 acc: 0.98667 val_loss: 0.17546, val_acc: 0.96000\n",
            "Epoch [5350/10000], loss: 0.17116 acc: 0.98667 val_loss: 0.17532, val_acc: 0.96000\n",
            "Epoch [5360/10000], loss: 0.17100 acc: 0.98667 val_loss: 0.17518, val_acc: 0.96000\n",
            "Epoch [5370/10000], loss: 0.17084 acc: 0.98667 val_loss: 0.17504, val_acc: 0.96000\n",
            "Epoch [5380/10000], loss: 0.17068 acc: 0.98667 val_loss: 0.17490, val_acc: 0.96000\n",
            "Epoch [5390/10000], loss: 0.17053 acc: 0.98667 val_loss: 0.17476, val_acc: 0.96000\n",
            "Epoch [5400/10000], loss: 0.17037 acc: 0.98667 val_loss: 0.17462, val_acc: 0.96000\n",
            "Epoch [5410/10000], loss: 0.17021 acc: 0.98667 val_loss: 0.17448, val_acc: 0.96000\n",
            "Epoch [5420/10000], loss: 0.17006 acc: 0.98667 val_loss: 0.17434, val_acc: 0.96000\n",
            "Epoch [5430/10000], loss: 0.16990 acc: 0.98667 val_loss: 0.17421, val_acc: 0.96000\n",
            "Epoch [5440/10000], loss: 0.16975 acc: 0.98667 val_loss: 0.17407, val_acc: 0.96000\n",
            "Epoch [5450/10000], loss: 0.16959 acc: 0.98667 val_loss: 0.17393, val_acc: 0.96000\n",
            "Epoch [5460/10000], loss: 0.16944 acc: 0.98667 val_loss: 0.17380, val_acc: 0.96000\n",
            "Epoch [5470/10000], loss: 0.16928 acc: 0.98667 val_loss: 0.17366, val_acc: 0.96000\n",
            "Epoch [5480/10000], loss: 0.16913 acc: 0.98667 val_loss: 0.17352, val_acc: 0.96000\n",
            "Epoch [5490/10000], loss: 0.16898 acc: 0.98667 val_loss: 0.17339, val_acc: 0.96000\n",
            "Epoch [5500/10000], loss: 0.16883 acc: 0.98667 val_loss: 0.17325, val_acc: 0.96000\n",
            "Epoch [5510/10000], loss: 0.16867 acc: 0.98667 val_loss: 0.17312, val_acc: 0.96000\n",
            "Epoch [5520/10000], loss: 0.16852 acc: 0.98667 val_loss: 0.17299, val_acc: 0.96000\n",
            "Epoch [5530/10000], loss: 0.16837 acc: 0.98667 val_loss: 0.17285, val_acc: 0.96000\n",
            "Epoch [5540/10000], loss: 0.16822 acc: 0.98667 val_loss: 0.17272, val_acc: 0.96000\n",
            "Epoch [5550/10000], loss: 0.16807 acc: 0.98667 val_loss: 0.17259, val_acc: 0.96000\n",
            "Epoch [5560/10000], loss: 0.16792 acc: 0.98667 val_loss: 0.17246, val_acc: 0.96000\n",
            "Epoch [5570/10000], loss: 0.16777 acc: 0.98667 val_loss: 0.17232, val_acc: 0.96000\n",
            "Epoch [5580/10000], loss: 0.16762 acc: 0.98667 val_loss: 0.17219, val_acc: 0.96000\n",
            "Epoch [5590/10000], loss: 0.16747 acc: 0.98667 val_loss: 0.17206, val_acc: 0.96000\n",
            "Epoch [5600/10000], loss: 0.16732 acc: 0.98667 val_loss: 0.17193, val_acc: 0.96000\n",
            "Epoch [5610/10000], loss: 0.16718 acc: 0.98667 val_loss: 0.17180, val_acc: 0.96000\n",
            "Epoch [5620/10000], loss: 0.16703 acc: 0.98667 val_loss: 0.17167, val_acc: 0.96000\n",
            "Epoch [5630/10000], loss: 0.16688 acc: 0.98667 val_loss: 0.17154, val_acc: 0.96000\n",
            "Epoch [5640/10000], loss: 0.16674 acc: 0.98667 val_loss: 0.17141, val_acc: 0.96000\n",
            "Epoch [5650/10000], loss: 0.16659 acc: 0.98667 val_loss: 0.17128, val_acc: 0.96000\n",
            "Epoch [5660/10000], loss: 0.16644 acc: 0.98667 val_loss: 0.17115, val_acc: 0.96000\n",
            "Epoch [5670/10000], loss: 0.16630 acc: 0.98667 val_loss: 0.17103, val_acc: 0.96000\n",
            "Epoch [5680/10000], loss: 0.16615 acc: 0.98667 val_loss: 0.17090, val_acc: 0.96000\n",
            "Epoch [5690/10000], loss: 0.16601 acc: 0.98667 val_loss: 0.17077, val_acc: 0.96000\n",
            "Epoch [5700/10000], loss: 0.16587 acc: 0.98667 val_loss: 0.17064, val_acc: 0.96000\n",
            "Epoch [5710/10000], loss: 0.16572 acc: 0.98667 val_loss: 0.17052, val_acc: 0.96000\n",
            "Epoch [5720/10000], loss: 0.16558 acc: 0.98667 val_loss: 0.17039, val_acc: 0.96000\n",
            "Epoch [5730/10000], loss: 0.16544 acc: 0.98667 val_loss: 0.17027, val_acc: 0.96000\n",
            "Epoch [5740/10000], loss: 0.16529 acc: 0.98667 val_loss: 0.17014, val_acc: 0.96000\n",
            "Epoch [5750/10000], loss: 0.16515 acc: 0.98667 val_loss: 0.17001, val_acc: 0.96000\n",
            "Epoch [5760/10000], loss: 0.16501 acc: 0.98667 val_loss: 0.16989, val_acc: 0.96000\n",
            "Epoch [5770/10000], loss: 0.16487 acc: 0.98667 val_loss: 0.16977, val_acc: 0.96000\n",
            "Epoch [5780/10000], loss: 0.16473 acc: 0.98667 val_loss: 0.16964, val_acc: 0.96000\n",
            "Epoch [5790/10000], loss: 0.16459 acc: 0.98667 val_loss: 0.16952, val_acc: 0.96000\n",
            "Epoch [5800/10000], loss: 0.16445 acc: 0.98667 val_loss: 0.16939, val_acc: 0.96000\n",
            "Epoch [5810/10000], loss: 0.16431 acc: 0.98667 val_loss: 0.16927, val_acc: 0.96000\n",
            "Epoch [5820/10000], loss: 0.16417 acc: 0.98667 val_loss: 0.16915, val_acc: 0.96000\n",
            "Epoch [5830/10000], loss: 0.16403 acc: 0.98667 val_loss: 0.16903, val_acc: 0.96000\n",
            "Epoch [5840/10000], loss: 0.16389 acc: 0.98667 val_loss: 0.16891, val_acc: 0.96000\n",
            "Epoch [5850/10000], loss: 0.16375 acc: 0.98667 val_loss: 0.16878, val_acc: 0.96000\n",
            "Epoch [5860/10000], loss: 0.16361 acc: 0.98667 val_loss: 0.16866, val_acc: 0.96000\n",
            "Epoch [5870/10000], loss: 0.16348 acc: 0.98667 val_loss: 0.16854, val_acc: 0.96000\n",
            "Epoch [5880/10000], loss: 0.16334 acc: 0.98667 val_loss: 0.16842, val_acc: 0.96000\n",
            "Epoch [5890/10000], loss: 0.16320 acc: 0.98667 val_loss: 0.16830, val_acc: 0.96000\n",
            "Epoch [5900/10000], loss: 0.16307 acc: 0.98667 val_loss: 0.16818, val_acc: 0.96000\n",
            "Epoch [5910/10000], loss: 0.16293 acc: 0.98667 val_loss: 0.16806, val_acc: 0.96000\n",
            "Epoch [5920/10000], loss: 0.16280 acc: 0.98667 val_loss: 0.16794, val_acc: 0.96000\n",
            "Epoch [5930/10000], loss: 0.16266 acc: 0.98667 val_loss: 0.16782, val_acc: 0.96000\n",
            "Epoch [5940/10000], loss: 0.16253 acc: 0.98667 val_loss: 0.16771, val_acc: 0.96000\n",
            "Epoch [5950/10000], loss: 0.16239 acc: 0.98667 val_loss: 0.16759, val_acc: 0.96000\n",
            "Epoch [5960/10000], loss: 0.16226 acc: 0.98667 val_loss: 0.16747, val_acc: 0.96000\n",
            "Epoch [5970/10000], loss: 0.16212 acc: 0.98667 val_loss: 0.16735, val_acc: 0.96000\n",
            "Epoch [5980/10000], loss: 0.16199 acc: 0.98667 val_loss: 0.16724, val_acc: 0.96000\n",
            "Epoch [5990/10000], loss: 0.16186 acc: 0.98667 val_loss: 0.16712, val_acc: 0.96000\n",
            "Epoch [6000/10000], loss: 0.16172 acc: 0.98667 val_loss: 0.16700, val_acc: 0.96000\n",
            "Epoch [6010/10000], loss: 0.16159 acc: 0.98667 val_loss: 0.16689, val_acc: 0.96000\n",
            "Epoch [6020/10000], loss: 0.16146 acc: 0.98667 val_loss: 0.16677, val_acc: 0.96000\n",
            "Epoch [6030/10000], loss: 0.16133 acc: 0.98667 val_loss: 0.16665, val_acc: 0.96000\n",
            "Epoch [6040/10000], loss: 0.16120 acc: 0.98667 val_loss: 0.16654, val_acc: 0.96000\n",
            "Epoch [6050/10000], loss: 0.16107 acc: 0.98667 val_loss: 0.16642, val_acc: 0.96000\n",
            "Epoch [6060/10000], loss: 0.16094 acc: 0.98667 val_loss: 0.16631, val_acc: 0.96000\n",
            "Epoch [6070/10000], loss: 0.16080 acc: 0.98667 val_loss: 0.16620, val_acc: 0.96000\n",
            "Epoch [6080/10000], loss: 0.16067 acc: 0.98667 val_loss: 0.16608, val_acc: 0.96000\n",
            "Epoch [6090/10000], loss: 0.16055 acc: 0.98667 val_loss: 0.16597, val_acc: 0.96000\n",
            "Epoch [6100/10000], loss: 0.16042 acc: 0.98667 val_loss: 0.16585, val_acc: 0.96000\n",
            "Epoch [6110/10000], loss: 0.16029 acc: 0.98667 val_loss: 0.16574, val_acc: 0.96000\n",
            "Epoch [6120/10000], loss: 0.16016 acc: 0.98667 val_loss: 0.16563, val_acc: 0.96000\n",
            "Epoch [6130/10000], loss: 0.16003 acc: 0.98667 val_loss: 0.16552, val_acc: 0.96000\n",
            "Epoch [6140/10000], loss: 0.15990 acc: 0.98667 val_loss: 0.16540, val_acc: 0.96000\n",
            "Epoch [6150/10000], loss: 0.15978 acc: 0.98667 val_loss: 0.16529, val_acc: 0.96000\n",
            "Epoch [6160/10000], loss: 0.15965 acc: 0.98667 val_loss: 0.16518, val_acc: 0.96000\n",
            "Epoch [6170/10000], loss: 0.15952 acc: 0.98667 val_loss: 0.16507, val_acc: 0.96000\n",
            "Epoch [6180/10000], loss: 0.15939 acc: 0.98667 val_loss: 0.16496, val_acc: 0.96000\n",
            "Epoch [6190/10000], loss: 0.15927 acc: 0.98667 val_loss: 0.16485, val_acc: 0.96000\n",
            "Epoch [6200/10000], loss: 0.15914 acc: 0.98667 val_loss: 0.16474, val_acc: 0.96000\n",
            "Epoch [6210/10000], loss: 0.15902 acc: 0.98667 val_loss: 0.16463, val_acc: 0.96000\n",
            "Epoch [6220/10000], loss: 0.15889 acc: 0.98667 val_loss: 0.16452, val_acc: 0.96000\n",
            "Epoch [6230/10000], loss: 0.15877 acc: 0.98667 val_loss: 0.16441, val_acc: 0.96000\n",
            "Epoch [6240/10000], loss: 0.15864 acc: 0.98667 val_loss: 0.16430, val_acc: 0.96000\n",
            "Epoch [6250/10000], loss: 0.15852 acc: 0.98667 val_loss: 0.16419, val_acc: 0.96000\n",
            "Epoch [6260/10000], loss: 0.15839 acc: 0.98667 val_loss: 0.16408, val_acc: 0.96000\n",
            "Epoch [6270/10000], loss: 0.15827 acc: 0.98667 val_loss: 0.16398, val_acc: 0.96000\n",
            "Epoch [6280/10000], loss: 0.15815 acc: 0.98667 val_loss: 0.16387, val_acc: 0.96000\n",
            "Epoch [6290/10000], loss: 0.15802 acc: 0.98667 val_loss: 0.16376, val_acc: 0.96000\n",
            "Epoch [6300/10000], loss: 0.15790 acc: 0.98667 val_loss: 0.16365, val_acc: 0.96000\n",
            "Epoch [6310/10000], loss: 0.15778 acc: 0.98667 val_loss: 0.16355, val_acc: 0.96000\n",
            "Epoch [6320/10000], loss: 0.15766 acc: 0.98667 val_loss: 0.16344, val_acc: 0.96000\n",
            "Epoch [6330/10000], loss: 0.15754 acc: 0.98667 val_loss: 0.16333, val_acc: 0.96000\n",
            "Epoch [6340/10000], loss: 0.15741 acc: 0.98667 val_loss: 0.16323, val_acc: 0.96000\n",
            "Epoch [6350/10000], loss: 0.15729 acc: 0.98667 val_loss: 0.16312, val_acc: 0.96000\n",
            "Epoch [6360/10000], loss: 0.15717 acc: 0.98667 val_loss: 0.16302, val_acc: 0.96000\n",
            "Epoch [6370/10000], loss: 0.15705 acc: 0.98667 val_loss: 0.16291, val_acc: 0.96000\n",
            "Epoch [6380/10000], loss: 0.15693 acc: 0.98667 val_loss: 0.16281, val_acc: 0.96000\n",
            "Epoch [6390/10000], loss: 0.15681 acc: 0.98667 val_loss: 0.16270, val_acc: 0.96000\n",
            "Epoch [6400/10000], loss: 0.15669 acc: 0.98667 val_loss: 0.16260, val_acc: 0.96000\n",
            "Epoch [6410/10000], loss: 0.15657 acc: 0.98667 val_loss: 0.16249, val_acc: 0.96000\n",
            "Epoch [6420/10000], loss: 0.15645 acc: 0.98667 val_loss: 0.16239, val_acc: 0.96000\n",
            "Epoch [6430/10000], loss: 0.15634 acc: 0.98667 val_loss: 0.16228, val_acc: 0.96000\n",
            "Epoch [6440/10000], loss: 0.15622 acc: 0.98667 val_loss: 0.16218, val_acc: 0.96000\n",
            "Epoch [6450/10000], loss: 0.15610 acc: 0.98667 val_loss: 0.16208, val_acc: 0.96000\n",
            "Epoch [6460/10000], loss: 0.15598 acc: 0.98667 val_loss: 0.16198, val_acc: 0.96000\n",
            "Epoch [6470/10000], loss: 0.15586 acc: 0.98667 val_loss: 0.16187, val_acc: 0.96000\n",
            "Epoch [6480/10000], loss: 0.15575 acc: 0.98667 val_loss: 0.16177, val_acc: 0.96000\n",
            "Epoch [6490/10000], loss: 0.15563 acc: 0.98667 val_loss: 0.16167, val_acc: 0.96000\n",
            "Epoch [6500/10000], loss: 0.15551 acc: 0.98667 val_loss: 0.16157, val_acc: 0.96000\n",
            "Epoch [6510/10000], loss: 0.15540 acc: 0.98667 val_loss: 0.16147, val_acc: 0.96000\n",
            "Epoch [6520/10000], loss: 0.15528 acc: 0.98667 val_loss: 0.16136, val_acc: 0.96000\n",
            "Epoch [6530/10000], loss: 0.15516 acc: 0.98667 val_loss: 0.16126, val_acc: 0.96000\n",
            "Epoch [6540/10000], loss: 0.15505 acc: 0.98667 val_loss: 0.16116, val_acc: 0.96000\n",
            "Epoch [6550/10000], loss: 0.15493 acc: 0.98667 val_loss: 0.16106, val_acc: 0.96000\n",
            "Epoch [6560/10000], loss: 0.15482 acc: 0.98667 val_loss: 0.16096, val_acc: 0.96000\n",
            "Epoch [6570/10000], loss: 0.15470 acc: 0.98667 val_loss: 0.16086, val_acc: 0.96000\n",
            "Epoch [6580/10000], loss: 0.15459 acc: 0.98667 val_loss: 0.16076, val_acc: 0.96000\n",
            "Epoch [6590/10000], loss: 0.15448 acc: 0.98667 val_loss: 0.16066, val_acc: 0.96000\n",
            "Epoch [6600/10000], loss: 0.15436 acc: 0.98667 val_loss: 0.16056, val_acc: 0.96000\n",
            "Epoch [6610/10000], loss: 0.15425 acc: 0.98667 val_loss: 0.16047, val_acc: 0.96000\n",
            "Epoch [6620/10000], loss: 0.15414 acc: 0.98667 val_loss: 0.16037, val_acc: 0.96000\n",
            "Epoch [6630/10000], loss: 0.15402 acc: 0.98667 val_loss: 0.16027, val_acc: 0.96000\n",
            "Epoch [6640/10000], loss: 0.15391 acc: 0.98667 val_loss: 0.16017, val_acc: 0.96000\n",
            "Epoch [6650/10000], loss: 0.15380 acc: 0.98667 val_loss: 0.16007, val_acc: 0.96000\n",
            "Epoch [6660/10000], loss: 0.15369 acc: 0.98667 val_loss: 0.15998, val_acc: 0.96000\n",
            "Epoch [6670/10000], loss: 0.15357 acc: 0.98667 val_loss: 0.15988, val_acc: 0.96000\n",
            "Epoch [6680/10000], loss: 0.15346 acc: 0.98667 val_loss: 0.15978, val_acc: 0.96000\n",
            "Epoch [6690/10000], loss: 0.15335 acc: 0.98667 val_loss: 0.15968, val_acc: 0.96000\n",
            "Epoch [6700/10000], loss: 0.15324 acc: 0.98667 val_loss: 0.15959, val_acc: 0.96000\n",
            "Epoch [6710/10000], loss: 0.15313 acc: 0.98667 val_loss: 0.15949, val_acc: 0.96000\n",
            "Epoch [6720/10000], loss: 0.15302 acc: 0.98667 val_loss: 0.15939, val_acc: 0.96000\n",
            "Epoch [6730/10000], loss: 0.15291 acc: 0.98667 val_loss: 0.15930, val_acc: 0.96000\n",
            "Epoch [6740/10000], loss: 0.15280 acc: 0.98667 val_loss: 0.15920, val_acc: 0.96000\n",
            "Epoch [6750/10000], loss: 0.15269 acc: 0.98667 val_loss: 0.15911, val_acc: 0.96000\n",
            "Epoch [6760/10000], loss: 0.15258 acc: 0.98667 val_loss: 0.15901, val_acc: 0.96000\n",
            "Epoch [6770/10000], loss: 0.15247 acc: 0.98667 val_loss: 0.15892, val_acc: 0.96000\n",
            "Epoch [6780/10000], loss: 0.15236 acc: 0.98667 val_loss: 0.15882, val_acc: 0.96000\n",
            "Epoch [6790/10000], loss: 0.15225 acc: 0.98667 val_loss: 0.15873, val_acc: 0.96000\n",
            "Epoch [6800/10000], loss: 0.15215 acc: 0.98667 val_loss: 0.15863, val_acc: 0.96000\n",
            "Epoch [6810/10000], loss: 0.15204 acc: 0.98667 val_loss: 0.15854, val_acc: 0.96000\n",
            "Epoch [6820/10000], loss: 0.15193 acc: 0.98667 val_loss: 0.15845, val_acc: 0.96000\n",
            "Epoch [6830/10000], loss: 0.15182 acc: 0.98667 val_loss: 0.15835, val_acc: 0.96000\n",
            "Epoch [6840/10000], loss: 0.15171 acc: 0.98667 val_loss: 0.15826, val_acc: 0.96000\n",
            "Epoch [6850/10000], loss: 0.15161 acc: 0.98667 val_loss: 0.15817, val_acc: 0.96000\n",
            "Epoch [6860/10000], loss: 0.15150 acc: 0.98667 val_loss: 0.15807, val_acc: 0.96000\n",
            "Epoch [6870/10000], loss: 0.15139 acc: 0.98667 val_loss: 0.15798, val_acc: 0.96000\n",
            "Epoch [6880/10000], loss: 0.15129 acc: 0.98667 val_loss: 0.15789, val_acc: 0.96000\n",
            "Epoch [6890/10000], loss: 0.15118 acc: 0.98667 val_loss: 0.15780, val_acc: 0.96000\n",
            "Epoch [6900/10000], loss: 0.15108 acc: 0.98667 val_loss: 0.15771, val_acc: 0.96000\n",
            "Epoch [6910/10000], loss: 0.15097 acc: 0.98667 val_loss: 0.15761, val_acc: 0.96000\n",
            "Epoch [6920/10000], loss: 0.15086 acc: 0.98667 val_loss: 0.15752, val_acc: 0.96000\n",
            "Epoch [6930/10000], loss: 0.15076 acc: 0.98667 val_loss: 0.15743, val_acc: 0.96000\n",
            "Epoch [6940/10000], loss: 0.15065 acc: 0.98667 val_loss: 0.15734, val_acc: 0.96000\n",
            "Epoch [6950/10000], loss: 0.15055 acc: 0.98667 val_loss: 0.15725, val_acc: 0.96000\n",
            "Epoch [6960/10000], loss: 0.15045 acc: 0.98667 val_loss: 0.15716, val_acc: 0.96000\n",
            "Epoch [6970/10000], loss: 0.15034 acc: 0.98667 val_loss: 0.15707, val_acc: 0.96000\n",
            "Epoch [6980/10000], loss: 0.15024 acc: 0.98667 val_loss: 0.15698, val_acc: 0.96000\n",
            "Epoch [6990/10000], loss: 0.15013 acc: 0.98667 val_loss: 0.15689, val_acc: 0.96000\n",
            "Epoch [7000/10000], loss: 0.15003 acc: 0.98667 val_loss: 0.15680, val_acc: 0.96000\n",
            "Epoch [7010/10000], loss: 0.14993 acc: 0.98667 val_loss: 0.15671, val_acc: 0.96000\n",
            "Epoch [7020/10000], loss: 0.14983 acc: 0.98667 val_loss: 0.15662, val_acc: 0.96000\n",
            "Epoch [7030/10000], loss: 0.14972 acc: 0.98667 val_loss: 0.15653, val_acc: 0.96000\n",
            "Epoch [7040/10000], loss: 0.14962 acc: 0.98667 val_loss: 0.15644, val_acc: 0.96000\n",
            "Epoch [7050/10000], loss: 0.14952 acc: 0.98667 val_loss: 0.15636, val_acc: 0.96000\n",
            "Epoch [7060/10000], loss: 0.14942 acc: 0.98667 val_loss: 0.15627, val_acc: 0.96000\n",
            "Epoch [7070/10000], loss: 0.14931 acc: 0.98667 val_loss: 0.15618, val_acc: 0.96000\n",
            "Epoch [7080/10000], loss: 0.14921 acc: 0.98667 val_loss: 0.15609, val_acc: 0.96000\n",
            "Epoch [7090/10000], loss: 0.14911 acc: 0.98667 val_loss: 0.15600, val_acc: 0.96000\n",
            "Epoch [7100/10000], loss: 0.14901 acc: 0.98667 val_loss: 0.15592, val_acc: 0.96000\n",
            "Epoch [7110/10000], loss: 0.14891 acc: 0.98667 val_loss: 0.15583, val_acc: 0.96000\n",
            "Epoch [7120/10000], loss: 0.14881 acc: 0.98667 val_loss: 0.15574, val_acc: 0.96000\n",
            "Epoch [7130/10000], loss: 0.14871 acc: 0.98667 val_loss: 0.15565, val_acc: 0.96000\n",
            "Epoch [7140/10000], loss: 0.14861 acc: 0.98667 val_loss: 0.15557, val_acc: 0.96000\n",
            "Epoch [7150/10000], loss: 0.14851 acc: 0.98667 val_loss: 0.15548, val_acc: 0.96000\n",
            "Epoch [7160/10000], loss: 0.14841 acc: 0.98667 val_loss: 0.15540, val_acc: 0.96000\n",
            "Epoch [7170/10000], loss: 0.14831 acc: 0.98667 val_loss: 0.15531, val_acc: 0.96000\n",
            "Epoch [7180/10000], loss: 0.14821 acc: 0.98667 val_loss: 0.15522, val_acc: 0.96000\n",
            "Epoch [7190/10000], loss: 0.14811 acc: 0.98667 val_loss: 0.15514, val_acc: 0.96000\n",
            "Epoch [7200/10000], loss: 0.14801 acc: 0.98667 val_loss: 0.15505, val_acc: 0.96000\n",
            "Epoch [7210/10000], loss: 0.14792 acc: 0.98667 val_loss: 0.15497, val_acc: 0.96000\n",
            "Epoch [7220/10000], loss: 0.14782 acc: 0.98667 val_loss: 0.15488, val_acc: 0.96000\n",
            "Epoch [7230/10000], loss: 0.14772 acc: 0.98667 val_loss: 0.15480, val_acc: 0.96000\n",
            "Epoch [7240/10000], loss: 0.14762 acc: 0.98667 val_loss: 0.15471, val_acc: 0.96000\n",
            "Epoch [7250/10000], loss: 0.14752 acc: 0.98667 val_loss: 0.15463, val_acc: 0.96000\n",
            "Epoch [7260/10000], loss: 0.14743 acc: 0.98667 val_loss: 0.15455, val_acc: 0.96000\n",
            "Epoch [7270/10000], loss: 0.14733 acc: 0.98667 val_loss: 0.15446, val_acc: 0.96000\n",
            "Epoch [7280/10000], loss: 0.14723 acc: 0.98667 val_loss: 0.15438, val_acc: 0.96000\n",
            "Epoch [7290/10000], loss: 0.14714 acc: 0.98667 val_loss: 0.15429, val_acc: 0.96000\n",
            "Epoch [7300/10000], loss: 0.14704 acc: 0.98667 val_loss: 0.15421, val_acc: 0.96000\n",
            "Epoch [7310/10000], loss: 0.14694 acc: 0.98667 val_loss: 0.15413, val_acc: 0.96000\n",
            "Epoch [7320/10000], loss: 0.14685 acc: 0.98667 val_loss: 0.15404, val_acc: 0.96000\n",
            "Epoch [7330/10000], loss: 0.14675 acc: 0.98667 val_loss: 0.15396, val_acc: 0.96000\n",
            "Epoch [7340/10000], loss: 0.14666 acc: 0.98667 val_loss: 0.15388, val_acc: 0.96000\n",
            "Epoch [7350/10000], loss: 0.14656 acc: 0.98667 val_loss: 0.15380, val_acc: 0.96000\n",
            "Epoch [7360/10000], loss: 0.14646 acc: 0.98667 val_loss: 0.15371, val_acc: 0.96000\n",
            "Epoch [7370/10000], loss: 0.14637 acc: 0.98667 val_loss: 0.15363, val_acc: 0.96000\n",
            "Epoch [7380/10000], loss: 0.14627 acc: 0.98667 val_loss: 0.15355, val_acc: 0.96000\n",
            "Epoch [7390/10000], loss: 0.14618 acc: 0.98667 val_loss: 0.15347, val_acc: 0.96000\n",
            "Epoch [7400/10000], loss: 0.14609 acc: 0.98667 val_loss: 0.15339, val_acc: 0.96000\n",
            "Epoch [7410/10000], loss: 0.14599 acc: 0.98667 val_loss: 0.15331, val_acc: 0.96000\n",
            "Epoch [7420/10000], loss: 0.14590 acc: 0.98667 val_loss: 0.15323, val_acc: 0.96000\n",
            "Epoch [7430/10000], loss: 0.14580 acc: 0.98667 val_loss: 0.15314, val_acc: 0.96000\n",
            "Epoch [7440/10000], loss: 0.14571 acc: 0.98667 val_loss: 0.15306, val_acc: 0.96000\n",
            "Epoch [7450/10000], loss: 0.14562 acc: 0.98667 val_loss: 0.15298, val_acc: 0.96000\n",
            "Epoch [7460/10000], loss: 0.14552 acc: 0.98667 val_loss: 0.15290, val_acc: 0.96000\n",
            "Epoch [7470/10000], loss: 0.14543 acc: 0.98667 val_loss: 0.15282, val_acc: 0.96000\n",
            "Epoch [7480/10000], loss: 0.14534 acc: 0.98667 val_loss: 0.15274, val_acc: 0.96000\n",
            "Epoch [7490/10000], loss: 0.14525 acc: 0.98667 val_loss: 0.15266, val_acc: 0.96000\n",
            "Epoch [7500/10000], loss: 0.14515 acc: 0.98667 val_loss: 0.15258, val_acc: 0.96000\n",
            "Epoch [7510/10000], loss: 0.14506 acc: 0.98667 val_loss: 0.15250, val_acc: 0.96000\n",
            "Epoch [7520/10000], loss: 0.14497 acc: 0.98667 val_loss: 0.15243, val_acc: 0.96000\n",
            "Epoch [7530/10000], loss: 0.14488 acc: 0.98667 val_loss: 0.15235, val_acc: 0.96000\n",
            "Epoch [7540/10000], loss: 0.14479 acc: 0.98667 val_loss: 0.15227, val_acc: 0.96000\n",
            "Epoch [7550/10000], loss: 0.14470 acc: 0.98667 val_loss: 0.15219, val_acc: 0.96000\n",
            "Epoch [7560/10000], loss: 0.14460 acc: 0.98667 val_loss: 0.15211, val_acc: 0.96000\n",
            "Epoch [7570/10000], loss: 0.14451 acc: 0.98667 val_loss: 0.15203, val_acc: 0.96000\n",
            "Epoch [7580/10000], loss: 0.14442 acc: 0.98667 val_loss: 0.15195, val_acc: 0.96000\n",
            "Epoch [7590/10000], loss: 0.14433 acc: 0.98667 val_loss: 0.15188, val_acc: 0.96000\n",
            "Epoch [7600/10000], loss: 0.14424 acc: 0.98667 val_loss: 0.15180, val_acc: 0.96000\n",
            "Epoch [7610/10000], loss: 0.14415 acc: 0.98667 val_loss: 0.15172, val_acc: 0.96000\n",
            "Epoch [7620/10000], loss: 0.14406 acc: 0.98667 val_loss: 0.15164, val_acc: 0.96000\n",
            "Epoch [7630/10000], loss: 0.14397 acc: 0.98667 val_loss: 0.15157, val_acc: 0.96000\n",
            "Epoch [7640/10000], loss: 0.14388 acc: 0.98667 val_loss: 0.15149, val_acc: 0.96000\n",
            "Epoch [7650/10000], loss: 0.14379 acc: 0.98667 val_loss: 0.15141, val_acc: 0.96000\n",
            "Epoch [7660/10000], loss: 0.14370 acc: 0.98667 val_loss: 0.15134, val_acc: 0.96000\n",
            "Epoch [7670/10000], loss: 0.14362 acc: 0.98667 val_loss: 0.15126, val_acc: 0.96000\n",
            "Epoch [7680/10000], loss: 0.14353 acc: 0.98667 val_loss: 0.15118, val_acc: 0.96000\n",
            "Epoch [7690/10000], loss: 0.14344 acc: 0.98667 val_loss: 0.15111, val_acc: 0.96000\n",
            "Epoch [7700/10000], loss: 0.14335 acc: 0.98667 val_loss: 0.15103, val_acc: 0.96000\n",
            "Epoch [7710/10000], loss: 0.14326 acc: 0.98667 val_loss: 0.15096, val_acc: 0.96000\n",
            "Epoch [7720/10000], loss: 0.14317 acc: 0.98667 val_loss: 0.15088, val_acc: 0.96000\n",
            "Epoch [7730/10000], loss: 0.14309 acc: 0.98667 val_loss: 0.15080, val_acc: 0.96000\n",
            "Epoch [7740/10000], loss: 0.14300 acc: 0.98667 val_loss: 0.15073, val_acc: 0.96000\n",
            "Epoch [7750/10000], loss: 0.14291 acc: 0.98667 val_loss: 0.15065, val_acc: 0.96000\n",
            "Epoch [7760/10000], loss: 0.14282 acc: 0.98667 val_loss: 0.15058, val_acc: 0.96000\n",
            "Epoch [7770/10000], loss: 0.14274 acc: 0.98667 val_loss: 0.15050, val_acc: 0.96000\n",
            "Epoch [7780/10000], loss: 0.14265 acc: 0.98667 val_loss: 0.15043, val_acc: 0.96000\n",
            "Epoch [7790/10000], loss: 0.14256 acc: 0.98667 val_loss: 0.15036, val_acc: 0.96000\n",
            "Epoch [7800/10000], loss: 0.14248 acc: 0.98667 val_loss: 0.15028, val_acc: 0.96000\n",
            "Epoch [7810/10000], loss: 0.14239 acc: 0.98667 val_loss: 0.15021, val_acc: 0.96000\n",
            "Epoch [7820/10000], loss: 0.14230 acc: 0.98667 val_loss: 0.15013, val_acc: 0.96000\n",
            "Epoch [7830/10000], loss: 0.14222 acc: 0.98667 val_loss: 0.15006, val_acc: 0.96000\n",
            "Epoch [7840/10000], loss: 0.14213 acc: 0.98667 val_loss: 0.14999, val_acc: 0.96000\n",
            "Epoch [7850/10000], loss: 0.14205 acc: 0.98667 val_loss: 0.14991, val_acc: 0.96000\n",
            "Epoch [7860/10000], loss: 0.14196 acc: 0.98667 val_loss: 0.14984, val_acc: 0.96000\n",
            "Epoch [7870/10000], loss: 0.14188 acc: 0.98667 val_loss: 0.14977, val_acc: 0.96000\n",
            "Epoch [7880/10000], loss: 0.14179 acc: 0.98667 val_loss: 0.14969, val_acc: 0.96000\n",
            "Epoch [7890/10000], loss: 0.14171 acc: 0.98667 val_loss: 0.14962, val_acc: 0.96000\n",
            "Epoch [7900/10000], loss: 0.14162 acc: 0.98667 val_loss: 0.14955, val_acc: 0.96000\n",
            "Epoch [7910/10000], loss: 0.14154 acc: 0.98667 val_loss: 0.14948, val_acc: 0.96000\n",
            "Epoch [7920/10000], loss: 0.14145 acc: 0.98667 val_loss: 0.14940, val_acc: 0.96000\n",
            "Epoch [7930/10000], loss: 0.14137 acc: 0.98667 val_loss: 0.14933, val_acc: 0.96000\n",
            "Epoch [7940/10000], loss: 0.14128 acc: 0.98667 val_loss: 0.14926, val_acc: 0.96000\n",
            "Epoch [7950/10000], loss: 0.14120 acc: 0.98667 val_loss: 0.14919, val_acc: 0.96000\n",
            "Epoch [7960/10000], loss: 0.14112 acc: 0.98667 val_loss: 0.14912, val_acc: 0.96000\n",
            "Epoch [7970/10000], loss: 0.14103 acc: 0.98667 val_loss: 0.14904, val_acc: 0.96000\n",
            "Epoch [7980/10000], loss: 0.14095 acc: 0.98667 val_loss: 0.14897, val_acc: 0.96000\n",
            "Epoch [7990/10000], loss: 0.14087 acc: 0.98667 val_loss: 0.14890, val_acc: 0.96000\n",
            "Epoch [8000/10000], loss: 0.14078 acc: 0.98667 val_loss: 0.14883, val_acc: 0.96000\n",
            "Epoch [8010/10000], loss: 0.14070 acc: 0.98667 val_loss: 0.14876, val_acc: 0.96000\n",
            "Epoch [8020/10000], loss: 0.14062 acc: 0.98667 val_loss: 0.14869, val_acc: 0.96000\n",
            "Epoch [8030/10000], loss: 0.14054 acc: 0.98667 val_loss: 0.14862, val_acc: 0.96000\n",
            "Epoch [8040/10000], loss: 0.14045 acc: 0.98667 val_loss: 0.14855, val_acc: 0.96000\n",
            "Epoch [8050/10000], loss: 0.14037 acc: 0.98667 val_loss: 0.14848, val_acc: 0.96000\n",
            "Epoch [8060/10000], loss: 0.14029 acc: 0.98667 val_loss: 0.14841, val_acc: 0.96000\n",
            "Epoch [8070/10000], loss: 0.14021 acc: 0.98667 val_loss: 0.14834, val_acc: 0.96000\n",
            "Epoch [8080/10000], loss: 0.14013 acc: 0.98667 val_loss: 0.14827, val_acc: 0.96000\n",
            "Epoch [8090/10000], loss: 0.14004 acc: 0.98667 val_loss: 0.14820, val_acc: 0.96000\n",
            "Epoch [8100/10000], loss: 0.13996 acc: 0.98667 val_loss: 0.14813, val_acc: 0.96000\n",
            "Epoch [8110/10000], loss: 0.13988 acc: 0.98667 val_loss: 0.14806, val_acc: 0.96000\n",
            "Epoch [8120/10000], loss: 0.13980 acc: 0.98667 val_loss: 0.14799, val_acc: 0.96000\n",
            "Epoch [8130/10000], loss: 0.13972 acc: 0.98667 val_loss: 0.14792, val_acc: 0.96000\n",
            "Epoch [8140/10000], loss: 0.13964 acc: 0.98667 val_loss: 0.14785, val_acc: 0.96000\n",
            "Epoch [8150/10000], loss: 0.13956 acc: 0.98667 val_loss: 0.14778, val_acc: 0.96000\n",
            "Epoch [8160/10000], loss: 0.13948 acc: 0.98667 val_loss: 0.14771, val_acc: 0.96000\n",
            "Epoch [8170/10000], loss: 0.13940 acc: 0.98667 val_loss: 0.14765, val_acc: 0.96000\n",
            "Epoch [8180/10000], loss: 0.13932 acc: 0.98667 val_loss: 0.14758, val_acc: 0.96000\n",
            "Epoch [8190/10000], loss: 0.13924 acc: 0.98667 val_loss: 0.14751, val_acc: 0.96000\n",
            "Epoch [8200/10000], loss: 0.13916 acc: 0.98667 val_loss: 0.14744, val_acc: 0.96000\n",
            "Epoch [8210/10000], loss: 0.13908 acc: 0.98667 val_loss: 0.14737, val_acc: 0.96000\n",
            "Epoch [8220/10000], loss: 0.13900 acc: 0.98667 val_loss: 0.14731, val_acc: 0.96000\n",
            "Epoch [8230/10000], loss: 0.13892 acc: 0.98667 val_loss: 0.14724, val_acc: 0.96000\n",
            "Epoch [8240/10000], loss: 0.13884 acc: 0.98667 val_loss: 0.14717, val_acc: 0.96000\n",
            "Epoch [8250/10000], loss: 0.13876 acc: 0.98667 val_loss: 0.14710, val_acc: 0.96000\n",
            "Epoch [8260/10000], loss: 0.13869 acc: 0.98667 val_loss: 0.14704, val_acc: 0.96000\n",
            "Epoch [8270/10000], loss: 0.13861 acc: 0.98667 val_loss: 0.14697, val_acc: 0.96000\n",
            "Epoch [8280/10000], loss: 0.13853 acc: 0.98667 val_loss: 0.14690, val_acc: 0.96000\n",
            "Epoch [8290/10000], loss: 0.13845 acc: 0.98667 val_loss: 0.14684, val_acc: 0.96000\n",
            "Epoch [8300/10000], loss: 0.13837 acc: 0.98667 val_loss: 0.14677, val_acc: 0.96000\n",
            "Epoch [8310/10000], loss: 0.13829 acc: 0.98667 val_loss: 0.14670, val_acc: 0.96000\n",
            "Epoch [8320/10000], loss: 0.13822 acc: 0.98667 val_loss: 0.14664, val_acc: 0.96000\n",
            "Epoch [8330/10000], loss: 0.13814 acc: 0.98667 val_loss: 0.14657, val_acc: 0.96000\n",
            "Epoch [8340/10000], loss: 0.13806 acc: 0.98667 val_loss: 0.14650, val_acc: 0.96000\n",
            "Epoch [8350/10000], loss: 0.13798 acc: 0.98667 val_loss: 0.14644, val_acc: 0.96000\n",
            "Epoch [8360/10000], loss: 0.13791 acc: 0.98667 val_loss: 0.14637, val_acc: 0.96000\n",
            "Epoch [8370/10000], loss: 0.13783 acc: 0.98667 val_loss: 0.14631, val_acc: 0.96000\n",
            "Epoch [8380/10000], loss: 0.13775 acc: 0.98667 val_loss: 0.14624, val_acc: 0.96000\n",
            "Epoch [8390/10000], loss: 0.13768 acc: 0.98667 val_loss: 0.14618, val_acc: 0.96000\n",
            "Epoch [8400/10000], loss: 0.13760 acc: 0.98667 val_loss: 0.14611, val_acc: 0.96000\n",
            "Epoch [8410/10000], loss: 0.13752 acc: 0.98667 val_loss: 0.14605, val_acc: 0.96000\n",
            "Epoch [8420/10000], loss: 0.13745 acc: 0.98667 val_loss: 0.14598, val_acc: 0.96000\n",
            "Epoch [8430/10000], loss: 0.13737 acc: 0.98667 val_loss: 0.14592, val_acc: 0.96000\n",
            "Epoch [8440/10000], loss: 0.13730 acc: 0.98667 val_loss: 0.14585, val_acc: 0.96000\n",
            "Epoch [8450/10000], loss: 0.13722 acc: 0.98667 val_loss: 0.14579, val_acc: 0.96000\n",
            "Epoch [8460/10000], loss: 0.13714 acc: 0.98667 val_loss: 0.14572, val_acc: 0.96000\n",
            "Epoch [8470/10000], loss: 0.13707 acc: 0.98667 val_loss: 0.14566, val_acc: 0.96000\n",
            "Epoch [8480/10000], loss: 0.13699 acc: 0.98667 val_loss: 0.14559, val_acc: 0.96000\n",
            "Epoch [8490/10000], loss: 0.13692 acc: 0.98667 val_loss: 0.14553, val_acc: 0.96000\n",
            "Epoch [8500/10000], loss: 0.13684 acc: 0.98667 val_loss: 0.14547, val_acc: 0.96000\n",
            "Epoch [8510/10000], loss: 0.13677 acc: 0.98667 val_loss: 0.14540, val_acc: 0.96000\n",
            "Epoch [8520/10000], loss: 0.13669 acc: 0.98667 val_loss: 0.14534, val_acc: 0.96000\n",
            "Epoch [8530/10000], loss: 0.13662 acc: 0.98667 val_loss: 0.14528, val_acc: 0.96000\n",
            "Epoch [8540/10000], loss: 0.13654 acc: 0.98667 val_loss: 0.14521, val_acc: 0.96000\n",
            "Epoch [8550/10000], loss: 0.13647 acc: 0.98667 val_loss: 0.14515, val_acc: 0.96000\n",
            "Epoch [8560/10000], loss: 0.13640 acc: 0.98667 val_loss: 0.14509, val_acc: 0.96000\n",
            "Epoch [8570/10000], loss: 0.13632 acc: 0.98667 val_loss: 0.14502, val_acc: 0.96000\n",
            "Epoch [8580/10000], loss: 0.13625 acc: 0.98667 val_loss: 0.14496, val_acc: 0.96000\n",
            "Epoch [8590/10000], loss: 0.13617 acc: 0.98667 val_loss: 0.14490, val_acc: 0.96000\n",
            "Epoch [8600/10000], loss: 0.13610 acc: 0.98667 val_loss: 0.14483, val_acc: 0.96000\n",
            "Epoch [8610/10000], loss: 0.13603 acc: 0.98667 val_loss: 0.14477, val_acc: 0.96000\n",
            "Epoch [8620/10000], loss: 0.13595 acc: 0.98667 val_loss: 0.14471, val_acc: 0.96000\n",
            "Epoch [8630/10000], loss: 0.13588 acc: 0.98667 val_loss: 0.14465, val_acc: 0.96000\n",
            "Epoch [8640/10000], loss: 0.13581 acc: 0.98667 val_loss: 0.14459, val_acc: 0.96000\n",
            "Epoch [8650/10000], loss: 0.13574 acc: 0.98667 val_loss: 0.14452, val_acc: 0.96000\n",
            "Epoch [8660/10000], loss: 0.13566 acc: 0.98667 val_loss: 0.14446, val_acc: 0.96000\n",
            "Epoch [8670/10000], loss: 0.13559 acc: 0.98667 val_loss: 0.14440, val_acc: 0.96000\n",
            "Epoch [8680/10000], loss: 0.13552 acc: 0.98667 val_loss: 0.14434, val_acc: 0.96000\n",
            "Epoch [8690/10000], loss: 0.13545 acc: 0.98667 val_loss: 0.14428, val_acc: 0.96000\n",
            "Epoch [8700/10000], loss: 0.13537 acc: 0.98667 val_loss: 0.14422, val_acc: 0.96000\n",
            "Epoch [8710/10000], loss: 0.13530 acc: 0.98667 val_loss: 0.14415, val_acc: 0.96000\n",
            "Epoch [8720/10000], loss: 0.13523 acc: 0.98667 val_loss: 0.14409, val_acc: 0.96000\n",
            "Epoch [8730/10000], loss: 0.13516 acc: 0.98667 val_loss: 0.14403, val_acc: 0.96000\n",
            "Epoch [8740/10000], loss: 0.13509 acc: 0.98667 val_loss: 0.14397, val_acc: 0.96000\n",
            "Epoch [8750/10000], loss: 0.13501 acc: 0.98667 val_loss: 0.14391, val_acc: 0.96000\n",
            "Epoch [8760/10000], loss: 0.13494 acc: 0.98667 val_loss: 0.14385, val_acc: 0.96000\n",
            "Epoch [8770/10000], loss: 0.13487 acc: 0.98667 val_loss: 0.14379, val_acc: 0.96000\n",
            "Epoch [8780/10000], loss: 0.13480 acc: 0.98667 val_loss: 0.14373, val_acc: 0.96000\n",
            "Epoch [8790/10000], loss: 0.13473 acc: 0.98667 val_loss: 0.14367, val_acc: 0.96000\n",
            "Epoch [8800/10000], loss: 0.13466 acc: 0.98667 val_loss: 0.14361, val_acc: 0.96000\n",
            "Epoch [8810/10000], loss: 0.13459 acc: 0.98667 val_loss: 0.14355, val_acc: 0.96000\n",
            "Epoch [8820/10000], loss: 0.13452 acc: 0.98667 val_loss: 0.14349, val_acc: 0.96000\n",
            "Epoch [8830/10000], loss: 0.13445 acc: 0.98667 val_loss: 0.14343, val_acc: 0.96000\n",
            "Epoch [8840/10000], loss: 0.13438 acc: 0.98667 val_loss: 0.14337, val_acc: 0.96000\n",
            "Epoch [8850/10000], loss: 0.13431 acc: 0.98667 val_loss: 0.14331, val_acc: 0.96000\n",
            "Epoch [8860/10000], loss: 0.13424 acc: 0.98667 val_loss: 0.14325, val_acc: 0.96000\n",
            "Epoch [8870/10000], loss: 0.13417 acc: 0.98667 val_loss: 0.14319, val_acc: 0.96000\n",
            "Epoch [8880/10000], loss: 0.13410 acc: 0.98667 val_loss: 0.14313, val_acc: 0.96000\n",
            "Epoch [8890/10000], loss: 0.13403 acc: 0.98667 val_loss: 0.14308, val_acc: 0.96000\n",
            "Epoch [8900/10000], loss: 0.13396 acc: 0.98667 val_loss: 0.14302, val_acc: 0.96000\n",
            "Epoch [8910/10000], loss: 0.13389 acc: 0.98667 val_loss: 0.14296, val_acc: 0.96000\n",
            "Epoch [8920/10000], loss: 0.13382 acc: 0.98667 val_loss: 0.14290, val_acc: 0.96000\n",
            "Epoch [8930/10000], loss: 0.13375 acc: 0.98667 val_loss: 0.14284, val_acc: 0.96000\n",
            "Epoch [8940/10000], loss: 0.13368 acc: 0.98667 val_loss: 0.14278, val_acc: 0.96000\n",
            "Epoch [8950/10000], loss: 0.13361 acc: 0.98667 val_loss: 0.14272, val_acc: 0.96000\n",
            "Epoch [8960/10000], loss: 0.13354 acc: 0.98667 val_loss: 0.14266, val_acc: 0.96000\n",
            "Epoch [8970/10000], loss: 0.13347 acc: 0.98667 val_loss: 0.14261, val_acc: 0.96000\n",
            "Epoch [8980/10000], loss: 0.13341 acc: 0.98667 val_loss: 0.14255, val_acc: 0.96000\n",
            "Epoch [8990/10000], loss: 0.13334 acc: 0.98667 val_loss: 0.14249, val_acc: 0.96000\n",
            "Epoch [9000/10000], loss: 0.13327 acc: 0.98667 val_loss: 0.14243, val_acc: 0.96000\n",
            "Epoch [9010/10000], loss: 0.13320 acc: 0.98667 val_loss: 0.14238, val_acc: 0.96000\n",
            "Epoch [9020/10000], loss: 0.13313 acc: 0.98667 val_loss: 0.14232, val_acc: 0.96000\n",
            "Epoch [9030/10000], loss: 0.13307 acc: 0.98667 val_loss: 0.14226, val_acc: 0.96000\n",
            "Epoch [9040/10000], loss: 0.13300 acc: 0.98667 val_loss: 0.14220, val_acc: 0.96000\n",
            "Epoch [9050/10000], loss: 0.13293 acc: 0.98667 val_loss: 0.14215, val_acc: 0.96000\n",
            "Epoch [9060/10000], loss: 0.13286 acc: 0.98667 val_loss: 0.14209, val_acc: 0.96000\n",
            "Epoch [9070/10000], loss: 0.13280 acc: 0.98667 val_loss: 0.14203, val_acc: 0.96000\n",
            "Epoch [9080/10000], loss: 0.13273 acc: 0.98667 val_loss: 0.14198, val_acc: 0.96000\n",
            "Epoch [9090/10000], loss: 0.13266 acc: 0.98667 val_loss: 0.14192, val_acc: 0.96000\n",
            "Epoch [9100/10000], loss: 0.13259 acc: 0.98667 val_loss: 0.14186, val_acc: 0.96000\n",
            "Epoch [9110/10000], loss: 0.13253 acc: 0.98667 val_loss: 0.14181, val_acc: 0.96000\n",
            "Epoch [9120/10000], loss: 0.13246 acc: 0.98667 val_loss: 0.14175, val_acc: 0.96000\n",
            "Epoch [9130/10000], loss: 0.13239 acc: 0.98667 val_loss: 0.14169, val_acc: 0.96000\n",
            "Epoch [9140/10000], loss: 0.13233 acc: 0.98667 val_loss: 0.14164, val_acc: 0.96000\n",
            "Epoch [9150/10000], loss: 0.13226 acc: 0.98667 val_loss: 0.14158, val_acc: 0.96000\n",
            "Epoch [9160/10000], loss: 0.13220 acc: 0.98667 val_loss: 0.14153, val_acc: 0.96000\n",
            "Epoch [9170/10000], loss: 0.13213 acc: 0.98667 val_loss: 0.14147, val_acc: 0.96000\n",
            "Epoch [9180/10000], loss: 0.13206 acc: 0.98667 val_loss: 0.14141, val_acc: 0.96000\n",
            "Epoch [9190/10000], loss: 0.13200 acc: 0.98667 val_loss: 0.14136, val_acc: 0.96000\n",
            "Epoch [9200/10000], loss: 0.13193 acc: 0.98667 val_loss: 0.14130, val_acc: 0.96000\n",
            "Epoch [9210/10000], loss: 0.13187 acc: 0.98667 val_loss: 0.14125, val_acc: 0.96000\n",
            "Epoch [9220/10000], loss: 0.13180 acc: 0.98667 val_loss: 0.14119, val_acc: 0.96000\n",
            "Epoch [9230/10000], loss: 0.13174 acc: 0.98667 val_loss: 0.14114, val_acc: 0.96000\n",
            "Epoch [9240/10000], loss: 0.13167 acc: 0.98667 val_loss: 0.14108, val_acc: 0.96000\n",
            "Epoch [9250/10000], loss: 0.13160 acc: 0.98667 val_loss: 0.14103, val_acc: 0.96000\n",
            "Epoch [9260/10000], loss: 0.13154 acc: 0.98667 val_loss: 0.14097, val_acc: 0.96000\n",
            "Epoch [9270/10000], loss: 0.13147 acc: 0.98667 val_loss: 0.14092, val_acc: 0.96000\n",
            "Epoch [9280/10000], loss: 0.13141 acc: 0.98667 val_loss: 0.14086, val_acc: 0.96000\n",
            "Epoch [9290/10000], loss: 0.13135 acc: 0.98667 val_loss: 0.14081, val_acc: 0.96000\n",
            "Epoch [9300/10000], loss: 0.13128 acc: 0.98667 val_loss: 0.14075, val_acc: 0.96000\n",
            "Epoch [9310/10000], loss: 0.13122 acc: 0.98667 val_loss: 0.14070, val_acc: 0.96000\n",
            "Epoch [9320/10000], loss: 0.13115 acc: 0.98667 val_loss: 0.14065, val_acc: 0.96000\n",
            "Epoch [9330/10000], loss: 0.13109 acc: 0.98667 val_loss: 0.14059, val_acc: 0.96000\n",
            "Epoch [9340/10000], loss: 0.13102 acc: 0.98667 val_loss: 0.14054, val_acc: 0.96000\n",
            "Epoch [9350/10000], loss: 0.13096 acc: 0.98667 val_loss: 0.14048, val_acc: 0.96000\n",
            "Epoch [9360/10000], loss: 0.13090 acc: 0.98667 val_loss: 0.14043, val_acc: 0.96000\n",
            "Epoch [9370/10000], loss: 0.13083 acc: 0.98667 val_loss: 0.14038, val_acc: 0.96000\n",
            "Epoch [9380/10000], loss: 0.13077 acc: 0.98667 val_loss: 0.14032, val_acc: 0.96000\n",
            "Epoch [9390/10000], loss: 0.13070 acc: 0.98667 val_loss: 0.14027, val_acc: 0.96000\n",
            "Epoch [9400/10000], loss: 0.13064 acc: 0.98667 val_loss: 0.14022, val_acc: 0.96000\n",
            "Epoch [9410/10000], loss: 0.13058 acc: 0.98667 val_loss: 0.14016, val_acc: 0.96000\n",
            "Epoch [9420/10000], loss: 0.13051 acc: 0.98667 val_loss: 0.14011, val_acc: 0.96000\n",
            "Epoch [9430/10000], loss: 0.13045 acc: 0.98667 val_loss: 0.14006, val_acc: 0.96000\n",
            "Epoch [9440/10000], loss: 0.13039 acc: 0.98667 val_loss: 0.14000, val_acc: 0.96000\n",
            "Epoch [9450/10000], loss: 0.13033 acc: 0.98667 val_loss: 0.13995, val_acc: 0.96000\n",
            "Epoch [9460/10000], loss: 0.13026 acc: 0.98667 val_loss: 0.13990, val_acc: 0.96000\n",
            "Epoch [9470/10000], loss: 0.13020 acc: 0.98667 val_loss: 0.13984, val_acc: 0.96000\n",
            "Epoch [9480/10000], loss: 0.13014 acc: 0.98667 val_loss: 0.13979, val_acc: 0.96000\n",
            "Epoch [9490/10000], loss: 0.13008 acc: 0.98667 val_loss: 0.13974, val_acc: 0.96000\n",
            "Epoch [9500/10000], loss: 0.13001 acc: 0.98667 val_loss: 0.13969, val_acc: 0.96000\n",
            "Epoch [9510/10000], loss: 0.12995 acc: 0.98667 val_loss: 0.13963, val_acc: 0.96000\n",
            "Epoch [9520/10000], loss: 0.12989 acc: 0.98667 val_loss: 0.13958, val_acc: 0.96000\n",
            "Epoch [9530/10000], loss: 0.12983 acc: 0.98667 val_loss: 0.13953, val_acc: 0.96000\n",
            "Epoch [9540/10000], loss: 0.12976 acc: 0.98667 val_loss: 0.13948, val_acc: 0.96000\n",
            "Epoch [9550/10000], loss: 0.12970 acc: 0.98667 val_loss: 0.13943, val_acc: 0.96000\n",
            "Epoch [9560/10000], loss: 0.12964 acc: 0.98667 val_loss: 0.13937, val_acc: 0.96000\n",
            "Epoch [9570/10000], loss: 0.12958 acc: 0.98667 val_loss: 0.13932, val_acc: 0.96000\n",
            "Epoch [9580/10000], loss: 0.12952 acc: 0.98667 val_loss: 0.13927, val_acc: 0.96000\n",
            "Epoch [9590/10000], loss: 0.12946 acc: 0.98667 val_loss: 0.13922, val_acc: 0.96000\n",
            "Epoch [9600/10000], loss: 0.12940 acc: 0.98667 val_loss: 0.13917, val_acc: 0.96000\n",
            "Epoch [9610/10000], loss: 0.12933 acc: 0.98667 val_loss: 0.13912, val_acc: 0.96000\n",
            "Epoch [9620/10000], loss: 0.12927 acc: 0.98667 val_loss: 0.13907, val_acc: 0.96000\n",
            "Epoch [9630/10000], loss: 0.12921 acc: 0.98667 val_loss: 0.13901, val_acc: 0.96000\n",
            "Epoch [9640/10000], loss: 0.12915 acc: 0.98667 val_loss: 0.13896, val_acc: 0.96000\n",
            "Epoch [9650/10000], loss: 0.12909 acc: 0.98667 val_loss: 0.13891, val_acc: 0.96000\n",
            "Epoch [9660/10000], loss: 0.12903 acc: 0.98667 val_loss: 0.13886, val_acc: 0.96000\n",
            "Epoch [9670/10000], loss: 0.12897 acc: 0.98667 val_loss: 0.13881, val_acc: 0.96000\n",
            "Epoch [9680/10000], loss: 0.12891 acc: 0.98667 val_loss: 0.13876, val_acc: 0.96000\n",
            "Epoch [9690/10000], loss: 0.12885 acc: 0.98667 val_loss: 0.13871, val_acc: 0.96000\n",
            "Epoch [9700/10000], loss: 0.12879 acc: 0.98667 val_loss: 0.13866, val_acc: 0.96000\n",
            "Epoch [9710/10000], loss: 0.12873 acc: 0.98667 val_loss: 0.13861, val_acc: 0.96000\n",
            "Epoch [9720/10000], loss: 0.12867 acc: 0.98667 val_loss: 0.13856, val_acc: 0.96000\n",
            "Epoch [9730/10000], loss: 0.12861 acc: 0.98667 val_loss: 0.13851, val_acc: 0.96000\n",
            "Epoch [9740/10000], loss: 0.12855 acc: 0.98667 val_loss: 0.13846, val_acc: 0.96000\n",
            "Epoch [9750/10000], loss: 0.12849 acc: 0.98667 val_loss: 0.13841, val_acc: 0.96000\n",
            "Epoch [9760/10000], loss: 0.12843 acc: 0.98667 val_loss: 0.13836, val_acc: 0.96000\n",
            "Epoch [9770/10000], loss: 0.12837 acc: 0.98667 val_loss: 0.13831, val_acc: 0.96000\n",
            "Epoch [9780/10000], loss: 0.12831 acc: 0.98667 val_loss: 0.13826, val_acc: 0.96000\n",
            "Epoch [9790/10000], loss: 0.12825 acc: 0.98667 val_loss: 0.13821, val_acc: 0.96000\n",
            "Epoch [9800/10000], loss: 0.12819 acc: 0.98667 val_loss: 0.13816, val_acc: 0.96000\n",
            "Epoch [9810/10000], loss: 0.12813 acc: 0.98667 val_loss: 0.13811, val_acc: 0.96000\n",
            "Epoch [9820/10000], loss: 0.12808 acc: 0.98667 val_loss: 0.13806, val_acc: 0.96000\n",
            "Epoch [9830/10000], loss: 0.12802 acc: 0.98667 val_loss: 0.13801, val_acc: 0.96000\n",
            "Epoch [9840/10000], loss: 0.12796 acc: 0.98667 val_loss: 0.13796, val_acc: 0.96000\n",
            "Epoch [9850/10000], loss: 0.12790 acc: 0.98667 val_loss: 0.13791, val_acc: 0.96000\n",
            "Epoch [9860/10000], loss: 0.12784 acc: 0.98667 val_loss: 0.13786, val_acc: 0.96000\n",
            "Epoch [9870/10000], loss: 0.12778 acc: 0.98667 val_loss: 0.13782, val_acc: 0.96000\n",
            "Epoch [9880/10000], loss: 0.12772 acc: 0.98667 val_loss: 0.13777, val_acc: 0.96000\n",
            "Epoch [9890/10000], loss: 0.12767 acc: 0.98667 val_loss: 0.13772, val_acc: 0.96000\n",
            "Epoch [9900/10000], loss: 0.12761 acc: 0.98667 val_loss: 0.13767, val_acc: 0.96000\n",
            "Epoch [9910/10000], loss: 0.12755 acc: 0.98667 val_loss: 0.13762, val_acc: 0.96000\n",
            "Epoch [9920/10000], loss: 0.12749 acc: 0.98667 val_loss: 0.13757, val_acc: 0.96000\n",
            "Epoch [9930/10000], loss: 0.12743 acc: 0.98667 val_loss: 0.13752, val_acc: 0.96000\n",
            "Epoch [9940/10000], loss: 0.12738 acc: 0.98667 val_loss: 0.13748, val_acc: 0.96000\n",
            "Epoch [9950/10000], loss: 0.12732 acc: 0.98667 val_loss: 0.13743, val_acc: 0.96000\n",
            "Epoch [9960/10000], loss: 0.12726 acc: 0.98667 val_loss: 0.13738, val_acc: 0.96000\n",
            "Epoch [9970/10000], loss: 0.12720 acc: 0.98667 val_loss: 0.13733, val_acc: 0.96000\n",
            "Epoch [9980/10000], loss: 0.12715 acc: 0.98667 val_loss: 0.13728, val_acc: 0.96000\n",
            "Epoch [9990/10000], loss: 0.12709 acc: 0.98667 val_loss: 0.13724, val_acc: 0.96000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#損失と精度の確認\n",
        "\n",
        "print(f'初期状態: 損失: {history[0,3]:.5f} 精度: {history[0,4]:.5f}' )\n",
        "print(f'最終状態: 損失: {history[-1,3]:.5f} 精度: {history[-1,4]:.5f}' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_x_5Yw1XUJY",
        "outputId": "8cf0a81b-deed-475c-ccb4-fc31ab6e65e1"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "初期状態: 損失: 1.09158 精度: 0.26667\n",
            "最終状態: 損失: 0.13724 精度: 0.96000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習曲線の表示 (損失)\n",
        "\n",
        "plt.plot(history[:,0], history[:,1], 'b', label='訓練')\n",
        "plt.plot(history[:,0], history[:,3], 'k', label='検証')\n",
        "plt.xlabel('繰り返し回数')\n",
        "plt.ylabel('損失')\n",
        "plt.title('学習曲線(損失)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "uqoWeQPJZUdG",
        "outputId": "5d8a5cda-b584-4ec2-b137-0591557c1b50"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習曲線の表示 (精度)\n",
        "\n",
        "plt.plot(history[:,0], history[:,2], 'b', label='訓練')\n",
        "plt.plot(history[:,0], history[:,4], 'k', label='検証')\n",
        "plt.xlabel('繰り返し回数')\n",
        "plt.ylabel('精度')\n",
        "plt.title('学習曲線(精度)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "5ihKuEj8ZXC9",
        "outputId": "aaadf20d-209e-412d-f7f4-cecf8d3d2c06"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAGOCAYAAABWoT4ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXwV9b3/8dcnIQFkU1FQCIqVW3FfiNVWWxF3RaVau6ht8V7KT1vrduuttrbaXq1oleqttYJttbXu4oo71ai1xYoWFEvBBZFNFBWTCARIPr8/vnPCMJyTc3LkTLb38/GYx8nMfGfm+z2E+eS7zZi7IyIiUoyyts6AiIh0XAoiIiJSNAUREREpmoKIiIgUTUFERESKpiAiIiJFUxCRDsXMKrJsq2yLvLQ1Mys3s9FmZjn272tmVWnnS7oWBRFp18zsdDP7dfTzYGCpmY2I7a+Otu2eOK5HjqXCzCpz7OueJy83mtmZsfU/mdnpBZbjQjMbmGPfTWb2uQLO0SexqSfwEFBuZttkCSYXA4cWkr/EdX5lZlcVkR/pghREpL17CzjTzKrdfTHwEvCz2P5fAjPd/dXMBjPrDazKsdwIPJVj3+I8eRkCbBVb3y6xnpWZjQTOBtZl2bcV8PWonC2d44vAX6KfDzCzJxNJ/gGcY2ZTMwuwb3KbmQ2InbPCzHonF2BbYJts+zK1PjPbG3g6X+CVzk9BRNo1d38CeA74fLQpUyupMLNxwB7AtxPH1AO9gDuAL7i7ubsBV0RJvgw8CHw+tu+LmzrvZraZmW0JTAROBwab2WHRvhvMbA3wNtAIvG1m9Wa2zszGJs6zeVSW86NNs4EDgb7R+iBgS+Bm4Aex5V/AnYltH8VO/T2gLsvyNeCUHPuuBHD3fwKvEYK4dGXurkVLu1uAMwEvYhkWO8c3gBXAVwi1iAnAzdG+rwLLCQHoYMJNeXkiD1OLuP5FsePPAT4ErgN6EG7+V0X7bgAuyVLux4CxiW0XAzWJbf8Ejo+uOQ64N9r+IrAoWlZF18+s35w4xznx8wLfAs5PpPkzsGeOf6NhQAMwtK1/X7S03dKt4Ggjkr7pwFEFpu1H+Ku+mbvfbmYNhL/A3wCWxPbdZWaNwIXAJ8Avcpz3WuCa6OfJhJv3b6P13wPPA3+I1u9IXP8aM9uFEKAmAiuBH8WSXGBm5ySul6lBAc2DBs4mBNW464APop9XZPLk7vvGjp0K3OPuN+coW5TMMveBYcD2sXWivN8U29bk7k3Rtd4ws+eA/wa+38I1pBNTc5a0Z42EJpR8VgEfxzdEI5PuJDS/3A+cBQwE3MwONbOno323AycCfQh/1SetcPe33f1tQhD4KLa+Cvgwtr46y/HfZX1t6HxCM1HGBHffPL4Q9XvEHABsTqihZMq2F6EGsFO0aTNgYNTxvyizAIcAE+PbzOx/E+f/ErA2Wn5CqI2sjS3bA9Ni67cljn8MGJ2l3NJFqCYi7d3ehCaalrwMHJZZiUYpfZ9wQz4VuJrQP+DA/xGatiYBdwNjgRcIN+IpmzbrQKhZbEloPlsI3G1m97Xi+IOBee7+YWzb54CTga2j9f8ilO27hEDQkk8S68+4+0gAM7uE0DQ1NrPTzN4mNK/V5Djf34BfmtkO7j4/z7WlE1IQkXbJ3a8jNNkAbDQPwswOIXSyvwd8M7rJxtN9K/bzWdGCmV0P7OPuX4v2/T5acukRdWwDVCTWuwE9E+vxPN4HVANVwNOxXd8g/FV/gZldEDsuM3rr1lja7YEF8fO6+2Rgspn9BtgFONLdV0XX/C7w8xxlOdPd401uZYTaXkYT8DUzGxPbthnZa2gZmbxtDyiIdEFqzpIOxcy2N7NngT8RmqMOdveFOdIeFI12al4Io6S+ktxuZo/nuOQPCSOaPgKOJnRyZ9aPIPSlZNYPSBw7jdCUdh3hBn0ioaawM3Au0Jtwk54A/MPdexCaoLaPnWNrQud4smybEZrIAB4ys8xIrc2Ax9x9q/hC6F/qkThNBSGYAeDuP3f3nokmtkp3fybHdwPr+2W2biGNdGIKItLumFm3aPLcRguhKecAQlv+Y4S+gHia+M3MANy9W2wpc/fy+DbgUqA8R3b+l3CzrSAMC/5xbP0RQqdyZv3ZxLGTgFpCE5oTRoP1IMxTyfQxfEC48X/ezM4nNLFNj53Dyf7/9FvReSDUBh4xs17R+hgzezu+AKOynKM38ImZXWBmnme5JsvxsP57a8qxXzo5BRFpj/YCluZY7iL83r6RY3++/pPWanL3de6+jnBDz7ceN5gwjDbz1/4SwtyMqR7mpnwTmEnosH+aMI/lJHefFjvH+8AW8ZNGgfIywsRJonOWE5rOAO5396HxhfUBJ66KMKx5QpSfmwmBssLXz585O8rD1Tm+ny1j+ZQuSEFE2h13n5G5iSUXwixsgC1ypBmaOF25ma1uaQEuKlFRhgPvxMr1BiFgVJtZD+CnhFoQhBnndxOa2+LeAnZIbPs5MCM6BkJfytGxZqcTzezd+EL2x5/sz4Yz5cdHn4+ZWVU0/Pgi4NhcTYaxvKk/pItSEJHOrtHde7S0sP5Gvql9Hnglse3PhOG5vwVecvf4kN7vAV+w8CytzIMmnwKGJZrpHiA0ozVz9/hM9Cnuvk18IfTPNLPwYMadiDXBuftaYAzwOvAmcBVhZNYLeco4r4UgI52cRmdJu2dm2xGG+r7L+iabQtvgy82spdFFGcn5GRkXm9nFsfXjzezy2PoxZvar2Hr8Zv1JYh13/6GZTSY02R1qZkMJz9/6yN2Xm9mR0TGHAw8T+kfeI3Tq/zE6x2PQ/IywFpnZvsAyojkysV3/TZicOT1K1w84iPDIk2MI/ThbEoYk/zvK0yvAP939X7HzHE1oApMuSkFEOoK+hOG8mxM6pqe6e22BxzZGnec5RfMjDsyx+2rCX+SFuDe+4u6/jM4/NJHuNsKor3XAq0AlYa4H7v66me3p7iui9XVmdjXw/4iCSCtNJowG+5j1zV8Q5q/8DNjBzB4FPkN4uOVdwFnu/kGU9x8QAsuhwH8S+mF+FO3bmTDQ4RtF5Es6CXMv5I80EWkrUY3jVeB0d881FLm156wE1rl7k4UnBL+WmNCY7RgDyty9MVq/C3jD3X/U0nHSuSmIiHQAFt6b8ht336+t8wJgZvsQnit2cDQyTbooBRGRDsLMKt19TVvnI6O95UfahoKIiIgUrVN2rG+11VY+dOjQoo795JNP6NWrV/6EnYjK3DWozF3DpynzSy+9tNzdW/UIm04ZRIYOHcqMGTOKOrampoaRI0du2gy1cypz16Aydw2fpsxmtiB/qg1psqGIiBRNQURERIqmICIiIkVTEBERkaIpiIiISNEUREREpGgKIiIiUjQFERERKZqCiIiIFE1BREREiqYgIiIiRVMQERGRonXKBzBK1zJ//nyuuOIK1q5dW/AxS5cu5ZZbbilhrtoflblrOOaYY1K9noKIdHhTpkxh0qRJDB48mPAG1/waGhro3r17iXPWvqjMXcNhhx2W6vUURKTDq62txcxYuHBhwUFEjwjvGrpqmdOkPhHp8Gpra+nTp0/BAURENh0FEenwamtr6du3b1tnQ6RLUhCRDq+urk5BRKSNqE+kk3j//fc58MADWbFiRauPXbt2LRUVFSXIVTo++ugjRowY0dbZEOmSFEQ6iXnz5jFv3jyOPfZYBg8e3KpjlyxZwqBBg0qUs3SMHj26rbMg0iUpiHQStbW1APz4xz9mv/32a9WxXXEEi4hsGuoT6SQyQaRPnz5tnBMR6UoURDqJTBBRB7OIpEnNWR3MvHnz+Pjjjzfa/q9//QtQEBGRdCmIdCBz585l+PDhOff37NmTXr16pZgjEenqFEQ6kCVLlgAwYcIEdtttt432b7fddpSXl6edLRHpwhREOpBMv8fhhx/O3nvv3ca5ERFRx3qHohFYItLeKIh0IBqBJSLtjZqzirR0Kdx4IzQ2wimnwGc/m/+YWbNmMWXKlKKv+be//Q1QEBGR9kNBpEh//jNcfHH4efly+M1v8h/zi1/8grvuuutTPbJ811137XIv2RGR9ktBpEgrVkB5OWy/PWSZtpHjmBXst99+TJ8+vbSZExFJifpEilRbC337hiXqqijgGL33QkQ6FwWRImWCSJ8+CiIi0nWlGkTMbKyZzTazRWb2opkd2ELaE8xsppktNbPXzez7aeY1n7q6EED69g0/F3aMXp4kIp1Lan0iZnYqMAE42N3nmNmJwMNmto+7v5lIewjwJ+BYd3/azLYD7jWzde7+27Ty3JJ4c9a0abDPPhunaWiYz4IFp9LUtAqAVauW8MEHm3aOx223wVVXfbpz1NePoHfvTZOfjkJl7hq6YpkvuCDdgTdpdqxfDEx09zkA7j7FzL4NnAWcnUj7n8Dt7v50lPadqCZyq5nd4O6eYr6zqq2F/v3h29+G+vrsaRYvfoFPPvkb/fsfTLduvVm9ejsqK7+2SfNx//3wxhvwaV4H8sEHDfTv37UmMKrMXUNXLHNZWbq3x1SCiJkNAYYBUxO7HgLOZ+Mg0hdI3ppXATsA2wELSpDNVqmrg6FD4YgjwpLNjTfWMX48zJz5J6qqqth+e9jUz0esrYWdd4YHHyz+HDU1s7vcS6lU5q6ha5Z5TarXS6tPJPO+1iWJ7Uti++JuB042s8MsGAr8Itq3TUly2EqZ5qyW02w4w7w1/SeFqqvLnw8RkVJJqzlrbfTZlNjuwEYz79z9tmhC3i+A3wP/Bn4KHAWsy3YBMxsPjAcYOHAgNTU1RWW0vr6+oGM/+uhAPv54KTU1b+ZM88orrwAwY8YMysrKcN+bBQsaqal5pai8ZbN0aTVVVauoqXmt6HMUWubORGXuGlTm0ksriCyKPgcB8QGxg4DF2Q5w99uA2zLrZpZ5kcZbOdJPBiYDVFdXe7FV2ELeN/7hh7BqFeyyyxBGjhySM92DDz5Inz59GDVqFABVVbBsGXz2s8XlLZs1a+Azn+n9qarsXfEd6ypz16Ayl14qQcTdl5nZLOBoQq0i4wjgsWzHmNlm7r4ytulI4G/u/lHpcprfyy9DdXX4ecstW05bW1u7wRN3+/eHxx+Hwdka8D6FfPkQESmVNEdnXQFcbWYPu/tcMxtDCAwjkgnN7DvAmWZ2jLsvMrMRwP8AJ6WY36zeegvc4dJLYezYltMmJxdedhkcdNCmzY8ZHHvspj2niEihUgsi7n67mfUFpppZL0Iz1mh3n2dmVcB04Fx3vxv4I2Ek1vNmVg4sBb7p7s+nld9cMrPTTzkF+vVrOW1ycuHQoTB+fOnyJiKStlQfwOjuk4BJWbYvAqpi62uAH0VLu5IZXVXIiCg95kREOjs9O6uVMjWRQl4umOwTERHpbPQo+FaqrYUePaCiYv22uro6pkyZwpo1G07yeffddxkxYqMuHxGRTkNBpJWyTe674447GJ+js2PHHXdMIVciIm1DQaSVss1U/+CDDwB488036dGjR/N2M2ObbdrFBHsRkZJQEGml2tqN+0Nqa2spLy9nhx12+FSvvhUR6WjUsd5K2ZqzMkN5FUBEpKtREGmlbM1ZGsorIl2VmrMKdOedcNddMHMm7LILvPrqq/z0pz9l3bp1vPTSS/Tv37+tsygikjoFkQJdeWV4bhaEmshDDz3E/fffz9577822227LiSee2LYZFBFpAwoiBSovX/9z376hCauyspKXM5FFRKQLUp9IgeJ95n36qB9ERAQURArW0LD+5/CGwjo90kREujwFkQLFn2iSac5STUREujoFkQLFayL9+unhiiIioCBSsIYG2GEHmDABDjts43eFiIh0RQoiBWpogCOPhB/+EHr3VnOWiAgoiBSsoQG6d1+/ruYsEREFkYIlg4ias0REFEQKsm5dGJ1VWRnWV69ezcqVKxVERKTLUxApwKOPhs9u0fz+e++9F4DevXu3UY5ERNoHBZECvP9++Dz11PD54YcfAnDyySe3UY5ERNoHBZEC1NaGzy22yKzXRutbtFGORETaBwWRAmSCSGYwVm1tLRUVFXSP97SLiHRBCiIFqK2Fnj3X94loZJaISKBHwRdgyhTo1cv52c9+zrvvvstTTz2lICIigoJIQZYtg/LyBVxyySX06dOHnj17MmbMmLbOlohIm1NzVgHKyuDLX/4YgJtuuolly5YxadKkNs6ViEjbUxApwLp10NhYB6BmLBGRGAWRAjQ2wrp1YYiWgoiIyHoKIgVYtw7Wrg1BRA9dFBFZT0Ekj6am8PnKKzcDqomIiMQpiOSxbl34bGxcBcDgwYPbMDciIu1LqkHEzMaa2WwzW2RmL5rZgS2kPczMno3SvmNm95jZf6SZXwj9IQANDbWMHj0aM0s7CyIi7VZqQcTMTgUmACe5e1X088NmtmOWtCOAqcD/RWmHAfOBGjPrlVaeYX0QWbNGs9RFRJLSrIlcDEx09zkA7j4FeAY4K0vaQ4G57n5PlHYNcCkwCNg1newGmeashga9DldEJCmVIGJmQwi1iamJXQ8BR2U5ZAYwzMziAeM44H3g3yXJZA6hJuLU17+vkVkiIglpPfYk0xu9JLF9SWxfM3f/i5mdATxoZs8DA4A64AB3ry1pThNCTeRJAHr27JnmpUVE2r20gsja6LMpsd2BjXqqzawc2JFQ83iREEROBkYBr2e7gJmNB8YDDBw4kJqamqIyWl9fv8Gxy5dXAosBGDp0aNHnbc+SZe4KVOauQWVOgbuXfAEGEgLG8MT2ccDrWdL/GHgZqIxt24FQGzkk3/VGjBjhxXr66ac3WH/nHXe4xgFfvnx50edtz5Jl7gpU5q5BZW4dYIa38v6eSp+Iuy8DZgFHJ3YdATyW5ZADgL956FDPnGM+oRayX6nymU1ozgrPzVKfiIjIhtIcnXUF8AMz2wnAzMYARwK/zpL2KeAkM9svSltmZt8BdiPTQZGS0LFeS0VFDyorK9O8tIhIu5fa+0Tc/XYz6wtMjeZ6LAZGu/s8M6sCpgPnuvvdwNXAKmCSmW0NlAOvAke6+4tp5RkyNZFH6d491ekpIiIdQqovpXL3ScBGL+Jw90VAVWzdgd9ES5sKNZHXaWho65yIiLQ/enZWHqEm4hx9dLY5kSIiXZuCSB7r1jmwhu7de7R1VkRE2h0FkTwaGsIUl+7du7dxTkRE2h8FkTxWrgydIZWVCiIiIkkKInmsXh2CiGoiIiIbUxDJo64uBJFevRRERESSFETy+OijEET69NFEQxGRJAWRPFasCE9e6ddPNRERkSQFkTw+/jjURBREREQ2piCSh4KIiEhuCiJ51NZmOtbVJyIikqQgkkd9fXjJekVFRRvnRESk/VEQyeOTTxoBKC8vb+OciIi0PwoieWRqIt26pfrAYxGRDkFBJA/VREREclMQacHHH8Nrr4UgopqIiMjGFERa8PvfA4TmLNVEREQ2piDSguXLAVQTERHJRUGkBXV10KuXaiIiIrkoiLSgthZ69FDHuohILgoiLYgHETVniYhsTEGkBXV10KOHmrNERHJREGmBaiIiIi1TEGlBbS1UVqomIiKSi4JIC+rqoHt3dayLiOSiINKC2lro3l3PzhIRyUVBJIemJqivh4oK1URERHJREMnhqafCZyaIqCYiIrIxBZEc5s0Ln5/5jDrWRURyURDJobY2fG6xhWoiIiK5KIjkUFcHofIRaiJlZfqqRESSdGfMobYW+vaFpqZGNWWJiOSQahAxs7FmNtvMFpnZi2Z2YI50E6M08WWZmbmZ7VfqfNbVwYMPQu/esG7dOjVliYjkkFoQMbNTgQnASe5eFf38sJntmEzr7ue5e1V8Aa4D/uruL5Q6rxdfDO+8A4MHQ2OjaiIiIrmkWRO5GJjo7nMA3H0K8AxwVr4DzWxr4L+Bc0uaw8i774bPBx+EhoYGunfvnsZlRUQ6nFSCiJkNAYYBUxO7HgKOKuAUPwamufuMTZ23bGprYZ99YOutFURERFqSVmP/4OhzSWL7kti+rMxsK+A7wEF50o0HxgMMHDiQmpqaojJaX1/PwoUrMIOampksWLAAdy/6fB1BfX19py5fNipz16Ayl15aQWRt9NmU2O6A5Tn2LODFfLUQd58MTAaorq72kSNHFpFNqKmpoaxsc4YMgZEjR3LDDTfQt29fij1fR1BTU9Opy5eNytw1qMyll1afyKLoc1Bi+yBgca6DzKwboRZyU4nylVVmeC/AmjVr1JwlIpJDKkHE3ZcBs4CjE7uOAB5r4dBjgL7AlBJlLatVq6Bnz/Cz+kRERHJLc3TWFcAPzGwnADMbAxwJ/LqFY74OPOPu9Snkr5k7WNTIpiAiIpJbarPo3P12M+sLTDWzXoRmrNHuPs/MqoDpwLnufjeAmZUTaiqXppXH9XlVEBERKUSqU7HdfRIwKcv2RUBVYlsjsGVKWUvkZ8Mg0rt377bIhohIu6dnZ2WRDCKVlZVtmyERkXZKQSSHTBDR6CwRkdwURLJwX/+z+kRERHJTEMlCHesiIoVREMlCQUREpDAKIlkoiIiIFEZBJAuNzhIRKYyCSBaZINLU1MTatWtVExERyUFBJAczWLs2PHxYQUREJDsFkSwyQ3wbGhoABRERkVwURLLINGcpiIiItExBJAsFERGRwiiIZKEgIiJSGAWRLDJBZPXq1QD06NGjjXMkItI+KYhkkQkitbW1APTNvCtXREQ2oCCSgxnU1dUB0KdPnzbOjYhI+6QgkkVmiK9qIiIiLVMQyULNWSIihVEQySITRNScJSLSMgWRLJI1EQUREZHsWgwiZjYx+pzUQppeZvbHTZ2xthQPIj179qSioqKtsyQi0i7lq4mMjj6/FN9oZvHZd7sCe23KTLW1eHOWaiEiIrkV25z1tpkdF/1cDdRsmuy0H5maiDrVRURy65Znv5nZk8COZvYW4MAXgSbgcjPrRqitXFHabKbLHRob1/Lhhx8qiIiItCBfTcSBLwPzgb2BeUAF8AFwMDAB2NbdnyllJtPmDjfcsBOPP/44W2yxRVtnR0Sk3cpaEzGzWwgBBHevN7NGd//YzNZl0rj7e2b2N2BYOllNj3sDK1bM55hjjuGyyy5r6+yIiLRbuWoifwWez7I9msuNmdlXgS2BejM7oBSZazthaO+RRx7Jnnvu2cZ5ERFpv7LWRNx9EoCZ/cDMpgOfNbOPCEGkCdgBOIvQH/IlYCzZg06HEx55ovkhIiKFyNsn4u77A6+7+xbuvqW7LyT0iRzi7iuAx4EjSp3RtIQgEmaqq1NdRKRlhQ7x9cT6je7eABB9vmdm22/SnLUpPTNLRKQQ+Yb4VpnZU8D2ZvYXQlPWGqDWzK4GZgIPAye6+4LSZjUdas4SESlcviByWGK9jDDEd3NgR+AE4DfAH4Hv57uYmY0FfhAdvxQ4193/2kL6M6Pz9gY+Bn7p7jflu86nY6g5S0SkMC0GEXd/HsDMBgJbu/vsZBozGwwMyXchMzuVMK/kYHefY2YnAg+b2T7u/maW9OcBJ0fpl5jZ54HbzWxa1C9TEvGaiIKIiEjLcgYRM7uI0FxVDTwFHGhmWwHbJZI68K8CrnUxMNHd5wC4+xQz+zZhlNfZiWv3AX4OjHL3JVH6v5vZju7eWFDJiqQgIiJSuJY61suj5eho3Qg3/IOAy4CdgcuB3YFHW7qImQ0hTEqcmtj1EHBUlkNGAavd/R/xjaUOIOEaAHWYGb169Sr15UREOrSWgoiz8agsgP8DFrr7hcASd/8fYF2WdHGDo88lie1LYvvi/gNYYGajzewFM1tgZo+ZWQpPCzaglsrKPphZ6S8nItKB5XrsyevAFkADYVb6rcBvsyTNBJlz81xnbfTZlOX4bHfqcsKExuOBw4FVhCav58xsV3d/J0uexwPjAQYOHEhNTU2eLGVXX78SWElZWfeiz9HR1NfXd5myZqjMXYPKnAJ332ghjIa6DPga8BJwJPBj4F5gD+BvUbp/ZDs+y/kGEgLG8MT2cYSJjMn03wA+BLolts8Bzs53vREjRnixHnvsGYfTvF+/IUWfo6N5+umn2zoLqVOZuwaVuXWAGV7APT2+ZG3Ocvd6wnyQ1UAjsDLaZcD/AEOjtx5uZ2YTM29AbCFQLQNmsb5/JeMI4LEsh/w9+sxWU2po6VqfVohVaykvzzf6WURECrlT/pUQPBy4CqgidIgDvNCKa10BXG1mD7v7XDMbQ6jhjEgmdPe3zexe4HdmdjqhOessYABwfyuu2WohiKyjrEyvxBURyaelINJE6Ju4BKgEvubr543sC3wduMDd1+Y8Q4y7325mfYGpZtYLWAyMdvd5ZlYFTCdMPrw7OuRMwuiveYQg9i/CkN93W1nGVjJUExERKUxLd8pXgf2B8wn9I0cCmNkhwGTg/xUaQDI8PB14Upbtiwg1nPi21YQO+3yd9ptUpjlLNRERkfxyjc6Kz/tYAXwPGGhmjxAe/T4POC+aVQ6Auyf7OzqkTHOWaiIiIvnlulP+IPrsR3gt7tuESYWzgd0Iz736A/DvEuevjaylvFw1ERGRfHKNznoNOIMQKPYjvD9krYeJhUMJc0Z+BlwILIvSdwrrO9ZVExERyaelO+V/e/TOEAAz+zqAuzcROscfJQzZ/aC0WUxbpmNdNRERkXxyBpF4AInWX0isN7J+qG+nsb5PZLO2zoqISLtX6JsNuwxNNhQRKZyCSML6moias0RE8lEQ2UjoE1HHuohIfgoiWaljXUSkEAoiCZpsKCJSOAWRhPUd66qJiIjkoyCSEIJII2Vl5W2dFRGRdk9BZCPhqfd6Na6ISH4KIgmhJqIgIiJSCAWRBAUREZHCKYhk1YSZvhoRkXx0p0xQTUREpHAKIhtRx7qISKEURBJUExERKZyCSIKCiIhI4RREEhREREQKpyCSlYKIiEghFEQ2oo51EZFCKYgkqDlLRKRwCiIJCiIiIoVTEElQEBERKZyCyEbUJyIiUigFkQTVRERECqcgkpVTVqYgIiKSj4JIQqYmEpq1RESkJQoiCWrOEhEpnILIRtSxLiJSqFSDiJmNNbPZZrbIzF40swNbSDvZzFZEaTPL26XOY6Ymoj4REZH8uqV1ITM7FZgAHOzuc8zsROBhM9vH3d/McsgQ4Cx3/6ASqeYAAB3GSURBVFNaeQQ1Z4mItEaaNZGLgYnuPgfA3acAzwBn5Ug/BFiYUt6ara+JqKVPRCSfVO6UZjYEGAZMTex6CDgqx2FDgEWlzFduqomIiBQirT+3B0efSxLbl8T2NTOzvkBfYHTUdzLfzB40s91LnM+oJgIa4isikl9afSJro8+mxPZcEzL6E2oha4GDgTXAOcCzZra7u29UQzGz8cB4gIEDB1JTU1NURuvrQxRZvvz9os/R0dTX13eZsmaozF2Dylx6aQWRzE1/EFAb2z4IWJxM7O7zCc1ZcVea2WnAGOC6LMdMBiYDVFdX+8iRI4vK6OuvTwdCICr2HB1NTU1NlylrhsrcNajMpZdKc5a7LwNmAUcndh0BPJbtGDPLlrdyQu2lZJqaPHP9Ul5GRKRTSHMI0hXAD8xsJwAzGwMcCfw6mTDq+5hvZgdH693M7CfA1sA9pcyku2XyUMrLiIh0CqnNE3H326MO86lm1ovQjDXa3eeZWRUwHTjX3e9291fN7Dzg8mhkVw/gZWBUVKspZT4BBRERkUKkFkQA3H0SMCnL9kVAVWLbFGBKSlmLXxdQEBERKYRm1CUoiIiIFE5BJEEd6yIihVMQ2UgIHnoAo4hIfgoiCevWhZqIgoiISH4KIglN0Zx6BRERkfwURBIyQaS8XEFERCQfBZGExkZ1rIuIFEpBJKGxMXyqJiIikp+CSIL6RERECqcgkpCpiSiIiIjkpyCSsL5jXV+NiEg+ulMmZDrW1SciIpKfgkiC+kRERAqnIJKQqYkoiIiI5KcgkqDJhiIihVMQSVAQEREpnIJIgob4iogUTkEkQR3rIiKFUxBJUHOWiEjhFEQSNE9ERKRwCiIJas4SESmcgkiCgoiISOEURBLUnCUiUjgFkQR1rIuIFE5BJMFDRURBRESkAAoiCU1NenaWiEihFEQS9HpcEZHCKYgkKIiIiBROQSTBXc1ZIiKFUhBJyNREunXTVyMiko/ulAmabCgiUjgFkYQ1a8KngoiISH6pBhEzG2tms81skZm9aGYHFnjcr8zMzWxoaXMIq1aVZ65Z6kuJiHR4qQURMzsVmACc5O5V0c8Pm9mOeY47Ajg4hSwCsGqVZa6b1iVFRDqsNGsiFwMT3X0OgLtPAZ4Bzsp1gJltDfwBOD2VHAKrV5dlrp3WJUVEOqxUgoiZDQGGAVMTux4Cjmrh0N8Dd7v79FLlLWnZskpAQUREpBDdUrrO4OhzSWL7kti+DZjZGcBngK+WMF8buPtuePfdnpnrp3VZEZEOK60gsjb6bEpsd2Cju7WZ7Qz8Ahjp7qsLuYCZjQfGAwwcOJCamppWZ/K55wZHWYLXXnuN/v37t/ocHVF9fX1R31dHpjJ3DSpz6aUVRBZFn4OA2tj2QcDieEIzqwBuA37h7rMKvYC7TwYmA1RXV/vIkSNbnclZswBmArD77rtTzDk6opqami5T1gyVuWtQmUsvlT4Rd18GzAKOTuw6AngssW0wsBdwZTSs180sekA7883sr6XKZ5hoGC6l5iwRkfzSqokAXAFcbWYPu/tcMxsDHAmMiCdy97fJ3sTlwA7R/pJQEBERaZ3Ugoi7325mfYGpZtaL0Iw12t3nmVkVMB04193vTitPSQoiIiKtk2ZNBHefBEzKsn0RUJXn2JLf1RVERERaR8/OiglBJAwgKyvTVyMiko/ulDHxmoiCiIhIfrpTxsRrImrOEhHJT0EkRjUREZHW0Z0yRjUREZHWURCJaWoCM3Wsi4gUSnfKGNVERERaR0Ekxl01ERGR1tCdMibenKWaiIhIfgoiMU1NUFammoiISKF0p4xRn4iISOsoiMSEmojmiYiIFEp3yhjVREREWkdBJEZ9IiIirZPqo+DbO9VERDqO2tpa3nvvPdauXZszTb9+/ZgzZ06KuWp7ucpcUVHBgAED6Nu37ya9noJIjGoiIh1DbW0ty5YtY/DgwfTs2TPnH311dXX06dMn5dy1rWxldndWrVrF4sWLATZpINGdMkY1EZGO4b333mPw4MFsttlm+r9aADNjs802Y/Dgwbz33nub9NwKIjEanSXSMaxdu5aePXu2dTY6nJ49e7bY/FcM3SljVBMR6Ti62v/RlStX8vnPf56GhoYNtq9YsYJhw4YVdI5SfGcKIjF6iq+IlNrEiRMZPnx483LPPffw8ssvc8IJJwDw0EMP8cknn3DHHXcwduzY5uNuueUWhg8fTvfu3dso59mpYz1Gz84SkVI777zzOO+88zbYNn36dD788EMAzj//fB577LHmfR9//DG33nor1113HY8//jhjx45l33335de//jUATU1NvPPOOwwfPrx5/e6772bPPfdMpTwKIjGqiYhIKc2ZM4djjz12o+1XXHFFzmMqKiq4/fbbOeyww5g1axYLFy7k5ptv5nvf+x4QmrOqq6v597//DaQ/Ik1BJCYEkdCxrpqIiGxqO++8M2+88cZG26dPn57zmM0224z777+fww8/nOeee47bbrsNgOHDh1NZWQnA4sWL2Wuvvfjkk0/Ydddduf/++0tTgCz053ZM6FhvBFQTEZHSuOaaa9htt92al3vvvTfvMf3792f//fdn/PjxXHrppcydOxeAa6+9lmuvvZZBgwZxww03cP7555c6+xtRTSQmXhNREBHpWM45B2bO3HBbY2NPystLd8299oJrrmndMaNGjWKbbbaJnWMv3nvvvZytH2+++SZXXXUVd911FytXrmTt2rVccMEFALz44otAGLk1ffp05s+fX1xBPgUFkZj4mw3VnCUiaVm9ejU9evTIuu8zn/kMZ555JmPGjOH222/nrLPOorGxkfHjx3PHHXcAoV/kz3/+M/X19c0d7GlREIkJzVmqiYh0RNlqBHV1q9rdY0+uuOIKZs2a1bw+ZswY9ttvP3r16pU1vZlxxhlnMG7cOCCM3rrvvvuaO9LPPPNM/vnPf3LCCSfwox/9iLq6utIXIkZ3ypjQnBX6RFQTEZFSePPNN7nnnnuYPXs2l156KYsWLWL+/PlUVVXlPGbx4sVsu+22AFRXV/Pcc88B8Oijj/LGG28wdOhQnnjiiYL6VzY1BZEY9YmISFt46aWX+OxnP5t130cffYS7U1FRAcCIESOoqKjgySef5LzzzuP666+nvLyc2267jXPOOYcJEybQFJpVUqE7ZYwmG4pIGo477jh22203zj77bFatWsUjjzzCyJEjATj44IPZbLPNmtOuWLFig7kl3/72t/noo484/fTTeeCBB9hyyy0BGDRoEM8//zxTp07liSeeSK0s6hOJUZ+IiKThwQcfbO4AnzVrFvPnz2eXXXYB4Le//S0A5eXlVFRUsMMOO3DttddSU1PTfPxRRx3FoYceSlVVFStWrGjePmTIEKZNm8bWW2+dWlkURGLUJyIipZacWLjnnnvyl7/8ZaN0J510EieddFLz+siRI5trKwMHDmzevvnmm28wgTHXKK9SSfXPbTMba2azzWyRmb1oZge2kPbLZjbDzBaa2dtm9jsz61/K/KlPRETaQnsbQdYaqd0pzexUYAJwkrtXRT8/bGY7Zkl7CHAD8H13HwLsBmwJ/LmUedSj4EVEWifNP7cvBia6+xwAd58CPAOclSXtU8De7v73KG09cAvwpVJm8H//F774xfDWL9VERETyS+VOaWZDgGHA1MSuh4Cjkuk9WBI7fifgfEJwKZnPfQ623XZl5pqlvJSISKeQVsf64OhzSWL7kti+jZjZD4GLCPn8PfCTFtKOB8ZD6HSKj2Rojcxbw/7+97/Tr1+/os7R0dTX1xf9fXVUKnPH1q9fv4JmZjc2NqY+g7ut5Svz6tWrN+nvQVpBJPNS3+QMGAdy/snv7leY2S+BzwOXA18EHsyRdjIwGaC6utozoxhaa8qUKQAceOCB9O9f0n78dqOmpoZiv6+OSmXu2ObMmVNQZ3Ta79YoxCeffMLKlStLNgw3X5l79OjB3nvvvcmul1bD/6Loc1Bi+yBgcUsHunuTuz8PXAr82cwqSpC/+PUA9YmISGk8+uij/OQnGzaqNDQ0sNVWW3HWWdm6iNu3VGoi7r7MzGYBRwP/ju06Angsmd7MhofDfG5s8wdAH6AXsCJ5zCbMayYPpbqEiMgGbr31Vr70pS8xdepUvvnNb7Lvvvs277vwwgu57777mtdfe+01/vjHP1JbW5v1XP/1X/9V8vzGpTnZ8ArgajN72N3nmtkY4EhgRJa0/wUcbWZfcfc5ZrY58HPgOXcvWQAB1UREJF11dXX85Cc/4YEHHmDhwoWcdNJJvPDCC80TCi+//HIuv/zyDY5ZsGABH3zwAQCPPPIIu+yyC0OHDk0760CKQcTdbzezvsBUM+tFaMYa7e7zzKwKmA6c6+53A/8DvAPcbWZbEF43+BfgP1PIJ6CaiIhsWnPnzuWXv/wlb7/9NosXL2bcuHFcfvnljB8/nkMPPZTq6mqqq6t56qmnGDVqFE8++SQLFy7klFNO2eA8X/rSl/jDH/7QvD5mzBjGjRvH6NGjAVIfSJDqY0/cfRIwKcv2RUBVbN2BX0dLqlQTEZFS6Nu3L/vvvz8LFy5k4MCB7LPPPowfP55FixY194n06NGDzTffnC984Qvss88+TJs2Les72dsT3SkTVBMRkVLYdtttGTduHMuXL2f48OEcddRRlJWVMW3aNF555RXGjh3LpZdeyuzZs7nxxhuZOHEiO+64IxdddNEG72RvbGxk6dKlzW81bGt6AGNC5jn8qomIdCznnHMOMxMvWW9sbKS8hC9Z32uvvbimFS9ZX7hwIbNnz2bu3Lkcd9xxfOc732GHHXZgu+22Y+nSpfTo0YNrrrmGBQsWcN9999GzZ09OOOEEqqurm89RVlbGggULuO666/j6178OwJ133snMmTPZfffdGTVq1CYvZ0t0p0xQTURESmXy5MkcfvjhjBo1ijPPPJOlS5dy3HHHMXPmTE477TQuu+wyZs6cyRFHHNF8TENDA/X19c1LNsOHD2f//fdn2LBhaRWlmWoiCeoTEemYstUI2tNkw2XLlnHDDTcwYcIEXnzxRX73u9/x8ssvM3XqVKqrq3nnnXfo1q0b11xzDW+99Rann346AFdeeSWvv/5683n22GOPjc695557cuihhwLpd6zrTpmgmoiIlMK9997Lt771rebHKQ0YMICePXsyduxYZsyYwZAhQxgwYADPPvssZ5xxRnPwe/3115k2bRqzZ89m6NChrFy5si2LsRHVRBJUExGRUjjllFNoaGjgmWeead520EEHcdBBB3HPPfcwZMgQjjnmGE455RTuvPNOKisr2zC3hVMQiVm+fHlzm6NqIiKyKfXt23ejbWvXrmXy5Mlce+21PP300wwePJi33nqL/fffn4kTJzY/62zhwoWsXr2aVatWpZzr/BREYk455RSeeOIJKisrFUREpKQaGho44IAD2GOPPXj++eebH8h4+eWXs//++3Pdddex3377AfDDH/6QyspKKioqePLJJ7n22msB2GqrrQD461//2nze66+/nq9+9auplUNBJOacc85h99135+ijj27rrIhIJ/WVr3yFr3zlKwC8+OKLWf9gPf744zn++OMBmD179kb7kw9wjOvUM9bbu6OOOoqePXt2msdli0j71hlaPNR7LCIiRVMQERGRoimIiIhI0RRERKRDyjznTgpXiu9MQUREOpxevXqxePFi1qxZ0zxBWHJzd9asWcPixYvp1avXJj23RmeJSIdTVVXF8uXLWbBgAevWrcuZbvXq1fTo0SPFnLW9XGXu1q0b/fr1a55bsqkoiIhIh1NWVsaAAQMYMGBAi+lqamrYe++9U8pV+5B2mdWcJSIiRVMQERGRoimIiIhI0RRERESkaAoiIiJSNOuMY6zN7H1gQZGHbwUs34TZ6QhU5q5BZe4aPk2Zt3f3rVtzQKcMIp+Gmc1w9+q2zkeaVOauQWXuGtIus5qzRESkaAoiIiJSNAWRjU1u6wy0AZW5a1CZu4ZUy6w+ERERKZpqIiIiUjQFERERKZqCSMTMxprZbDNbZGYvmtmBbZ2nQpnZt8zsFTNbbGavm9mFZlYe229mdr6ZzY3SPG1muyTOsbmZTTKzt8xsqZn90cz6JdLsbGaPmtmCaPmxmVla5czFzLY3sxVmdnNsW3czm2Bmb5jZEjN7wMwGJ44bbGZ3mtnb0ffyKzPrnkizv5k9Z2bvRN/t+JSKtREz2yEqx+Lo3+guMxsU298Zy9zHzCaa2XwzW2hmr5nZmbH9HbrMZlYWXXuimX1gZuMS+1P7v2tmx5jZS9H3PNvMxhRUCHfv8gtwKvAusHO0fiLwMbBjW+etgLyfHOV9n2h9e2AOcGEszUXAv4BBgAFnA0uALWJppgF3AD2i5Xbg0dj+rYClwDnROQYDrwE/bOPylwHPArOAm2Pbfwc8A2xOeOXBVcCrQLdof2X0nVwNlEfpaoDfxs6xE1ALnBit7xx9B19rg3JuTphAOz76/nsCfwau7Kxljq5/H/AXoH+0vhuwGDinM5QZOB2YDvwv8D4wLrE/lf+7wEHRd3BAtH4A4R54QN4ytMUvRntbgNeB/0lsexC4tq3zVkDefw2clth2FvBy9HPP6Jfjq4k0rwDnxn5h1gHbxvYPANYCe0XrPwZeS5zjBOA9oLINy38R8AhwCVEQAbYDGoHPxdJVEmbxfjlaPwX4EOgeS7MPsAYYEK3fCDySuN55wMw2KOfPsuSlPPZzpytzdO1VwAmJbb+K/s07VZmBt4kFkTT/7wJPAtcn0vwf8EC+fHf55iwzGwIMA6Ymdj0EHJV+jlrH3b/v7jclNu9B+OUDqAb6AA8n0sTLN4oQdJbGzvse8A/g6Fia5DkeJvyV0yYzgs1sP8JfV2ckdh0EfODu/8hscPc1wONsWOZp7t4QS/My4QZ0aCxNtt+LPePNSCk5Dng0vsHdG2OrnbHMAC8Cx5pZGYCZ9QYOJtQ+O2uZM1L5v2tmFcAXyf4dHJmvybrLBxFC1Q5CFTFuSWxfhxC1r14MfBO4NNo8GPjY3T9JJI+XbzAblz9vmug/5ge0wfcU3UxuJfxFlnxOWlHliSzOk2ZJbF+a/gP4yMxuiNq+XzWzn0Y3gEx+OluZAb4K9AZmmdkNhKaoScAVdN4yZ6T1f7c/0D3LeZYQanYtvk9XQSRU+wCaEtud0H7YIZjZtoS20dOAQ919WrRrLRuXDTYs36ZKk6brgJfc/ZYs+0pZ5szEqrTLXE5olrgT2BH4CuEGe1W0vzOWGWAbYFvg78ALhBr28YQ+gs5a5oy0/u+2dA+EPN+Bgggsij6T1dZBhL9W2j0z2x14Cfg3sJu7PxfbvQjYwsx6Jg6Ll28RG5c/bxoz6wFsScrfk5mdBBxC6JTMpqjyFJgms57278Y7wO/c/WkP5hI6Y78Z7e90ZTazvoQ/jK5x9/HufpO7jwLeJHQkd7oyJ6Tyf9fdPwBWZznPIELf0fstZbLLBxF3X0YY2XN0YtcRwGPp56h1zKwKeIIw0uK77l6fSPIy4Zcg2b8TL9/jwAgzGxA77xbAvok0ye/oEGAFod06TccAVcCHZuZm5sDFwLejn5uALc1sn8wBZtaN0DYcL8+hseYgzGxXYCDhxpVJk+334lV3T/vm8hyhySFpTfT5FJ2vzMMJTS01ie2PA5+jc5Y5Ls3/u7m+gyc86mXPKc3RB+11Ab5BaP/bKVofA9QBn23rvBWQ96nAZXnSXAjMBgZF698HlhENm4y2PQ7cxvphgrcSOiQz+7cgDBP8frS+bXTOi9r6O4jycwkbDvGdBDwN9CM0BV1JGCpZEe3vFuX/ymh/P8JN6XexcwwjNJ9kRvrsFP2enNoG5RsWXfvgaH17wjDNX3TiMvciDF//DdArVu6/E40a6kxlJjE6K9qWyv9d4EDCkN4vROtfiNYPypvvtH8x2usC/D/CUN8lhOic98trDwuh3XIZocq6wRJLU0YYCvt29MtUA+yeOM/mwB+j8i8B/kRsLHqUZtfoP+wSwpyFnwJlbf0dRHm7hA2DSHfCUNBFUZkfBIYkjqkCHojKswi4FuiRSPPF6PdhcfT7cUYblvFLhH6B9whNOj/N3Cw7cZk/S5j3sDDK85vABKB3Zysz2YNIav93gS8Tgsvi6PPEQvKtBzCKiEjRunyfiIiIFE9BREREiqYgIiIiRVMQERGRoimISKdkZt+I5gyU8hpbRo9fadcsPEJ+NzMbY2a/M7MdzWx0tO9HZja2jbMoHZiCiHQ6ZnYE8F3CE14xs63MbKWZzYiWuRZ790jsuP80swlZtjeYWbaHTJ4GPGNmW0fpLrDwXpO3syzXZznvPma2shXlmmBm9Wb2bp6l3swujR26P3BNbP27hHkAECalNSBSpJL+pSaSJjPrQ3jE9VmER4BfZ2ZXACuBN4CRUdIvAl/Lcoo9yP6H1fuEsfgbcPero6e8PmZmn4s2X+PulxSY5XLCY7xb4xp3v6ilBIkAAnAP4fEoldH6VsD50c8jgGfN7MhY+mfcfVUr8yVdlIKIdCaNwDjCpLF9CC8wWkiY+fwy4aGNGX/Ncvy2wIws2z8kzHTO5gfAF929Mc8Ts7Mpj/JcMma2E+GhjRCefNuX8J08YWYXEh7/cUi0HEV43PzLhPd4iOSlICKdhruvjF7p+QLh/RsnEW6S98SSXUx4wdMwMzvA3U+L7esHvGdmW7j7R7Htq8n+3Co8zNZ9NrbpPEu84pTw6I793T1Z6yg6iJjZG1GeMseXAw3uPiyRv7nAXlEfyC+j9BMI38l3genuPtrMegFvufvoYvIjXZf6RKRT8fBE0mmEx6BcBQwFVrj7gYRmnK2j/SOBvROHNxIeI/OUmW0T276OcJPOxwivYZ0JjCU8k+lkoDFLAIFPVxPpRqgBDXX3ocDnyfJHoZkNMLPfEV6rewnwPOGNgL8n9Olknty6I+FxHyKtopqIdBrR01m/T2j/z7yHYhyws5ldRQggAIcT3hiXtAI4E5jh7u/Gtvci9KvEr7Uz4UGABrzg7ocTagYfEx4KeLa7TzOzb7C+OSmp5M1ZhHdFvAz8Frie0N/xhyhIzgL+bmbDCAFVQURaTTUR6UwWEt4V/SPCI9IPJXSoHw/cTOh034PwV/lNwImJ418ndDT/LLG9io3fDDfH3TcnPC4702G9NaET/mHCI8ovA44lvMM7mxaDSJb3SLSau3/k7tcTgt1xhPdwEAXJMcBdhO/jUNY/Gl2kYKqJSKfh7rVRf8SdhCDyIHAD0Y0TqCAEhOMyx5jZae6eeafC3UC9uy+K7d+F0Bk9u4As7Av80d2bzOy7hGati929Lkf6MrK/cS7z/vgbzWwvd8+aBvirmWWaybIGJDPbG7iFEOAc+IeZDSX00/w3MIXwRNctCX0kIq2iICKdzQ6EGySEmsUsd9/NzPoTailOaIb6f8mbs7u/RnhHR9zPgUdbCAQAmNlwQoCaEV3r14THj59pZiuA67P0i6wANjcz89jjtM1sR0LH9zW5AkjUD5KXu//TzPYijFg7mfCdzAf29Ojd3WY2A/hMvjKKZKPmLOk0otnjPQmjqQDuB7pHkwEfILzcaCahaeqO+Nvgspyrn5ndAhwMnNvCZXsR5pCcQhhCeyrhpUiPu/sYQgf+N4GXs8ygf43QZ3G+mfWNJkWeThhddou7X11w4Vu2I2FwwNXA/wEPxQLIMYQ3RW5uZj/eRNeTLkRBRDqTgYTaBgDufhNhRNbLhGatv0TbLyb8ZT7bzPZNnsTMDgHeIrzh7gB3fzPbxczseMILgOYBexJu/i8Bo9z9suha/yK8yvU0EiO8ohv5CYTA8yGhBnUy8C13/1GOMp6Tb8Y6cE7iOnMJL7RaRegHGmVmR0f5vwX4OqFPZJyZ/T4a7itSEDVnSacR3ezHmdnI2Ob3gCPc/V9RX0Am7S/N7EFCx3tSDeHm/my8mSkuanL6E/BVd3/czL4GXEZ4L3i5mTUS/kjrAfQmNKPtTaK5zN2fBfaw8A5wzzEUOK5VM9YtzICcTJhMeCehxlRNGPr8K+AUd388SntAlGYQGqklBdKbDUWKZGbbJIYCx/d1J/yR1kSYBJirc7zkzOw/gHfcvSGxva+717ZRtqSTUBAREZGiqU9ERESKpiAiIiJFUxAREZGiKYiIiEjRFERERKRoCiIiIlI0BRERESna/webp3FGUSIegQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 正解データの0番目、2番目、3番目\n",
        "\n",
        "print(labels[[0,2,3]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "On_rJMUlZk0_",
        "outputId": "9cd9c50b-25ae-4960-9c4f-844b81543cbb"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 0, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 該当する入力値を抽出\n",
        "\n",
        "i3 = inputs[[0,2,3],:]\n",
        "print(i3.data.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vWJ3Ao3ZoFV",
        "outputId": "07307d07-8c18-4c04-f4a3-50eef339bb6d"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6.3 4.7]\n",
            " [5.  1.6]\n",
            " [6.4 5.6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 出力値にsoftmax関数をかけた結果を取得\n",
        "\n",
        "softmax = torch.nn.Softmax(dim=1)\n",
        "o3 = net(i3)\n",
        "k3 = softmax(o3)\n",
        "print(o3.data.numpy())\n",
        "print(k3.data.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhVQnn4KZ-0U",
        "outputId": "15b52a74-9102-430e-c56e-7f33e4182225"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 8.8071 14.1937 12.9986]\n",
            " [12.8262  9.8     0.1734]\n",
            " [ 6.7954 15.0928 17.1111]]\n",
            "[[0.0035 0.765  0.2315]\n",
            " [0.9537 0.0463 0.    ]\n",
            " [0.     0.1173 0.8827]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 重み行列\n",
        "print(net.l1.weight.data)\n",
        "# バイアス\n",
        "print(net.l1.bias.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yB3LNoKibD20",
        "outputId": "ac638ecd-a32f-4d8c-c1a3-35e877f2a903"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 3.0452, -2.5735],\n",
            "        [ 1.3573,  0.8481],\n",
            "        [-1.4026,  4.7253]])\n",
            "tensor([ 1.7178,  1.6563, -0.3741])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 訓練データ、検証データに分割 (シャフルも同時に実施)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x_org, y_org, train_size=75, test_size=75, \n",
        "    random_state=123)\n",
        "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "# 入力次元数\n",
        "n_input = x_train.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsleX2NSbc9H",
        "outputId": "9213c9cf-42f0-4d50-f816-ba4abf7b8c69"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(75, 4) (75, 4) (75,) (75,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('入力データ(x)')\n",
        "print(x_train[:5,:])\n",
        "print(f'入力次元数: {n_input}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJ5AP6S8cMwm",
        "outputId": "b87542e9-c42f-4f40-ad6b-ae5d9c1bc290"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "入力データ(x)\n",
            "[[6.3 3.3 4.7 1.6]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [5.  3.  1.6 0.2]\n",
            " [6.4 2.8 5.6 2.1]\n",
            " [6.3 2.5 5.  1.9]]\n",
            "入力次元数: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 入力データ x_train と正解データ y_train のテンソル変数化\n",
        "inputs = torch.tensor(x_train).float()\n",
        "labels = torch.tensor(y_train).long()\n",
        "\n",
        "# 検証用データのテンソル変数化\n",
        "inputs_test = torch.tensor(x_test).float()\n",
        "labels_test = torch.tensor(y_test).long()"
      ],
      "metadata": {
        "id": "zGdK911acRkK"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習率\n",
        "lr = 0.01\n",
        "\n",
        "# 初期化\n",
        "net = Net(n_input, n_output)\n",
        "\n",
        "# 損失関数： 交差エントロピー関数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 最適化アルゴリズム: 勾配降下法\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
        "\n",
        "# 繰り返し回数\n",
        "num_epochs = 10000\n",
        "\n",
        "# 評価結果記録用\n",
        "history = np.zeros((0,5))"
      ],
      "metadata": {
        "id": "UNX0VAcmcTwC"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # 訓練フェーズ\n",
        "    \n",
        "    #勾配の初期化\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 予測計算\n",
        "    outputs = net(inputs)\n",
        "\n",
        "    # 損失計算\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # 勾配計算\n",
        "    loss.backward()\n",
        "    \n",
        "    # パラメータ修正\n",
        "    optimizer.step()\n",
        "\n",
        "    #予測値算出\n",
        "    predicted = torch.max(outputs, 1)[1]\n",
        "\n",
        "    # 損失と精度の計算\n",
        "    train_loss = loss.item()\n",
        "    train_acc = (predicted == labels).sum()  / len(labels)\n",
        "\n",
        "    #予測フェーズ\n",
        "\n",
        "    # 予測計算\n",
        "    outputs_test = net(inputs_test)\n",
        "\n",
        "    # 損失計算\n",
        "    loss_test = criterion(outputs_test, labels_test)\n",
        "\n",
        "    # 予測ラベル算出\n",
        "    predicted_test = torch.max(outputs_test, 1)[1]\n",
        "\n",
        "    # 損失と精度の計算\n",
        "    val_loss =  loss_test.item()\n",
        "    val_acc =  (predicted_test == labels_test).sum() / len(labels_test)\n",
        "    \n",
        "    if ( epoch % 10 == 0):\n",
        "        print (f'Epoch [{epoch}/{num_epochs}], loss: {train_loss:.5f} acc: {train_acc:.5f} val_loss: {val_loss:.5f}, val_acc: {val_acc:.5f}')\n",
        "        item = np.array([epoch , train_loss, train_acc, val_loss, val_acc])\n",
        "        history = np.vstack((history, item))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ao5LX1mcZXo",
        "outputId": "6e8da5c5-ba35-416d-e2f3-28711af1b4a4"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/10000], loss: 1.09861 acc: 0.30667 val_loss: 1.09158, val_acc: 0.26667\n",
            "Epoch [10/10000], loss: 1.01848 acc: 0.40000 val_loss: 1.04171, val_acc: 0.26667\n",
            "Epoch [20/10000], loss: 0.96854 acc: 0.40000 val_loss: 0.98850, val_acc: 0.26667\n",
            "Epoch [30/10000], loss: 0.92459 acc: 0.65333 val_loss: 0.93996, val_acc: 0.57333\n",
            "Epoch [40/10000], loss: 0.88568 acc: 0.70667 val_loss: 0.89704, val_acc: 0.62667\n",
            "Epoch [50/10000], loss: 0.85120 acc: 0.70667 val_loss: 0.85918, val_acc: 0.62667\n",
            "Epoch [60/10000], loss: 0.82059 acc: 0.70667 val_loss: 0.82572, val_acc: 0.62667\n",
            "Epoch [70/10000], loss: 0.79335 acc: 0.72000 val_loss: 0.79607, val_acc: 0.62667\n",
            "Epoch [80/10000], loss: 0.76900 acc: 0.72000 val_loss: 0.76968, val_acc: 0.65333\n",
            "Epoch [90/10000], loss: 0.74717 acc: 0.72000 val_loss: 0.74610, val_acc: 0.65333\n",
            "Epoch [100/10000], loss: 0.72750 acc: 0.76000 val_loss: 0.72494, val_acc: 0.69333\n",
            "Epoch [110/10000], loss: 0.70970 acc: 0.77333 val_loss: 0.70585, val_acc: 0.74667\n",
            "Epoch [120/10000], loss: 0.69354 acc: 0.81333 val_loss: 0.68856, val_acc: 0.76000\n",
            "Epoch [130/10000], loss: 0.67878 acc: 0.84000 val_loss: 0.67283, val_acc: 0.76000\n",
            "Epoch [140/10000], loss: 0.66526 acc: 0.84000 val_loss: 0.65846, val_acc: 0.78667\n",
            "Epoch [150/10000], loss: 0.65283 acc: 0.86667 val_loss: 0.64528, val_acc: 0.78667\n",
            "Epoch [160/10000], loss: 0.64135 acc: 0.88000 val_loss: 0.63313, val_acc: 0.78667\n",
            "Epoch [170/10000], loss: 0.63070 acc: 0.89333 val_loss: 0.62190, val_acc: 0.81333\n",
            "Epoch [180/10000], loss: 0.62081 acc: 0.90667 val_loss: 0.61149, val_acc: 0.81333\n",
            "Epoch [190/10000], loss: 0.61157 acc: 0.90667 val_loss: 0.60179, val_acc: 0.84000\n",
            "Epoch [200/10000], loss: 0.60292 acc: 0.90667 val_loss: 0.59273, val_acc: 0.84000\n",
            "Epoch [210/10000], loss: 0.59481 acc: 0.90667 val_loss: 0.58425, val_acc: 0.88000\n",
            "Epoch [220/10000], loss: 0.58717 acc: 0.93333 val_loss: 0.57628, val_acc: 0.88000\n",
            "Epoch [230/10000], loss: 0.57996 acc: 0.93333 val_loss: 0.56877, val_acc: 0.89333\n",
            "Epoch [240/10000], loss: 0.57313 acc: 0.93333 val_loss: 0.56169, val_acc: 0.90667\n",
            "Epoch [250/10000], loss: 0.56666 acc: 0.93333 val_loss: 0.55498, val_acc: 0.90667\n",
            "Epoch [260/10000], loss: 0.56051 acc: 0.92000 val_loss: 0.54862, val_acc: 0.90667\n",
            "Epoch [270/10000], loss: 0.55465 acc: 0.92000 val_loss: 0.54257, val_acc: 0.90667\n",
            "Epoch [280/10000], loss: 0.54906 acc: 0.92000 val_loss: 0.53681, val_acc: 0.90667\n",
            "Epoch [290/10000], loss: 0.54371 acc: 0.92000 val_loss: 0.53131, val_acc: 0.90667\n",
            "Epoch [300/10000], loss: 0.53859 acc: 0.93333 val_loss: 0.52605, val_acc: 0.90667\n",
            "Epoch [310/10000], loss: 0.53368 acc: 0.93333 val_loss: 0.52102, val_acc: 0.90667\n",
            "Epoch [320/10000], loss: 0.52896 acc: 0.93333 val_loss: 0.51619, val_acc: 0.90667\n",
            "Epoch [330/10000], loss: 0.52442 acc: 0.93333 val_loss: 0.51155, val_acc: 0.90667\n",
            "Epoch [340/10000], loss: 0.52004 acc: 0.93333 val_loss: 0.50709, val_acc: 0.90667\n",
            "Epoch [350/10000], loss: 0.51582 acc: 0.93333 val_loss: 0.50280, val_acc: 0.90667\n",
            "Epoch [360/10000], loss: 0.51173 acc: 0.93333 val_loss: 0.49865, val_acc: 0.90667\n",
            "Epoch [370/10000], loss: 0.50779 acc: 0.93333 val_loss: 0.49465, val_acc: 0.90667\n",
            "Epoch [380/10000], loss: 0.50397 acc: 0.93333 val_loss: 0.49078, val_acc: 0.90667\n",
            "Epoch [390/10000], loss: 0.50026 acc: 0.93333 val_loss: 0.48703, val_acc: 0.90667\n",
            "Epoch [400/10000], loss: 0.49666 acc: 0.94667 val_loss: 0.48340, val_acc: 0.90667\n",
            "Epoch [410/10000], loss: 0.49317 acc: 0.94667 val_loss: 0.47988, val_acc: 0.90667\n",
            "Epoch [420/10000], loss: 0.48978 acc: 0.94667 val_loss: 0.47647, val_acc: 0.90667\n",
            "Epoch [430/10000], loss: 0.48647 acc: 0.96000 val_loss: 0.47315, val_acc: 0.90667\n",
            "Epoch [440/10000], loss: 0.48326 acc: 0.96000 val_loss: 0.46992, val_acc: 0.90667\n",
            "Epoch [450/10000], loss: 0.48012 acc: 0.96000 val_loss: 0.46678, val_acc: 0.90667\n",
            "Epoch [460/10000], loss: 0.47706 acc: 0.96000 val_loss: 0.46372, val_acc: 0.90667\n",
            "Epoch [470/10000], loss: 0.47408 acc: 0.96000 val_loss: 0.46073, val_acc: 0.90667\n",
            "Epoch [480/10000], loss: 0.47116 acc: 0.96000 val_loss: 0.45783, val_acc: 0.90667\n",
            "Epoch [490/10000], loss: 0.46831 acc: 0.96000 val_loss: 0.45499, val_acc: 0.90667\n",
            "Epoch [500/10000], loss: 0.46553 acc: 0.96000 val_loss: 0.45221, val_acc: 0.90667\n",
            "Epoch [510/10000], loss: 0.46280 acc: 0.96000 val_loss: 0.44951, val_acc: 0.90667\n",
            "Epoch [520/10000], loss: 0.46013 acc: 0.96000 val_loss: 0.44686, val_acc: 0.90667\n",
            "Epoch [530/10000], loss: 0.45752 acc: 0.96000 val_loss: 0.44426, val_acc: 0.90667\n",
            "Epoch [540/10000], loss: 0.45496 acc: 0.96000 val_loss: 0.44173, val_acc: 0.90667\n",
            "Epoch [550/10000], loss: 0.45245 acc: 0.96000 val_loss: 0.43924, val_acc: 0.90667\n",
            "Epoch [560/10000], loss: 0.44998 acc: 0.96000 val_loss: 0.43681, val_acc: 0.90667\n",
            "Epoch [570/10000], loss: 0.44757 acc: 0.96000 val_loss: 0.43442, val_acc: 0.90667\n",
            "Epoch [580/10000], loss: 0.44519 acc: 0.96000 val_loss: 0.43208, val_acc: 0.90667\n",
            "Epoch [590/10000], loss: 0.44286 acc: 0.96000 val_loss: 0.42979, val_acc: 0.92000\n",
            "Epoch [600/10000], loss: 0.44057 acc: 0.96000 val_loss: 0.42753, val_acc: 0.92000\n",
            "Epoch [610/10000], loss: 0.43832 acc: 0.96000 val_loss: 0.42532, val_acc: 0.92000\n",
            "Epoch [620/10000], loss: 0.43611 acc: 0.96000 val_loss: 0.42315, val_acc: 0.92000\n",
            "Epoch [630/10000], loss: 0.43393 acc: 0.96000 val_loss: 0.42101, val_acc: 0.92000\n",
            "Epoch [640/10000], loss: 0.43179 acc: 0.96000 val_loss: 0.41891, val_acc: 0.92000\n",
            "Epoch [650/10000], loss: 0.42968 acc: 0.96000 val_loss: 0.41685, val_acc: 0.92000\n",
            "Epoch [660/10000], loss: 0.42761 acc: 0.96000 val_loss: 0.41482, val_acc: 0.92000\n",
            "Epoch [670/10000], loss: 0.42556 acc: 0.96000 val_loss: 0.41282, val_acc: 0.92000\n",
            "Epoch [680/10000], loss: 0.42355 acc: 0.96000 val_loss: 0.41085, val_acc: 0.92000\n",
            "Epoch [690/10000], loss: 0.42157 acc: 0.96000 val_loss: 0.40892, val_acc: 0.92000\n",
            "Epoch [700/10000], loss: 0.41961 acc: 0.96000 val_loss: 0.40701, val_acc: 0.92000\n",
            "Epoch [710/10000], loss: 0.41768 acc: 0.96000 val_loss: 0.40513, val_acc: 0.92000\n",
            "Epoch [720/10000], loss: 0.41578 acc: 0.96000 val_loss: 0.40329, val_acc: 0.92000\n",
            "Epoch [730/10000], loss: 0.41391 acc: 0.96000 val_loss: 0.40146, val_acc: 0.92000\n",
            "Epoch [740/10000], loss: 0.41206 acc: 0.96000 val_loss: 0.39967, val_acc: 0.92000\n",
            "Epoch [750/10000], loss: 0.41024 acc: 0.96000 val_loss: 0.39789, val_acc: 0.92000\n",
            "Epoch [760/10000], loss: 0.40844 acc: 0.96000 val_loss: 0.39615, val_acc: 0.92000\n",
            "Epoch [770/10000], loss: 0.40666 acc: 0.96000 val_loss: 0.39443, val_acc: 0.93333\n",
            "Epoch [780/10000], loss: 0.40491 acc: 0.96000 val_loss: 0.39273, val_acc: 0.93333\n",
            "Epoch [790/10000], loss: 0.40317 acc: 0.96000 val_loss: 0.39105, val_acc: 0.93333\n",
            "Epoch [800/10000], loss: 0.40146 acc: 0.96000 val_loss: 0.38939, val_acc: 0.93333\n",
            "Epoch [810/10000], loss: 0.39977 acc: 0.96000 val_loss: 0.38776, val_acc: 0.93333\n",
            "Epoch [820/10000], loss: 0.39810 acc: 0.96000 val_loss: 0.38615, val_acc: 0.93333\n",
            "Epoch [830/10000], loss: 0.39646 acc: 0.96000 val_loss: 0.38456, val_acc: 0.93333\n",
            "Epoch [840/10000], loss: 0.39483 acc: 0.96000 val_loss: 0.38298, val_acc: 0.93333\n",
            "Epoch [850/10000], loss: 0.39321 acc: 0.97333 val_loss: 0.38143, val_acc: 0.94667\n",
            "Epoch [860/10000], loss: 0.39162 acc: 0.97333 val_loss: 0.37990, val_acc: 0.94667\n",
            "Epoch [870/10000], loss: 0.39005 acc: 0.97333 val_loss: 0.37838, val_acc: 0.94667\n",
            "Epoch [880/10000], loss: 0.38849 acc: 0.97333 val_loss: 0.37688, val_acc: 0.94667\n",
            "Epoch [890/10000], loss: 0.38695 acc: 0.97333 val_loss: 0.37540, val_acc: 0.94667\n",
            "Epoch [900/10000], loss: 0.38543 acc: 0.97333 val_loss: 0.37394, val_acc: 0.94667\n",
            "Epoch [910/10000], loss: 0.38392 acc: 0.97333 val_loss: 0.37249, val_acc: 0.94667\n",
            "Epoch [920/10000], loss: 0.38243 acc: 0.97333 val_loss: 0.37106, val_acc: 0.94667\n",
            "Epoch [930/10000], loss: 0.38096 acc: 0.97333 val_loss: 0.36965, val_acc: 0.94667\n",
            "Epoch [940/10000], loss: 0.37950 acc: 0.97333 val_loss: 0.36825, val_acc: 0.94667\n",
            "Epoch [950/10000], loss: 0.37806 acc: 0.97333 val_loss: 0.36686, val_acc: 0.94667\n",
            "Epoch [960/10000], loss: 0.37663 acc: 0.97333 val_loss: 0.36550, val_acc: 0.96000\n",
            "Epoch [970/10000], loss: 0.37522 acc: 0.97333 val_loss: 0.36414, val_acc: 0.96000\n",
            "Epoch [980/10000], loss: 0.37382 acc: 0.97333 val_loss: 0.36280, val_acc: 0.96000\n",
            "Epoch [990/10000], loss: 0.37243 acc: 0.97333 val_loss: 0.36148, val_acc: 0.96000\n",
            "Epoch [1000/10000], loss: 0.37106 acc: 0.97333 val_loss: 0.36017, val_acc: 0.96000\n",
            "Epoch [1010/10000], loss: 0.36970 acc: 0.97333 val_loss: 0.35887, val_acc: 0.96000\n",
            "Epoch [1020/10000], loss: 0.36836 acc: 0.97333 val_loss: 0.35758, val_acc: 0.96000\n",
            "Epoch [1030/10000], loss: 0.36703 acc: 0.97333 val_loss: 0.35631, val_acc: 0.96000\n",
            "Epoch [1040/10000], loss: 0.36571 acc: 0.97333 val_loss: 0.35505, val_acc: 0.96000\n",
            "Epoch [1050/10000], loss: 0.36440 acc: 0.97333 val_loss: 0.35381, val_acc: 0.96000\n",
            "Epoch [1060/10000], loss: 0.36311 acc: 0.97333 val_loss: 0.35258, val_acc: 0.96000\n",
            "Epoch [1070/10000], loss: 0.36183 acc: 0.97333 val_loss: 0.35135, val_acc: 0.96000\n",
            "Epoch [1080/10000], loss: 0.36056 acc: 0.97333 val_loss: 0.35014, val_acc: 0.96000\n",
            "Epoch [1090/10000], loss: 0.35930 acc: 0.97333 val_loss: 0.34895, val_acc: 0.96000\n",
            "Epoch [1100/10000], loss: 0.35805 acc: 0.97333 val_loss: 0.34776, val_acc: 0.96000\n",
            "Epoch [1110/10000], loss: 0.35682 acc: 0.97333 val_loss: 0.34659, val_acc: 0.96000\n",
            "Epoch [1120/10000], loss: 0.35559 acc: 0.97333 val_loss: 0.34542, val_acc: 0.96000\n",
            "Epoch [1130/10000], loss: 0.35438 acc: 0.97333 val_loss: 0.34427, val_acc: 0.96000\n",
            "Epoch [1140/10000], loss: 0.35318 acc: 0.97333 val_loss: 0.34313, val_acc: 0.96000\n",
            "Epoch [1150/10000], loss: 0.35199 acc: 0.97333 val_loss: 0.34199, val_acc: 0.96000\n",
            "Epoch [1160/10000], loss: 0.35081 acc: 0.97333 val_loss: 0.34087, val_acc: 0.96000\n",
            "Epoch [1170/10000], loss: 0.34964 acc: 0.97333 val_loss: 0.33976, val_acc: 0.96000\n",
            "Epoch [1180/10000], loss: 0.34848 acc: 0.97333 val_loss: 0.33866, val_acc: 0.96000\n",
            "Epoch [1190/10000], loss: 0.34732 acc: 0.97333 val_loss: 0.33757, val_acc: 0.96000\n",
            "Epoch [1200/10000], loss: 0.34618 acc: 0.97333 val_loss: 0.33649, val_acc: 0.96000\n",
            "Epoch [1210/10000], loss: 0.34505 acc: 0.97333 val_loss: 0.33542, val_acc: 0.96000\n",
            "Epoch [1220/10000], loss: 0.34393 acc: 0.97333 val_loss: 0.33435, val_acc: 0.96000\n",
            "Epoch [1230/10000], loss: 0.34282 acc: 0.97333 val_loss: 0.33330, val_acc: 0.96000\n",
            "Epoch [1240/10000], loss: 0.34172 acc: 0.97333 val_loss: 0.33226, val_acc: 0.96000\n",
            "Epoch [1250/10000], loss: 0.34062 acc: 0.97333 val_loss: 0.33122, val_acc: 0.96000\n",
            "Epoch [1260/10000], loss: 0.33954 acc: 0.97333 val_loss: 0.33020, val_acc: 0.96000\n",
            "Epoch [1270/10000], loss: 0.33846 acc: 0.97333 val_loss: 0.32918, val_acc: 0.96000\n",
            "Epoch [1280/10000], loss: 0.33740 acc: 0.97333 val_loss: 0.32817, val_acc: 0.96000\n",
            "Epoch [1290/10000], loss: 0.33634 acc: 0.97333 val_loss: 0.32717, val_acc: 0.96000\n",
            "Epoch [1300/10000], loss: 0.33529 acc: 0.97333 val_loss: 0.32618, val_acc: 0.96000\n",
            "Epoch [1310/10000], loss: 0.33425 acc: 0.97333 val_loss: 0.32520, val_acc: 0.96000\n",
            "Epoch [1320/10000], loss: 0.33321 acc: 0.97333 val_loss: 0.32422, val_acc: 0.96000\n",
            "Epoch [1330/10000], loss: 0.33219 acc: 0.97333 val_loss: 0.32325, val_acc: 0.96000\n",
            "Epoch [1340/10000], loss: 0.33117 acc: 0.97333 val_loss: 0.32229, val_acc: 0.96000\n",
            "Epoch [1350/10000], loss: 0.33016 acc: 0.97333 val_loss: 0.32134, val_acc: 0.96000\n",
            "Epoch [1360/10000], loss: 0.32916 acc: 0.97333 val_loss: 0.32040, val_acc: 0.96000\n",
            "Epoch [1370/10000], loss: 0.32817 acc: 0.97333 val_loss: 0.31946, val_acc: 0.96000\n",
            "Epoch [1380/10000], loss: 0.32719 acc: 0.97333 val_loss: 0.31853, val_acc: 0.96000\n",
            "Epoch [1390/10000], loss: 0.32621 acc: 0.97333 val_loss: 0.31761, val_acc: 0.96000\n",
            "Epoch [1400/10000], loss: 0.32524 acc: 0.97333 val_loss: 0.31670, val_acc: 0.96000\n",
            "Epoch [1410/10000], loss: 0.32428 acc: 0.97333 val_loss: 0.31579, val_acc: 0.96000\n",
            "Epoch [1420/10000], loss: 0.32332 acc: 0.97333 val_loss: 0.31490, val_acc: 0.96000\n",
            "Epoch [1430/10000], loss: 0.32237 acc: 0.97333 val_loss: 0.31400, val_acc: 0.96000\n",
            "Epoch [1440/10000], loss: 0.32143 acc: 0.97333 val_loss: 0.31312, val_acc: 0.96000\n",
            "Epoch [1450/10000], loss: 0.32050 acc: 0.97333 val_loss: 0.31224, val_acc: 0.96000\n",
            "Epoch [1460/10000], loss: 0.31957 acc: 0.97333 val_loss: 0.31137, val_acc: 0.96000\n",
            "Epoch [1470/10000], loss: 0.31865 acc: 0.97333 val_loss: 0.31050, val_acc: 0.96000\n",
            "Epoch [1480/10000], loss: 0.31774 acc: 0.97333 val_loss: 0.30964, val_acc: 0.96000\n",
            "Epoch [1490/10000], loss: 0.31683 acc: 0.97333 val_loss: 0.30879, val_acc: 0.96000\n",
            "Epoch [1500/10000], loss: 0.31593 acc: 0.97333 val_loss: 0.30795, val_acc: 0.96000\n",
            "Epoch [1510/10000], loss: 0.31504 acc: 0.97333 val_loss: 0.30711, val_acc: 0.96000\n",
            "Epoch [1520/10000], loss: 0.31415 acc: 0.97333 val_loss: 0.30628, val_acc: 0.96000\n",
            "Epoch [1530/10000], loss: 0.31327 acc: 0.97333 val_loss: 0.30545, val_acc: 0.96000\n",
            "Epoch [1540/10000], loss: 0.31240 acc: 0.97333 val_loss: 0.30463, val_acc: 0.96000\n",
            "Epoch [1550/10000], loss: 0.31153 acc: 0.97333 val_loss: 0.30382, val_acc: 0.96000\n",
            "Epoch [1560/10000], loss: 0.31067 acc: 0.97333 val_loss: 0.30301, val_acc: 0.96000\n",
            "Epoch [1570/10000], loss: 0.30981 acc: 0.97333 val_loss: 0.30221, val_acc: 0.96000\n",
            "Epoch [1580/10000], loss: 0.30896 acc: 0.97333 val_loss: 0.30141, val_acc: 0.96000\n",
            "Epoch [1590/10000], loss: 0.30812 acc: 0.97333 val_loss: 0.30062, val_acc: 0.96000\n",
            "Epoch [1600/10000], loss: 0.30728 acc: 0.97333 val_loss: 0.29984, val_acc: 0.96000\n",
            "Epoch [1610/10000], loss: 0.30645 acc: 0.97333 val_loss: 0.29906, val_acc: 0.96000\n",
            "Epoch [1620/10000], loss: 0.30562 acc: 0.97333 val_loss: 0.29828, val_acc: 0.96000\n",
            "Epoch [1630/10000], loss: 0.30480 acc: 0.97333 val_loss: 0.29752, val_acc: 0.96000\n",
            "Epoch [1640/10000], loss: 0.30399 acc: 0.97333 val_loss: 0.29675, val_acc: 0.96000\n",
            "Epoch [1650/10000], loss: 0.30318 acc: 0.97333 val_loss: 0.29600, val_acc: 0.96000\n",
            "Epoch [1660/10000], loss: 0.30237 acc: 0.97333 val_loss: 0.29525, val_acc: 0.96000\n",
            "Epoch [1670/10000], loss: 0.30158 acc: 0.97333 val_loss: 0.29450, val_acc: 0.96000\n",
            "Epoch [1680/10000], loss: 0.30078 acc: 0.97333 val_loss: 0.29376, val_acc: 0.96000\n",
            "Epoch [1690/10000], loss: 0.30000 acc: 0.97333 val_loss: 0.29302, val_acc: 0.96000\n",
            "Epoch [1700/10000], loss: 0.29922 acc: 0.97333 val_loss: 0.29229, val_acc: 0.96000\n",
            "Epoch [1710/10000], loss: 0.29844 acc: 0.97333 val_loss: 0.29157, val_acc: 0.96000\n",
            "Epoch [1720/10000], loss: 0.29767 acc: 0.97333 val_loss: 0.29085, val_acc: 0.96000\n",
            "Epoch [1730/10000], loss: 0.29690 acc: 0.97333 val_loss: 0.29013, val_acc: 0.96000\n",
            "Epoch [1740/10000], loss: 0.29614 acc: 0.97333 val_loss: 0.28942, val_acc: 0.96000\n",
            "Epoch [1750/10000], loss: 0.29538 acc: 0.97333 val_loss: 0.28872, val_acc: 0.96000\n",
            "Epoch [1760/10000], loss: 0.29463 acc: 0.97333 val_loss: 0.28801, val_acc: 0.96000\n",
            "Epoch [1770/10000], loss: 0.29389 acc: 0.97333 val_loss: 0.28732, val_acc: 0.96000\n",
            "Epoch [1780/10000], loss: 0.29315 acc: 0.97333 val_loss: 0.28663, val_acc: 0.96000\n",
            "Epoch [1790/10000], loss: 0.29241 acc: 0.97333 val_loss: 0.28594, val_acc: 0.96000\n",
            "Epoch [1800/10000], loss: 0.29168 acc: 0.97333 val_loss: 0.28526, val_acc: 0.96000\n",
            "Epoch [1810/10000], loss: 0.29095 acc: 0.97333 val_loss: 0.28458, val_acc: 0.96000\n",
            "Epoch [1820/10000], loss: 0.29023 acc: 0.97333 val_loss: 0.28391, val_acc: 0.96000\n",
            "Epoch [1830/10000], loss: 0.28951 acc: 0.97333 val_loss: 0.28324, val_acc: 0.96000\n",
            "Epoch [1840/10000], loss: 0.28880 acc: 0.97333 val_loss: 0.28258, val_acc: 0.96000\n",
            "Epoch [1850/10000], loss: 0.28809 acc: 0.97333 val_loss: 0.28192, val_acc: 0.96000\n",
            "Epoch [1860/10000], loss: 0.28739 acc: 0.97333 val_loss: 0.28126, val_acc: 0.96000\n",
            "Epoch [1870/10000], loss: 0.28669 acc: 0.97333 val_loss: 0.28061, val_acc: 0.96000\n",
            "Epoch [1880/10000], loss: 0.28599 acc: 0.97333 val_loss: 0.27996, val_acc: 0.96000\n",
            "Epoch [1890/10000], loss: 0.28530 acc: 0.97333 val_loss: 0.27932, val_acc: 0.96000\n",
            "Epoch [1900/10000], loss: 0.28462 acc: 0.97333 val_loss: 0.27868, val_acc: 0.96000\n",
            "Epoch [1910/10000], loss: 0.28394 acc: 0.97333 val_loss: 0.27805, val_acc: 0.96000\n",
            "Epoch [1920/10000], loss: 0.28326 acc: 0.97333 val_loss: 0.27742, val_acc: 0.96000\n",
            "Epoch [1930/10000], loss: 0.28258 acc: 0.97333 val_loss: 0.27679, val_acc: 0.96000\n",
            "Epoch [1940/10000], loss: 0.28192 acc: 0.97333 val_loss: 0.27617, val_acc: 0.96000\n",
            "Epoch [1950/10000], loss: 0.28125 acc: 0.97333 val_loss: 0.27555, val_acc: 0.96000\n",
            "Epoch [1960/10000], loss: 0.28059 acc: 0.97333 val_loss: 0.27494, val_acc: 0.96000\n",
            "Epoch [1970/10000], loss: 0.27993 acc: 0.97333 val_loss: 0.27433, val_acc: 0.96000\n",
            "Epoch [1980/10000], loss: 0.27928 acc: 0.97333 val_loss: 0.27372, val_acc: 0.96000\n",
            "Epoch [1990/10000], loss: 0.27863 acc: 0.97333 val_loss: 0.27312, val_acc: 0.96000\n",
            "Epoch [2000/10000], loss: 0.27799 acc: 0.97333 val_loss: 0.27252, val_acc: 0.96000\n",
            "Epoch [2010/10000], loss: 0.27735 acc: 0.97333 val_loss: 0.27193, val_acc: 0.96000\n",
            "Epoch [2020/10000], loss: 0.27671 acc: 0.97333 val_loss: 0.27134, val_acc: 0.96000\n",
            "Epoch [2030/10000], loss: 0.27608 acc: 0.97333 val_loss: 0.27075, val_acc: 0.96000\n",
            "Epoch [2040/10000], loss: 0.27545 acc: 0.97333 val_loss: 0.27016, val_acc: 0.96000\n",
            "Epoch [2050/10000], loss: 0.27482 acc: 0.97333 val_loss: 0.26958, val_acc: 0.96000\n",
            "Epoch [2060/10000], loss: 0.27420 acc: 0.97333 val_loss: 0.26901, val_acc: 0.96000\n",
            "Epoch [2070/10000], loss: 0.27358 acc: 0.97333 val_loss: 0.26843, val_acc: 0.96000\n",
            "Epoch [2080/10000], loss: 0.27297 acc: 0.97333 val_loss: 0.26786, val_acc: 0.96000\n",
            "Epoch [2090/10000], loss: 0.27236 acc: 0.97333 val_loss: 0.26730, val_acc: 0.96000\n",
            "Epoch [2100/10000], loss: 0.27175 acc: 0.97333 val_loss: 0.26674, val_acc: 0.96000\n",
            "Epoch [2110/10000], loss: 0.27115 acc: 0.97333 val_loss: 0.26618, val_acc: 0.96000\n",
            "Epoch [2120/10000], loss: 0.27055 acc: 0.97333 val_loss: 0.26562, val_acc: 0.96000\n",
            "Epoch [2130/10000], loss: 0.26995 acc: 0.97333 val_loss: 0.26507, val_acc: 0.96000\n",
            "Epoch [2140/10000], loss: 0.26936 acc: 0.97333 val_loss: 0.26452, val_acc: 0.96000\n",
            "Epoch [2150/10000], loss: 0.26877 acc: 0.97333 val_loss: 0.26397, val_acc: 0.96000\n",
            "Epoch [2160/10000], loss: 0.26818 acc: 0.97333 val_loss: 0.26343, val_acc: 0.96000\n",
            "Epoch [2170/10000], loss: 0.26760 acc: 0.97333 val_loss: 0.26289, val_acc: 0.96000\n",
            "Epoch [2180/10000], loss: 0.26702 acc: 0.97333 val_loss: 0.26236, val_acc: 0.96000\n",
            "Epoch [2190/10000], loss: 0.26644 acc: 0.97333 val_loss: 0.26182, val_acc: 0.96000\n",
            "Epoch [2200/10000], loss: 0.26587 acc: 0.97333 val_loss: 0.26129, val_acc: 0.96000\n",
            "Epoch [2210/10000], loss: 0.26530 acc: 0.97333 val_loss: 0.26077, val_acc: 0.96000\n",
            "Epoch [2220/10000], loss: 0.26473 acc: 0.97333 val_loss: 0.26024, val_acc: 0.96000\n",
            "Epoch [2230/10000], loss: 0.26417 acc: 0.97333 val_loss: 0.25972, val_acc: 0.96000\n",
            "Epoch [2240/10000], loss: 0.26361 acc: 0.97333 val_loss: 0.25921, val_acc: 0.96000\n",
            "Epoch [2250/10000], loss: 0.26305 acc: 0.97333 val_loss: 0.25869, val_acc: 0.96000\n",
            "Epoch [2260/10000], loss: 0.26250 acc: 0.97333 val_loss: 0.25818, val_acc: 0.96000\n",
            "Epoch [2270/10000], loss: 0.26195 acc: 0.97333 val_loss: 0.25767, val_acc: 0.96000\n",
            "Epoch [2280/10000], loss: 0.26140 acc: 0.97333 val_loss: 0.25717, val_acc: 0.96000\n",
            "Epoch [2290/10000], loss: 0.26086 acc: 0.97333 val_loss: 0.25666, val_acc: 0.96000\n",
            "Epoch [2300/10000], loss: 0.26032 acc: 0.97333 val_loss: 0.25616, val_acc: 0.96000\n",
            "Epoch [2310/10000], loss: 0.25978 acc: 0.97333 val_loss: 0.25567, val_acc: 0.96000\n",
            "Epoch [2320/10000], loss: 0.25924 acc: 0.97333 val_loss: 0.25517, val_acc: 0.96000\n",
            "Epoch [2330/10000], loss: 0.25871 acc: 0.97333 val_loss: 0.25468, val_acc: 0.96000\n",
            "Epoch [2340/10000], loss: 0.25818 acc: 0.97333 val_loss: 0.25419, val_acc: 0.96000\n",
            "Epoch [2350/10000], loss: 0.25766 acc: 0.97333 val_loss: 0.25371, val_acc: 0.96000\n",
            "Epoch [2360/10000], loss: 0.25713 acc: 0.97333 val_loss: 0.25322, val_acc: 0.96000\n",
            "Epoch [2370/10000], loss: 0.25661 acc: 0.97333 val_loss: 0.25274, val_acc: 0.96000\n",
            "Epoch [2380/10000], loss: 0.25609 acc: 0.97333 val_loss: 0.25227, val_acc: 0.96000\n",
            "Epoch [2390/10000], loss: 0.25558 acc: 0.97333 val_loss: 0.25179, val_acc: 0.96000\n",
            "Epoch [2400/10000], loss: 0.25507 acc: 0.97333 val_loss: 0.25132, val_acc: 0.96000\n",
            "Epoch [2410/10000], loss: 0.25456 acc: 0.97333 val_loss: 0.25085, val_acc: 0.96000\n",
            "Epoch [2420/10000], loss: 0.25405 acc: 0.97333 val_loss: 0.25038, val_acc: 0.96000\n",
            "Epoch [2430/10000], loss: 0.25355 acc: 0.97333 val_loss: 0.24992, val_acc: 0.96000\n",
            "Epoch [2440/10000], loss: 0.25304 acc: 0.97333 val_loss: 0.24946, val_acc: 0.96000\n",
            "Epoch [2450/10000], loss: 0.25255 acc: 0.97333 val_loss: 0.24900, val_acc: 0.96000\n",
            "Epoch [2460/10000], loss: 0.25205 acc: 0.97333 val_loss: 0.24854, val_acc: 0.96000\n",
            "Epoch [2470/10000], loss: 0.25156 acc: 0.97333 val_loss: 0.24809, val_acc: 0.96000\n",
            "Epoch [2480/10000], loss: 0.25107 acc: 0.97333 val_loss: 0.24764, val_acc: 0.96000\n",
            "Epoch [2490/10000], loss: 0.25058 acc: 0.97333 val_loss: 0.24719, val_acc: 0.96000\n",
            "Epoch [2500/10000], loss: 0.25009 acc: 0.97333 val_loss: 0.24674, val_acc: 0.96000\n",
            "Epoch [2510/10000], loss: 0.24961 acc: 0.97333 val_loss: 0.24630, val_acc: 0.96000\n",
            "Epoch [2520/10000], loss: 0.24913 acc: 0.97333 val_loss: 0.24585, val_acc: 0.96000\n",
            "Epoch [2530/10000], loss: 0.24865 acc: 0.97333 val_loss: 0.24541, val_acc: 0.96000\n",
            "Epoch [2540/10000], loss: 0.24818 acc: 0.97333 val_loss: 0.24498, val_acc: 0.96000\n",
            "Epoch [2550/10000], loss: 0.24770 acc: 0.97333 val_loss: 0.24454, val_acc: 0.96000\n",
            "Epoch [2560/10000], loss: 0.24723 acc: 0.97333 val_loss: 0.24411, val_acc: 0.96000\n",
            "Epoch [2570/10000], loss: 0.24676 acc: 0.97333 val_loss: 0.24368, val_acc: 0.96000\n",
            "Epoch [2580/10000], loss: 0.24630 acc: 0.98667 val_loss: 0.24325, val_acc: 0.96000\n",
            "Epoch [2590/10000], loss: 0.24584 acc: 0.98667 val_loss: 0.24283, val_acc: 0.96000\n",
            "Epoch [2600/10000], loss: 0.24537 acc: 0.98667 val_loss: 0.24240, val_acc: 0.96000\n",
            "Epoch [2610/10000], loss: 0.24492 acc: 0.98667 val_loss: 0.24198, val_acc: 0.96000\n",
            "Epoch [2620/10000], loss: 0.24446 acc: 0.98667 val_loss: 0.24156, val_acc: 0.96000\n",
            "Epoch [2630/10000], loss: 0.24401 acc: 0.98667 val_loss: 0.24115, val_acc: 0.96000\n",
            "Epoch [2640/10000], loss: 0.24355 acc: 0.98667 val_loss: 0.24073, val_acc: 0.96000\n",
            "Epoch [2650/10000], loss: 0.24311 acc: 0.98667 val_loss: 0.24032, val_acc: 0.96000\n",
            "Epoch [2660/10000], loss: 0.24266 acc: 0.98667 val_loss: 0.23991, val_acc: 0.96000\n",
            "Epoch [2670/10000], loss: 0.24221 acc: 0.98667 val_loss: 0.23950, val_acc: 0.96000\n",
            "Epoch [2680/10000], loss: 0.24177 acc: 0.98667 val_loss: 0.23909, val_acc: 0.96000\n",
            "Epoch [2690/10000], loss: 0.24133 acc: 0.98667 val_loss: 0.23869, val_acc: 0.96000\n",
            "Epoch [2700/10000], loss: 0.24089 acc: 0.98667 val_loss: 0.23829, val_acc: 0.96000\n",
            "Epoch [2710/10000], loss: 0.24046 acc: 0.98667 val_loss: 0.23789, val_acc: 0.96000\n",
            "Epoch [2720/10000], loss: 0.24002 acc: 0.98667 val_loss: 0.23749, val_acc: 0.96000\n",
            "Epoch [2730/10000], loss: 0.23959 acc: 0.98667 val_loss: 0.23710, val_acc: 0.96000\n",
            "Epoch [2740/10000], loss: 0.23916 acc: 0.98667 val_loss: 0.23670, val_acc: 0.96000\n",
            "Epoch [2750/10000], loss: 0.23874 acc: 0.98667 val_loss: 0.23631, val_acc: 0.96000\n",
            "Epoch [2760/10000], loss: 0.23831 acc: 0.98667 val_loss: 0.23592, val_acc: 0.96000\n",
            "Epoch [2770/10000], loss: 0.23789 acc: 0.98667 val_loss: 0.23553, val_acc: 0.96000\n",
            "Epoch [2780/10000], loss: 0.23747 acc: 0.98667 val_loss: 0.23515, val_acc: 0.96000\n",
            "Epoch [2790/10000], loss: 0.23705 acc: 0.98667 val_loss: 0.23476, val_acc: 0.96000\n",
            "Epoch [2800/10000], loss: 0.23663 acc: 0.98667 val_loss: 0.23438, val_acc: 0.96000\n",
            "Epoch [2810/10000], loss: 0.23622 acc: 0.98667 val_loss: 0.23400, val_acc: 0.96000\n",
            "Epoch [2820/10000], loss: 0.23580 acc: 0.98667 val_loss: 0.23363, val_acc: 0.96000\n",
            "Epoch [2830/10000], loss: 0.23539 acc: 0.98667 val_loss: 0.23325, val_acc: 0.96000\n",
            "Epoch [2840/10000], loss: 0.23498 acc: 0.98667 val_loss: 0.23287, val_acc: 0.96000\n",
            "Epoch [2850/10000], loss: 0.23458 acc: 0.98667 val_loss: 0.23250, val_acc: 0.96000\n",
            "Epoch [2860/10000], loss: 0.23417 acc: 0.98667 val_loss: 0.23213, val_acc: 0.96000\n",
            "Epoch [2870/10000], loss: 0.23377 acc: 0.98667 val_loss: 0.23176, val_acc: 0.96000\n",
            "Epoch [2880/10000], loss: 0.23337 acc: 0.98667 val_loss: 0.23140, val_acc: 0.96000\n",
            "Epoch [2890/10000], loss: 0.23297 acc: 0.98667 val_loss: 0.23103, val_acc: 0.96000\n",
            "Epoch [2900/10000], loss: 0.23257 acc: 0.98667 val_loss: 0.23067, val_acc: 0.96000\n",
            "Epoch [2910/10000], loss: 0.23218 acc: 0.98667 val_loss: 0.23031, val_acc: 0.96000\n",
            "Epoch [2920/10000], loss: 0.23178 acc: 0.98667 val_loss: 0.22995, val_acc: 0.96000\n",
            "Epoch [2930/10000], loss: 0.23139 acc: 0.98667 val_loss: 0.22959, val_acc: 0.96000\n",
            "Epoch [2940/10000], loss: 0.23100 acc: 0.98667 val_loss: 0.22923, val_acc: 0.96000\n",
            "Epoch [2950/10000], loss: 0.23061 acc: 0.98667 val_loss: 0.22888, val_acc: 0.96000\n",
            "Epoch [2960/10000], loss: 0.23023 acc: 0.98667 val_loss: 0.22853, val_acc: 0.96000\n",
            "Epoch [2970/10000], loss: 0.22984 acc: 0.98667 val_loss: 0.22818, val_acc: 0.96000\n",
            "Epoch [2980/10000], loss: 0.22946 acc: 0.98667 val_loss: 0.22783, val_acc: 0.96000\n",
            "Epoch [2990/10000], loss: 0.22908 acc: 0.98667 val_loss: 0.22748, val_acc: 0.96000\n",
            "Epoch [3000/10000], loss: 0.22870 acc: 0.98667 val_loss: 0.22713, val_acc: 0.96000\n",
            "Epoch [3010/10000], loss: 0.22832 acc: 0.98667 val_loss: 0.22679, val_acc: 0.96000\n",
            "Epoch [3020/10000], loss: 0.22795 acc: 0.98667 val_loss: 0.22645, val_acc: 0.96000\n",
            "Epoch [3030/10000], loss: 0.22757 acc: 0.98667 val_loss: 0.22610, val_acc: 0.96000\n",
            "Epoch [3040/10000], loss: 0.22720 acc: 0.98667 val_loss: 0.22577, val_acc: 0.96000\n",
            "Epoch [3050/10000], loss: 0.22683 acc: 0.98667 val_loss: 0.22543, val_acc: 0.96000\n",
            "Epoch [3060/10000], loss: 0.22646 acc: 0.98667 val_loss: 0.22509, val_acc: 0.96000\n",
            "Epoch [3070/10000], loss: 0.22610 acc: 0.98667 val_loss: 0.22476, val_acc: 0.96000\n",
            "Epoch [3080/10000], loss: 0.22573 acc: 0.98667 val_loss: 0.22442, val_acc: 0.96000\n",
            "Epoch [3090/10000], loss: 0.22537 acc: 0.98667 val_loss: 0.22409, val_acc: 0.96000\n",
            "Epoch [3100/10000], loss: 0.22501 acc: 0.98667 val_loss: 0.22376, val_acc: 0.96000\n",
            "Epoch [3110/10000], loss: 0.22465 acc: 0.98667 val_loss: 0.22343, val_acc: 0.96000\n",
            "Epoch [3120/10000], loss: 0.22429 acc: 0.98667 val_loss: 0.22311, val_acc: 0.96000\n",
            "Epoch [3130/10000], loss: 0.22393 acc: 0.98667 val_loss: 0.22278, val_acc: 0.96000\n",
            "Epoch [3140/10000], loss: 0.22358 acc: 0.98667 val_loss: 0.22246, val_acc: 0.96000\n",
            "Epoch [3150/10000], loss: 0.22322 acc: 0.98667 val_loss: 0.22214, val_acc: 0.96000\n",
            "Epoch [3160/10000], loss: 0.22287 acc: 0.98667 val_loss: 0.22181, val_acc: 0.96000\n",
            "Epoch [3170/10000], loss: 0.22252 acc: 0.98667 val_loss: 0.22150, val_acc: 0.96000\n",
            "Epoch [3180/10000], loss: 0.22217 acc: 0.98667 val_loss: 0.22118, val_acc: 0.96000\n",
            "Epoch [3190/10000], loss: 0.22182 acc: 0.98667 val_loss: 0.22086, val_acc: 0.96000\n",
            "Epoch [3200/10000], loss: 0.22148 acc: 0.98667 val_loss: 0.22055, val_acc: 0.96000\n",
            "Epoch [3210/10000], loss: 0.22113 acc: 0.98667 val_loss: 0.22023, val_acc: 0.96000\n",
            "Epoch [3220/10000], loss: 0.22079 acc: 0.98667 val_loss: 0.21992, val_acc: 0.96000\n",
            "Epoch [3230/10000], loss: 0.22045 acc: 0.98667 val_loss: 0.21961, val_acc: 0.96000\n",
            "Epoch [3240/10000], loss: 0.22011 acc: 0.98667 val_loss: 0.21930, val_acc: 0.96000\n",
            "Epoch [3250/10000], loss: 0.21977 acc: 0.98667 val_loss: 0.21899, val_acc: 0.96000\n",
            "Epoch [3260/10000], loss: 0.21943 acc: 0.98667 val_loss: 0.21869, val_acc: 0.96000\n",
            "Epoch [3270/10000], loss: 0.21910 acc: 0.98667 val_loss: 0.21838, val_acc: 0.96000\n",
            "Epoch [3280/10000], loss: 0.21876 acc: 0.98667 val_loss: 0.21808, val_acc: 0.96000\n",
            "Epoch [3290/10000], loss: 0.21843 acc: 0.98667 val_loss: 0.21778, val_acc: 0.96000\n",
            "Epoch [3300/10000], loss: 0.21810 acc: 0.98667 val_loss: 0.21747, val_acc: 0.96000\n",
            "Epoch [3310/10000], loss: 0.21777 acc: 0.98667 val_loss: 0.21717, val_acc: 0.96000\n",
            "Epoch [3320/10000], loss: 0.21744 acc: 0.98667 val_loss: 0.21688, val_acc: 0.96000\n",
            "Epoch [3330/10000], loss: 0.21711 acc: 0.98667 val_loss: 0.21658, val_acc: 0.96000\n",
            "Epoch [3340/10000], loss: 0.21679 acc: 0.98667 val_loss: 0.21628, val_acc: 0.96000\n",
            "Epoch [3350/10000], loss: 0.21646 acc: 0.98667 val_loss: 0.21599, val_acc: 0.96000\n",
            "Epoch [3360/10000], loss: 0.21614 acc: 0.98667 val_loss: 0.21570, val_acc: 0.96000\n",
            "Epoch [3370/10000], loss: 0.21582 acc: 0.98667 val_loss: 0.21540, val_acc: 0.96000\n",
            "Epoch [3380/10000], loss: 0.21550 acc: 0.98667 val_loss: 0.21511, val_acc: 0.96000\n",
            "Epoch [3390/10000], loss: 0.21518 acc: 0.98667 val_loss: 0.21483, val_acc: 0.96000\n",
            "Epoch [3400/10000], loss: 0.21487 acc: 0.98667 val_loss: 0.21454, val_acc: 0.96000\n",
            "Epoch [3410/10000], loss: 0.21455 acc: 0.98667 val_loss: 0.21425, val_acc: 0.96000\n",
            "Epoch [3420/10000], loss: 0.21424 acc: 0.98667 val_loss: 0.21396, val_acc: 0.96000\n",
            "Epoch [3430/10000], loss: 0.21392 acc: 0.98667 val_loss: 0.21368, val_acc: 0.96000\n",
            "Epoch [3440/10000], loss: 0.21361 acc: 0.98667 val_loss: 0.21340, val_acc: 0.96000\n",
            "Epoch [3450/10000], loss: 0.21330 acc: 0.98667 val_loss: 0.21312, val_acc: 0.96000\n",
            "Epoch [3460/10000], loss: 0.21299 acc: 0.98667 val_loss: 0.21284, val_acc: 0.96000\n",
            "Epoch [3470/10000], loss: 0.21268 acc: 0.98667 val_loss: 0.21256, val_acc: 0.96000\n",
            "Epoch [3480/10000], loss: 0.21238 acc: 0.98667 val_loss: 0.21228, val_acc: 0.96000\n",
            "Epoch [3490/10000], loss: 0.21207 acc: 0.98667 val_loss: 0.21200, val_acc: 0.96000\n",
            "Epoch [3500/10000], loss: 0.21177 acc: 0.98667 val_loss: 0.21173, val_acc: 0.96000\n",
            "Epoch [3510/10000], loss: 0.21146 acc: 0.98667 val_loss: 0.21145, val_acc: 0.96000\n",
            "Epoch [3520/10000], loss: 0.21116 acc: 0.98667 val_loss: 0.21118, val_acc: 0.96000\n",
            "Epoch [3530/10000], loss: 0.21086 acc: 0.98667 val_loss: 0.21091, val_acc: 0.96000\n",
            "Epoch [3540/10000], loss: 0.21056 acc: 0.98667 val_loss: 0.21064, val_acc: 0.96000\n",
            "Epoch [3550/10000], loss: 0.21026 acc: 0.98667 val_loss: 0.21037, val_acc: 0.96000\n",
            "Epoch [3560/10000], loss: 0.20997 acc: 0.98667 val_loss: 0.21010, val_acc: 0.96000\n",
            "Epoch [3570/10000], loss: 0.20967 acc: 0.98667 val_loss: 0.20983, val_acc: 0.96000\n",
            "Epoch [3580/10000], loss: 0.20938 acc: 0.98667 val_loss: 0.20956, val_acc: 0.96000\n",
            "Epoch [3590/10000], loss: 0.20909 acc: 0.98667 val_loss: 0.20930, val_acc: 0.96000\n",
            "Epoch [3600/10000], loss: 0.20879 acc: 0.98667 val_loss: 0.20903, val_acc: 0.96000\n",
            "Epoch [3610/10000], loss: 0.20850 acc: 0.98667 val_loss: 0.20877, val_acc: 0.96000\n",
            "Epoch [3620/10000], loss: 0.20821 acc: 0.98667 val_loss: 0.20851, val_acc: 0.96000\n",
            "Epoch [3630/10000], loss: 0.20793 acc: 0.98667 val_loss: 0.20825, val_acc: 0.96000\n",
            "Epoch [3640/10000], loss: 0.20764 acc: 0.98667 val_loss: 0.20799, val_acc: 0.96000\n",
            "Epoch [3650/10000], loss: 0.20735 acc: 0.98667 val_loss: 0.20773, val_acc: 0.96000\n",
            "Epoch [3660/10000], loss: 0.20707 acc: 0.98667 val_loss: 0.20747, val_acc: 0.96000\n",
            "Epoch [3670/10000], loss: 0.20678 acc: 0.98667 val_loss: 0.20721, val_acc: 0.96000\n",
            "Epoch [3680/10000], loss: 0.20650 acc: 0.98667 val_loss: 0.20696, val_acc: 0.96000\n",
            "Epoch [3690/10000], loss: 0.20622 acc: 0.98667 val_loss: 0.20670, val_acc: 0.96000\n",
            "Epoch [3700/10000], loss: 0.20594 acc: 0.98667 val_loss: 0.20645, val_acc: 0.96000\n",
            "Epoch [3710/10000], loss: 0.20566 acc: 0.98667 val_loss: 0.20620, val_acc: 0.96000\n",
            "Epoch [3720/10000], loss: 0.20538 acc: 0.98667 val_loss: 0.20595, val_acc: 0.96000\n",
            "Epoch [3730/10000], loss: 0.20511 acc: 0.98667 val_loss: 0.20570, val_acc: 0.96000\n",
            "Epoch [3740/10000], loss: 0.20483 acc: 0.98667 val_loss: 0.20545, val_acc: 0.96000\n",
            "Epoch [3750/10000], loss: 0.20455 acc: 0.98667 val_loss: 0.20520, val_acc: 0.96000\n",
            "Epoch [3760/10000], loss: 0.20428 acc: 0.98667 val_loss: 0.20495, val_acc: 0.96000\n",
            "Epoch [3770/10000], loss: 0.20401 acc: 0.98667 val_loss: 0.20471, val_acc: 0.96000\n",
            "Epoch [3780/10000], loss: 0.20374 acc: 0.98667 val_loss: 0.20446, val_acc: 0.96000\n",
            "Epoch [3790/10000], loss: 0.20347 acc: 0.98667 val_loss: 0.20422, val_acc: 0.96000\n",
            "Epoch [3800/10000], loss: 0.20320 acc: 0.98667 val_loss: 0.20397, val_acc: 0.96000\n",
            "Epoch [3810/10000], loss: 0.20293 acc: 0.98667 val_loss: 0.20373, val_acc: 0.96000\n",
            "Epoch [3820/10000], loss: 0.20266 acc: 0.98667 val_loss: 0.20349, val_acc: 0.96000\n",
            "Epoch [3830/10000], loss: 0.20239 acc: 0.98667 val_loss: 0.20325, val_acc: 0.96000\n",
            "Epoch [3840/10000], loss: 0.20213 acc: 0.98667 val_loss: 0.20301, val_acc: 0.96000\n",
            "Epoch [3850/10000], loss: 0.20186 acc: 0.98667 val_loss: 0.20277, val_acc: 0.96000\n",
            "Epoch [3860/10000], loss: 0.20160 acc: 0.98667 val_loss: 0.20253, val_acc: 0.96000\n",
            "Epoch [3870/10000], loss: 0.20134 acc: 0.98667 val_loss: 0.20230, val_acc: 0.96000\n",
            "Epoch [3880/10000], loss: 0.20108 acc: 0.98667 val_loss: 0.20206, val_acc: 0.96000\n",
            "Epoch [3890/10000], loss: 0.20082 acc: 0.98667 val_loss: 0.20183, val_acc: 0.96000\n",
            "Epoch [3900/10000], loss: 0.20056 acc: 0.98667 val_loss: 0.20159, val_acc: 0.96000\n",
            "Epoch [3910/10000], loss: 0.20030 acc: 0.98667 val_loss: 0.20136, val_acc: 0.96000\n",
            "Epoch [3920/10000], loss: 0.20004 acc: 0.98667 val_loss: 0.20113, val_acc: 0.96000\n",
            "Epoch [3930/10000], loss: 0.19979 acc: 0.98667 val_loss: 0.20090, val_acc: 0.96000\n",
            "Epoch [3940/10000], loss: 0.19953 acc: 0.98667 val_loss: 0.20067, val_acc: 0.96000\n",
            "Epoch [3950/10000], loss: 0.19928 acc: 0.98667 val_loss: 0.20044, val_acc: 0.96000\n",
            "Epoch [3960/10000], loss: 0.19902 acc: 0.98667 val_loss: 0.20021, val_acc: 0.96000\n",
            "Epoch [3970/10000], loss: 0.19877 acc: 0.98667 val_loss: 0.19998, val_acc: 0.96000\n",
            "Epoch [3980/10000], loss: 0.19852 acc: 0.98667 val_loss: 0.19976, val_acc: 0.96000\n",
            "Epoch [3990/10000], loss: 0.19827 acc: 0.98667 val_loss: 0.19953, val_acc: 0.96000\n",
            "Epoch [4000/10000], loss: 0.19802 acc: 0.98667 val_loss: 0.19931, val_acc: 0.96000\n",
            "Epoch [4010/10000], loss: 0.19777 acc: 0.98667 val_loss: 0.19908, val_acc: 0.96000\n",
            "Epoch [4020/10000], loss: 0.19752 acc: 0.98667 val_loss: 0.19886, val_acc: 0.96000\n",
            "Epoch [4030/10000], loss: 0.19728 acc: 0.98667 val_loss: 0.19864, val_acc: 0.96000\n",
            "Epoch [4040/10000], loss: 0.19703 acc: 0.98667 val_loss: 0.19842, val_acc: 0.96000\n",
            "Epoch [4050/10000], loss: 0.19679 acc: 0.98667 val_loss: 0.19820, val_acc: 0.96000\n",
            "Epoch [4060/10000], loss: 0.19654 acc: 0.98667 val_loss: 0.19798, val_acc: 0.96000\n",
            "Epoch [4070/10000], loss: 0.19630 acc: 0.98667 val_loss: 0.19776, val_acc: 0.96000\n",
            "Epoch [4080/10000], loss: 0.19606 acc: 0.98667 val_loss: 0.19754, val_acc: 0.96000\n",
            "Epoch [4090/10000], loss: 0.19582 acc: 0.98667 val_loss: 0.19732, val_acc: 0.96000\n",
            "Epoch [4100/10000], loss: 0.19557 acc: 0.98667 val_loss: 0.19711, val_acc: 0.96000\n",
            "Epoch [4110/10000], loss: 0.19534 acc: 0.98667 val_loss: 0.19689, val_acc: 0.96000\n",
            "Epoch [4120/10000], loss: 0.19510 acc: 0.98667 val_loss: 0.19668, val_acc: 0.96000\n",
            "Epoch [4130/10000], loss: 0.19486 acc: 0.98667 val_loss: 0.19646, val_acc: 0.96000\n",
            "Epoch [4140/10000], loss: 0.19462 acc: 0.98667 val_loss: 0.19625, val_acc: 0.96000\n",
            "Epoch [4150/10000], loss: 0.19439 acc: 0.98667 val_loss: 0.19604, val_acc: 0.96000\n",
            "Epoch [4160/10000], loss: 0.19415 acc: 0.98667 val_loss: 0.19583, val_acc: 0.96000\n",
            "Epoch [4170/10000], loss: 0.19392 acc: 0.98667 val_loss: 0.19562, val_acc: 0.96000\n",
            "Epoch [4180/10000], loss: 0.19368 acc: 0.98667 val_loss: 0.19541, val_acc: 0.96000\n",
            "Epoch [4190/10000], loss: 0.19345 acc: 0.98667 val_loss: 0.19520, val_acc: 0.96000\n",
            "Epoch [4200/10000], loss: 0.19322 acc: 0.98667 val_loss: 0.19499, val_acc: 0.96000\n",
            "Epoch [4210/10000], loss: 0.19299 acc: 0.98667 val_loss: 0.19478, val_acc: 0.96000\n",
            "Epoch [4220/10000], loss: 0.19276 acc: 0.98667 val_loss: 0.19457, val_acc: 0.96000\n",
            "Epoch [4230/10000], loss: 0.19253 acc: 0.98667 val_loss: 0.19437, val_acc: 0.96000\n",
            "Epoch [4240/10000], loss: 0.19230 acc: 0.98667 val_loss: 0.19416, val_acc: 0.96000\n",
            "Epoch [4250/10000], loss: 0.19207 acc: 0.98667 val_loss: 0.19396, val_acc: 0.96000\n",
            "Epoch [4260/10000], loss: 0.19184 acc: 0.98667 val_loss: 0.19376, val_acc: 0.96000\n",
            "Epoch [4270/10000], loss: 0.19162 acc: 0.98667 val_loss: 0.19355, val_acc: 0.96000\n",
            "Epoch [4280/10000], loss: 0.19139 acc: 0.98667 val_loss: 0.19335, val_acc: 0.96000\n",
            "Epoch [4290/10000], loss: 0.19117 acc: 0.98667 val_loss: 0.19315, val_acc: 0.96000\n",
            "Epoch [4300/10000], loss: 0.19094 acc: 0.98667 val_loss: 0.19295, val_acc: 0.96000\n",
            "Epoch [4310/10000], loss: 0.19072 acc: 0.98667 val_loss: 0.19275, val_acc: 0.96000\n",
            "Epoch [4320/10000], loss: 0.19050 acc: 0.98667 val_loss: 0.19255, val_acc: 0.96000\n",
            "Epoch [4330/10000], loss: 0.19028 acc: 0.98667 val_loss: 0.19235, val_acc: 0.96000\n",
            "Epoch [4340/10000], loss: 0.19006 acc: 0.98667 val_loss: 0.19215, val_acc: 0.96000\n",
            "Epoch [4350/10000], loss: 0.18984 acc: 0.98667 val_loss: 0.19196, val_acc: 0.96000\n",
            "Epoch [4360/10000], loss: 0.18962 acc: 0.98667 val_loss: 0.19176, val_acc: 0.96000\n",
            "Epoch [4370/10000], loss: 0.18940 acc: 0.98667 val_loss: 0.19156, val_acc: 0.96000\n",
            "Epoch [4380/10000], loss: 0.18918 acc: 0.98667 val_loss: 0.19137, val_acc: 0.96000\n",
            "Epoch [4390/10000], loss: 0.18897 acc: 0.98667 val_loss: 0.19118, val_acc: 0.96000\n",
            "Epoch [4400/10000], loss: 0.18875 acc: 0.98667 val_loss: 0.19098, val_acc: 0.96000\n",
            "Epoch [4410/10000], loss: 0.18853 acc: 0.98667 val_loss: 0.19079, val_acc: 0.96000\n",
            "Epoch [4420/10000], loss: 0.18832 acc: 0.98667 val_loss: 0.19060, val_acc: 0.96000\n",
            "Epoch [4430/10000], loss: 0.18811 acc: 0.98667 val_loss: 0.19041, val_acc: 0.96000\n",
            "Epoch [4440/10000], loss: 0.18789 acc: 0.98667 val_loss: 0.19021, val_acc: 0.96000\n",
            "Epoch [4450/10000], loss: 0.18768 acc: 0.98667 val_loss: 0.19002, val_acc: 0.96000\n",
            "Epoch [4460/10000], loss: 0.18747 acc: 0.98667 val_loss: 0.18984, val_acc: 0.96000\n",
            "Epoch [4470/10000], loss: 0.18726 acc: 0.98667 val_loss: 0.18965, val_acc: 0.96000\n",
            "Epoch [4480/10000], loss: 0.18705 acc: 0.98667 val_loss: 0.18946, val_acc: 0.96000\n",
            "Epoch [4490/10000], loss: 0.18684 acc: 0.98667 val_loss: 0.18927, val_acc: 0.96000\n",
            "Epoch [4500/10000], loss: 0.18663 acc: 0.98667 val_loss: 0.18908, val_acc: 0.96000\n",
            "Epoch [4510/10000], loss: 0.18642 acc: 0.98667 val_loss: 0.18890, val_acc: 0.96000\n",
            "Epoch [4520/10000], loss: 0.18622 acc: 0.98667 val_loss: 0.18871, val_acc: 0.96000\n",
            "Epoch [4530/10000], loss: 0.18601 acc: 0.98667 val_loss: 0.18853, val_acc: 0.96000\n",
            "Epoch [4540/10000], loss: 0.18580 acc: 0.98667 val_loss: 0.18834, val_acc: 0.96000\n",
            "Epoch [4550/10000], loss: 0.18560 acc: 0.98667 val_loss: 0.18816, val_acc: 0.96000\n",
            "Epoch [4560/10000], loss: 0.18539 acc: 0.98667 val_loss: 0.18798, val_acc: 0.96000\n",
            "Epoch [4570/10000], loss: 0.18519 acc: 0.98667 val_loss: 0.18780, val_acc: 0.96000\n",
            "Epoch [4580/10000], loss: 0.18499 acc: 0.98667 val_loss: 0.18762, val_acc: 0.96000\n",
            "Epoch [4590/10000], loss: 0.18478 acc: 0.98667 val_loss: 0.18743, val_acc: 0.96000\n",
            "Epoch [4600/10000], loss: 0.18458 acc: 0.98667 val_loss: 0.18725, val_acc: 0.96000\n",
            "Epoch [4610/10000], loss: 0.18438 acc: 0.98667 val_loss: 0.18707, val_acc: 0.96000\n",
            "Epoch [4620/10000], loss: 0.18418 acc: 0.98667 val_loss: 0.18690, val_acc: 0.96000\n",
            "Epoch [4630/10000], loss: 0.18398 acc: 0.98667 val_loss: 0.18672, val_acc: 0.96000\n",
            "Epoch [4640/10000], loss: 0.18378 acc: 0.98667 val_loss: 0.18654, val_acc: 0.96000\n",
            "Epoch [4650/10000], loss: 0.18358 acc: 0.98667 val_loss: 0.18636, val_acc: 0.96000\n",
            "Epoch [4660/10000], loss: 0.18339 acc: 0.98667 val_loss: 0.18619, val_acc: 0.96000\n",
            "Epoch [4670/10000], loss: 0.18319 acc: 0.98667 val_loss: 0.18601, val_acc: 0.96000\n",
            "Epoch [4680/10000], loss: 0.18299 acc: 0.98667 val_loss: 0.18583, val_acc: 0.96000\n",
            "Epoch [4690/10000], loss: 0.18280 acc: 0.98667 val_loss: 0.18566, val_acc: 0.96000\n",
            "Epoch [4700/10000], loss: 0.18260 acc: 0.98667 val_loss: 0.18549, val_acc: 0.96000\n",
            "Epoch [4710/10000], loss: 0.18241 acc: 0.98667 val_loss: 0.18531, val_acc: 0.96000\n",
            "Epoch [4720/10000], loss: 0.18221 acc: 0.98667 val_loss: 0.18514, val_acc: 0.96000\n",
            "Epoch [4730/10000], loss: 0.18202 acc: 0.98667 val_loss: 0.18497, val_acc: 0.96000\n",
            "Epoch [4740/10000], loss: 0.18183 acc: 0.98667 val_loss: 0.18479, val_acc: 0.96000\n",
            "Epoch [4750/10000], loss: 0.18164 acc: 0.98667 val_loss: 0.18462, val_acc: 0.96000\n",
            "Epoch [4760/10000], loss: 0.18144 acc: 0.98667 val_loss: 0.18445, val_acc: 0.96000\n",
            "Epoch [4770/10000], loss: 0.18125 acc: 0.98667 val_loss: 0.18428, val_acc: 0.96000\n",
            "Epoch [4780/10000], loss: 0.18106 acc: 0.98667 val_loss: 0.18411, val_acc: 0.96000\n",
            "Epoch [4790/10000], loss: 0.18087 acc: 0.98667 val_loss: 0.18395, val_acc: 0.96000\n",
            "Epoch [4800/10000], loss: 0.18068 acc: 0.98667 val_loss: 0.18378, val_acc: 0.96000\n",
            "Epoch [4810/10000], loss: 0.18050 acc: 0.98667 val_loss: 0.18361, val_acc: 0.96000\n",
            "Epoch [4820/10000], loss: 0.18031 acc: 0.98667 val_loss: 0.18344, val_acc: 0.96000\n",
            "Epoch [4830/10000], loss: 0.18012 acc: 0.98667 val_loss: 0.18328, val_acc: 0.96000\n",
            "Epoch [4840/10000], loss: 0.17994 acc: 0.98667 val_loss: 0.18311, val_acc: 0.96000\n",
            "Epoch [4850/10000], loss: 0.17975 acc: 0.98667 val_loss: 0.18294, val_acc: 0.96000\n",
            "Epoch [4860/10000], loss: 0.17956 acc: 0.98667 val_loss: 0.18278, val_acc: 0.96000\n",
            "Epoch [4870/10000], loss: 0.17938 acc: 0.98667 val_loss: 0.18261, val_acc: 0.96000\n",
            "Epoch [4880/10000], loss: 0.17920 acc: 0.98667 val_loss: 0.18245, val_acc: 0.96000\n",
            "Epoch [4890/10000], loss: 0.17901 acc: 0.98667 val_loss: 0.18229, val_acc: 0.96000\n",
            "Epoch [4900/10000], loss: 0.17883 acc: 0.98667 val_loss: 0.18212, val_acc: 0.96000\n",
            "Epoch [4910/10000], loss: 0.17865 acc: 0.98667 val_loss: 0.18196, val_acc: 0.96000\n",
            "Epoch [4920/10000], loss: 0.17846 acc: 0.98667 val_loss: 0.18180, val_acc: 0.96000\n",
            "Epoch [4930/10000], loss: 0.17828 acc: 0.98667 val_loss: 0.18164, val_acc: 0.96000\n",
            "Epoch [4940/10000], loss: 0.17810 acc: 0.98667 val_loss: 0.18148, val_acc: 0.96000\n",
            "Epoch [4950/10000], loss: 0.17792 acc: 0.98667 val_loss: 0.18132, val_acc: 0.96000\n",
            "Epoch [4960/10000], loss: 0.17774 acc: 0.98667 val_loss: 0.18116, val_acc: 0.96000\n",
            "Epoch [4970/10000], loss: 0.17756 acc: 0.98667 val_loss: 0.18100, val_acc: 0.96000\n",
            "Epoch [4980/10000], loss: 0.17739 acc: 0.98667 val_loss: 0.18084, val_acc: 0.96000\n",
            "Epoch [4990/10000], loss: 0.17721 acc: 0.98667 val_loss: 0.18068, val_acc: 0.96000\n",
            "Epoch [5000/10000], loss: 0.17703 acc: 0.98667 val_loss: 0.18053, val_acc: 0.96000\n",
            "Epoch [5010/10000], loss: 0.17685 acc: 0.98667 val_loss: 0.18037, val_acc: 0.96000\n",
            "Epoch [5020/10000], loss: 0.17668 acc: 0.98667 val_loss: 0.18021, val_acc: 0.96000\n",
            "Epoch [5030/10000], loss: 0.17650 acc: 0.98667 val_loss: 0.18006, val_acc: 0.96000\n",
            "Epoch [5040/10000], loss: 0.17633 acc: 0.98667 val_loss: 0.17990, val_acc: 0.96000\n",
            "Epoch [5050/10000], loss: 0.17615 acc: 0.98667 val_loss: 0.17975, val_acc: 0.96000\n",
            "Epoch [5060/10000], loss: 0.17598 acc: 0.98667 val_loss: 0.17959, val_acc: 0.96000\n",
            "Epoch [5070/10000], loss: 0.17581 acc: 0.98667 val_loss: 0.17944, val_acc: 0.96000\n",
            "Epoch [5080/10000], loss: 0.17563 acc: 0.98667 val_loss: 0.17928, val_acc: 0.96000\n",
            "Epoch [5090/10000], loss: 0.17546 acc: 0.98667 val_loss: 0.17913, val_acc: 0.96000\n",
            "Epoch [5100/10000], loss: 0.17529 acc: 0.98667 val_loss: 0.17898, val_acc: 0.96000\n",
            "Epoch [5110/10000], loss: 0.17512 acc: 0.98667 val_loss: 0.17883, val_acc: 0.96000\n",
            "Epoch [5120/10000], loss: 0.17495 acc: 0.98667 val_loss: 0.17867, val_acc: 0.96000\n",
            "Epoch [5130/10000], loss: 0.17478 acc: 0.98667 val_loss: 0.17852, val_acc: 0.96000\n",
            "Epoch [5140/10000], loss: 0.17461 acc: 0.98667 val_loss: 0.17837, val_acc: 0.96000\n",
            "Epoch [5150/10000], loss: 0.17444 acc: 0.98667 val_loss: 0.17822, val_acc: 0.96000\n",
            "Epoch [5160/10000], loss: 0.17427 acc: 0.98667 val_loss: 0.17807, val_acc: 0.96000\n",
            "Epoch [5170/10000], loss: 0.17410 acc: 0.98667 val_loss: 0.17792, val_acc: 0.96000\n",
            "Epoch [5180/10000], loss: 0.17393 acc: 0.98667 val_loss: 0.17778, val_acc: 0.96000\n",
            "Epoch [5190/10000], loss: 0.17377 acc: 0.98667 val_loss: 0.17763, val_acc: 0.96000\n",
            "Epoch [5200/10000], loss: 0.17360 acc: 0.98667 val_loss: 0.17748, val_acc: 0.96000\n",
            "Epoch [5210/10000], loss: 0.17343 acc: 0.98667 val_loss: 0.17733, val_acc: 0.96000\n",
            "Epoch [5220/10000], loss: 0.17327 acc: 0.98667 val_loss: 0.17719, val_acc: 0.96000\n",
            "Epoch [5230/10000], loss: 0.17310 acc: 0.98667 val_loss: 0.17704, val_acc: 0.96000\n",
            "Epoch [5240/10000], loss: 0.17294 acc: 0.98667 val_loss: 0.17689, val_acc: 0.96000\n",
            "Epoch [5250/10000], loss: 0.17277 acc: 0.98667 val_loss: 0.17675, val_acc: 0.96000\n",
            "Epoch [5260/10000], loss: 0.17261 acc: 0.98667 val_loss: 0.17660, val_acc: 0.96000\n",
            "Epoch [5270/10000], loss: 0.17245 acc: 0.98667 val_loss: 0.17646, val_acc: 0.96000\n",
            "Epoch [5280/10000], loss: 0.17229 acc: 0.98667 val_loss: 0.17631, val_acc: 0.96000\n",
            "Epoch [5290/10000], loss: 0.17212 acc: 0.98667 val_loss: 0.17617, val_acc: 0.96000\n",
            "Epoch [5300/10000], loss: 0.17196 acc: 0.98667 val_loss: 0.17603, val_acc: 0.96000\n",
            "Epoch [5310/10000], loss: 0.17180 acc: 0.98667 val_loss: 0.17589, val_acc: 0.96000\n",
            "Epoch [5320/10000], loss: 0.17164 acc: 0.98667 val_loss: 0.17574, val_acc: 0.96000\n",
            "Epoch [5330/10000], loss: 0.17148 acc: 0.98667 val_loss: 0.17560, val_acc: 0.96000\n",
            "Epoch [5340/10000], loss: 0.17132 acc: 0.98667 val_loss: 0.17546, val_acc: 0.96000\n",
            "Epoch [5350/10000], loss: 0.17116 acc: 0.98667 val_loss: 0.17532, val_acc: 0.96000\n",
            "Epoch [5360/10000], loss: 0.17100 acc: 0.98667 val_loss: 0.17518, val_acc: 0.96000\n",
            "Epoch [5370/10000], loss: 0.17084 acc: 0.98667 val_loss: 0.17504, val_acc: 0.96000\n",
            "Epoch [5380/10000], loss: 0.17068 acc: 0.98667 val_loss: 0.17490, val_acc: 0.96000\n",
            "Epoch [5390/10000], loss: 0.17053 acc: 0.98667 val_loss: 0.17476, val_acc: 0.96000\n",
            "Epoch [5400/10000], loss: 0.17037 acc: 0.98667 val_loss: 0.17462, val_acc: 0.96000\n",
            "Epoch [5410/10000], loss: 0.17021 acc: 0.98667 val_loss: 0.17448, val_acc: 0.96000\n",
            "Epoch [5420/10000], loss: 0.17006 acc: 0.98667 val_loss: 0.17434, val_acc: 0.96000\n",
            "Epoch [5430/10000], loss: 0.16990 acc: 0.98667 val_loss: 0.17421, val_acc: 0.96000\n",
            "Epoch [5440/10000], loss: 0.16975 acc: 0.98667 val_loss: 0.17407, val_acc: 0.96000\n",
            "Epoch [5450/10000], loss: 0.16959 acc: 0.98667 val_loss: 0.17393, val_acc: 0.96000\n",
            "Epoch [5460/10000], loss: 0.16944 acc: 0.98667 val_loss: 0.17380, val_acc: 0.96000\n",
            "Epoch [5470/10000], loss: 0.16928 acc: 0.98667 val_loss: 0.17366, val_acc: 0.96000\n",
            "Epoch [5480/10000], loss: 0.16913 acc: 0.98667 val_loss: 0.17352, val_acc: 0.96000\n",
            "Epoch [5490/10000], loss: 0.16898 acc: 0.98667 val_loss: 0.17339, val_acc: 0.96000\n",
            "Epoch [5500/10000], loss: 0.16883 acc: 0.98667 val_loss: 0.17325, val_acc: 0.96000\n",
            "Epoch [5510/10000], loss: 0.16867 acc: 0.98667 val_loss: 0.17312, val_acc: 0.96000\n",
            "Epoch [5520/10000], loss: 0.16852 acc: 0.98667 val_loss: 0.17299, val_acc: 0.96000\n",
            "Epoch [5530/10000], loss: 0.16837 acc: 0.98667 val_loss: 0.17285, val_acc: 0.96000\n",
            "Epoch [5540/10000], loss: 0.16822 acc: 0.98667 val_loss: 0.17272, val_acc: 0.96000\n",
            "Epoch [5550/10000], loss: 0.16807 acc: 0.98667 val_loss: 0.17259, val_acc: 0.96000\n",
            "Epoch [5560/10000], loss: 0.16792 acc: 0.98667 val_loss: 0.17246, val_acc: 0.96000\n",
            "Epoch [5570/10000], loss: 0.16777 acc: 0.98667 val_loss: 0.17232, val_acc: 0.96000\n",
            "Epoch [5580/10000], loss: 0.16762 acc: 0.98667 val_loss: 0.17219, val_acc: 0.96000\n",
            "Epoch [5590/10000], loss: 0.16747 acc: 0.98667 val_loss: 0.17206, val_acc: 0.96000\n",
            "Epoch [5600/10000], loss: 0.16732 acc: 0.98667 val_loss: 0.17193, val_acc: 0.96000\n",
            "Epoch [5610/10000], loss: 0.16718 acc: 0.98667 val_loss: 0.17180, val_acc: 0.96000\n",
            "Epoch [5620/10000], loss: 0.16703 acc: 0.98667 val_loss: 0.17167, val_acc: 0.96000\n",
            "Epoch [5630/10000], loss: 0.16688 acc: 0.98667 val_loss: 0.17154, val_acc: 0.96000\n",
            "Epoch [5640/10000], loss: 0.16674 acc: 0.98667 val_loss: 0.17141, val_acc: 0.96000\n",
            "Epoch [5650/10000], loss: 0.16659 acc: 0.98667 val_loss: 0.17128, val_acc: 0.96000\n",
            "Epoch [5660/10000], loss: 0.16644 acc: 0.98667 val_loss: 0.17115, val_acc: 0.96000\n",
            "Epoch [5670/10000], loss: 0.16630 acc: 0.98667 val_loss: 0.17103, val_acc: 0.96000\n",
            "Epoch [5680/10000], loss: 0.16615 acc: 0.98667 val_loss: 0.17090, val_acc: 0.96000\n",
            "Epoch [5690/10000], loss: 0.16601 acc: 0.98667 val_loss: 0.17077, val_acc: 0.96000\n",
            "Epoch [5700/10000], loss: 0.16587 acc: 0.98667 val_loss: 0.17064, val_acc: 0.96000\n",
            "Epoch [5710/10000], loss: 0.16572 acc: 0.98667 val_loss: 0.17052, val_acc: 0.96000\n",
            "Epoch [5720/10000], loss: 0.16558 acc: 0.98667 val_loss: 0.17039, val_acc: 0.96000\n",
            "Epoch [5730/10000], loss: 0.16544 acc: 0.98667 val_loss: 0.17027, val_acc: 0.96000\n",
            "Epoch [5740/10000], loss: 0.16529 acc: 0.98667 val_loss: 0.17014, val_acc: 0.96000\n",
            "Epoch [5750/10000], loss: 0.16515 acc: 0.98667 val_loss: 0.17001, val_acc: 0.96000\n",
            "Epoch [5760/10000], loss: 0.16501 acc: 0.98667 val_loss: 0.16989, val_acc: 0.96000\n",
            "Epoch [5770/10000], loss: 0.16487 acc: 0.98667 val_loss: 0.16977, val_acc: 0.96000\n",
            "Epoch [5780/10000], loss: 0.16473 acc: 0.98667 val_loss: 0.16964, val_acc: 0.96000\n",
            "Epoch [5790/10000], loss: 0.16459 acc: 0.98667 val_loss: 0.16952, val_acc: 0.96000\n",
            "Epoch [5800/10000], loss: 0.16445 acc: 0.98667 val_loss: 0.16939, val_acc: 0.96000\n",
            "Epoch [5810/10000], loss: 0.16431 acc: 0.98667 val_loss: 0.16927, val_acc: 0.96000\n",
            "Epoch [5820/10000], loss: 0.16417 acc: 0.98667 val_loss: 0.16915, val_acc: 0.96000\n",
            "Epoch [5830/10000], loss: 0.16403 acc: 0.98667 val_loss: 0.16903, val_acc: 0.96000\n",
            "Epoch [5840/10000], loss: 0.16389 acc: 0.98667 val_loss: 0.16891, val_acc: 0.96000\n",
            "Epoch [5850/10000], loss: 0.16375 acc: 0.98667 val_loss: 0.16878, val_acc: 0.96000\n",
            "Epoch [5860/10000], loss: 0.16361 acc: 0.98667 val_loss: 0.16866, val_acc: 0.96000\n",
            "Epoch [5870/10000], loss: 0.16348 acc: 0.98667 val_loss: 0.16854, val_acc: 0.96000\n",
            "Epoch [5880/10000], loss: 0.16334 acc: 0.98667 val_loss: 0.16842, val_acc: 0.96000\n",
            "Epoch [5890/10000], loss: 0.16320 acc: 0.98667 val_loss: 0.16830, val_acc: 0.96000\n",
            "Epoch [5900/10000], loss: 0.16307 acc: 0.98667 val_loss: 0.16818, val_acc: 0.96000\n",
            "Epoch [5910/10000], loss: 0.16293 acc: 0.98667 val_loss: 0.16806, val_acc: 0.96000\n",
            "Epoch [5920/10000], loss: 0.16280 acc: 0.98667 val_loss: 0.16794, val_acc: 0.96000\n",
            "Epoch [5930/10000], loss: 0.16266 acc: 0.98667 val_loss: 0.16782, val_acc: 0.96000\n",
            "Epoch [5940/10000], loss: 0.16253 acc: 0.98667 val_loss: 0.16771, val_acc: 0.96000\n",
            "Epoch [5950/10000], loss: 0.16239 acc: 0.98667 val_loss: 0.16759, val_acc: 0.96000\n",
            "Epoch [5960/10000], loss: 0.16226 acc: 0.98667 val_loss: 0.16747, val_acc: 0.96000\n",
            "Epoch [5970/10000], loss: 0.16212 acc: 0.98667 val_loss: 0.16735, val_acc: 0.96000\n",
            "Epoch [5980/10000], loss: 0.16199 acc: 0.98667 val_loss: 0.16724, val_acc: 0.96000\n",
            "Epoch [5990/10000], loss: 0.16186 acc: 0.98667 val_loss: 0.16712, val_acc: 0.96000\n",
            "Epoch [6000/10000], loss: 0.16172 acc: 0.98667 val_loss: 0.16700, val_acc: 0.96000\n",
            "Epoch [6010/10000], loss: 0.16159 acc: 0.98667 val_loss: 0.16689, val_acc: 0.96000\n",
            "Epoch [6020/10000], loss: 0.16146 acc: 0.98667 val_loss: 0.16677, val_acc: 0.96000\n",
            "Epoch [6030/10000], loss: 0.16133 acc: 0.98667 val_loss: 0.16665, val_acc: 0.96000\n",
            "Epoch [6040/10000], loss: 0.16120 acc: 0.98667 val_loss: 0.16654, val_acc: 0.96000\n",
            "Epoch [6050/10000], loss: 0.16107 acc: 0.98667 val_loss: 0.16642, val_acc: 0.96000\n",
            "Epoch [6060/10000], loss: 0.16094 acc: 0.98667 val_loss: 0.16631, val_acc: 0.96000\n",
            "Epoch [6070/10000], loss: 0.16080 acc: 0.98667 val_loss: 0.16620, val_acc: 0.96000\n",
            "Epoch [6080/10000], loss: 0.16067 acc: 0.98667 val_loss: 0.16608, val_acc: 0.96000\n",
            "Epoch [6090/10000], loss: 0.16055 acc: 0.98667 val_loss: 0.16597, val_acc: 0.96000\n",
            "Epoch [6100/10000], loss: 0.16042 acc: 0.98667 val_loss: 0.16585, val_acc: 0.96000\n",
            "Epoch [6110/10000], loss: 0.16029 acc: 0.98667 val_loss: 0.16574, val_acc: 0.96000\n",
            "Epoch [6120/10000], loss: 0.16016 acc: 0.98667 val_loss: 0.16563, val_acc: 0.96000\n",
            "Epoch [6130/10000], loss: 0.16003 acc: 0.98667 val_loss: 0.16552, val_acc: 0.96000\n",
            "Epoch [6140/10000], loss: 0.15990 acc: 0.98667 val_loss: 0.16540, val_acc: 0.96000\n",
            "Epoch [6150/10000], loss: 0.15978 acc: 0.98667 val_loss: 0.16529, val_acc: 0.96000\n",
            "Epoch [6160/10000], loss: 0.15965 acc: 0.98667 val_loss: 0.16518, val_acc: 0.96000\n",
            "Epoch [6170/10000], loss: 0.15952 acc: 0.98667 val_loss: 0.16507, val_acc: 0.96000\n",
            "Epoch [6180/10000], loss: 0.15939 acc: 0.98667 val_loss: 0.16496, val_acc: 0.96000\n",
            "Epoch [6190/10000], loss: 0.15927 acc: 0.98667 val_loss: 0.16485, val_acc: 0.96000\n",
            "Epoch [6200/10000], loss: 0.15914 acc: 0.98667 val_loss: 0.16474, val_acc: 0.96000\n",
            "Epoch [6210/10000], loss: 0.15902 acc: 0.98667 val_loss: 0.16463, val_acc: 0.96000\n",
            "Epoch [6220/10000], loss: 0.15889 acc: 0.98667 val_loss: 0.16452, val_acc: 0.96000\n",
            "Epoch [6230/10000], loss: 0.15877 acc: 0.98667 val_loss: 0.16441, val_acc: 0.96000\n",
            "Epoch [6240/10000], loss: 0.15864 acc: 0.98667 val_loss: 0.16430, val_acc: 0.96000\n",
            "Epoch [6250/10000], loss: 0.15852 acc: 0.98667 val_loss: 0.16419, val_acc: 0.96000\n",
            "Epoch [6260/10000], loss: 0.15839 acc: 0.98667 val_loss: 0.16408, val_acc: 0.96000\n",
            "Epoch [6270/10000], loss: 0.15827 acc: 0.98667 val_loss: 0.16398, val_acc: 0.96000\n",
            "Epoch [6280/10000], loss: 0.15815 acc: 0.98667 val_loss: 0.16387, val_acc: 0.96000\n",
            "Epoch [6290/10000], loss: 0.15802 acc: 0.98667 val_loss: 0.16376, val_acc: 0.96000\n",
            "Epoch [6300/10000], loss: 0.15790 acc: 0.98667 val_loss: 0.16365, val_acc: 0.96000\n",
            "Epoch [6310/10000], loss: 0.15778 acc: 0.98667 val_loss: 0.16355, val_acc: 0.96000\n",
            "Epoch [6320/10000], loss: 0.15766 acc: 0.98667 val_loss: 0.16344, val_acc: 0.96000\n",
            "Epoch [6330/10000], loss: 0.15754 acc: 0.98667 val_loss: 0.16333, val_acc: 0.96000\n",
            "Epoch [6340/10000], loss: 0.15741 acc: 0.98667 val_loss: 0.16323, val_acc: 0.96000\n",
            "Epoch [6350/10000], loss: 0.15729 acc: 0.98667 val_loss: 0.16312, val_acc: 0.96000\n",
            "Epoch [6360/10000], loss: 0.15717 acc: 0.98667 val_loss: 0.16302, val_acc: 0.96000\n",
            "Epoch [6370/10000], loss: 0.15705 acc: 0.98667 val_loss: 0.16291, val_acc: 0.96000\n",
            "Epoch [6380/10000], loss: 0.15693 acc: 0.98667 val_loss: 0.16281, val_acc: 0.96000\n",
            "Epoch [6390/10000], loss: 0.15681 acc: 0.98667 val_loss: 0.16270, val_acc: 0.96000\n",
            "Epoch [6400/10000], loss: 0.15669 acc: 0.98667 val_loss: 0.16260, val_acc: 0.96000\n",
            "Epoch [6410/10000], loss: 0.15657 acc: 0.98667 val_loss: 0.16249, val_acc: 0.96000\n",
            "Epoch [6420/10000], loss: 0.15645 acc: 0.98667 val_loss: 0.16239, val_acc: 0.96000\n",
            "Epoch [6430/10000], loss: 0.15634 acc: 0.98667 val_loss: 0.16228, val_acc: 0.96000\n",
            "Epoch [6440/10000], loss: 0.15622 acc: 0.98667 val_loss: 0.16218, val_acc: 0.96000\n",
            "Epoch [6450/10000], loss: 0.15610 acc: 0.98667 val_loss: 0.16208, val_acc: 0.96000\n",
            "Epoch [6460/10000], loss: 0.15598 acc: 0.98667 val_loss: 0.16198, val_acc: 0.96000\n",
            "Epoch [6470/10000], loss: 0.15586 acc: 0.98667 val_loss: 0.16187, val_acc: 0.96000\n",
            "Epoch [6480/10000], loss: 0.15575 acc: 0.98667 val_loss: 0.16177, val_acc: 0.96000\n",
            "Epoch [6490/10000], loss: 0.15563 acc: 0.98667 val_loss: 0.16167, val_acc: 0.96000\n",
            "Epoch [6500/10000], loss: 0.15551 acc: 0.98667 val_loss: 0.16157, val_acc: 0.96000\n",
            "Epoch [6510/10000], loss: 0.15540 acc: 0.98667 val_loss: 0.16147, val_acc: 0.96000\n",
            "Epoch [6520/10000], loss: 0.15528 acc: 0.98667 val_loss: 0.16136, val_acc: 0.96000\n",
            "Epoch [6530/10000], loss: 0.15516 acc: 0.98667 val_loss: 0.16126, val_acc: 0.96000\n",
            "Epoch [6540/10000], loss: 0.15505 acc: 0.98667 val_loss: 0.16116, val_acc: 0.96000\n",
            "Epoch [6550/10000], loss: 0.15493 acc: 0.98667 val_loss: 0.16106, val_acc: 0.96000\n",
            "Epoch [6560/10000], loss: 0.15482 acc: 0.98667 val_loss: 0.16096, val_acc: 0.96000\n",
            "Epoch [6570/10000], loss: 0.15470 acc: 0.98667 val_loss: 0.16086, val_acc: 0.96000\n",
            "Epoch [6580/10000], loss: 0.15459 acc: 0.98667 val_loss: 0.16076, val_acc: 0.96000\n",
            "Epoch [6590/10000], loss: 0.15448 acc: 0.98667 val_loss: 0.16066, val_acc: 0.96000\n",
            "Epoch [6600/10000], loss: 0.15436 acc: 0.98667 val_loss: 0.16056, val_acc: 0.96000\n",
            "Epoch [6610/10000], loss: 0.15425 acc: 0.98667 val_loss: 0.16047, val_acc: 0.96000\n",
            "Epoch [6620/10000], loss: 0.15414 acc: 0.98667 val_loss: 0.16037, val_acc: 0.96000\n",
            "Epoch [6630/10000], loss: 0.15402 acc: 0.98667 val_loss: 0.16027, val_acc: 0.96000\n",
            "Epoch [6640/10000], loss: 0.15391 acc: 0.98667 val_loss: 0.16017, val_acc: 0.96000\n",
            "Epoch [6650/10000], loss: 0.15380 acc: 0.98667 val_loss: 0.16007, val_acc: 0.96000\n",
            "Epoch [6660/10000], loss: 0.15369 acc: 0.98667 val_loss: 0.15998, val_acc: 0.96000\n",
            "Epoch [6670/10000], loss: 0.15357 acc: 0.98667 val_loss: 0.15988, val_acc: 0.96000\n",
            "Epoch [6680/10000], loss: 0.15346 acc: 0.98667 val_loss: 0.15978, val_acc: 0.96000\n",
            "Epoch [6690/10000], loss: 0.15335 acc: 0.98667 val_loss: 0.15968, val_acc: 0.96000\n",
            "Epoch [6700/10000], loss: 0.15324 acc: 0.98667 val_loss: 0.15959, val_acc: 0.96000\n",
            "Epoch [6710/10000], loss: 0.15313 acc: 0.98667 val_loss: 0.15949, val_acc: 0.96000\n",
            "Epoch [6720/10000], loss: 0.15302 acc: 0.98667 val_loss: 0.15939, val_acc: 0.96000\n",
            "Epoch [6730/10000], loss: 0.15291 acc: 0.98667 val_loss: 0.15930, val_acc: 0.96000\n",
            "Epoch [6740/10000], loss: 0.15280 acc: 0.98667 val_loss: 0.15920, val_acc: 0.96000\n",
            "Epoch [6750/10000], loss: 0.15269 acc: 0.98667 val_loss: 0.15911, val_acc: 0.96000\n",
            "Epoch [6760/10000], loss: 0.15258 acc: 0.98667 val_loss: 0.15901, val_acc: 0.96000\n",
            "Epoch [6770/10000], loss: 0.15247 acc: 0.98667 val_loss: 0.15892, val_acc: 0.96000\n",
            "Epoch [6780/10000], loss: 0.15236 acc: 0.98667 val_loss: 0.15882, val_acc: 0.96000\n",
            "Epoch [6790/10000], loss: 0.15225 acc: 0.98667 val_loss: 0.15873, val_acc: 0.96000\n",
            "Epoch [6800/10000], loss: 0.15215 acc: 0.98667 val_loss: 0.15863, val_acc: 0.96000\n",
            "Epoch [6810/10000], loss: 0.15204 acc: 0.98667 val_loss: 0.15854, val_acc: 0.96000\n",
            "Epoch [6820/10000], loss: 0.15193 acc: 0.98667 val_loss: 0.15845, val_acc: 0.96000\n",
            "Epoch [6830/10000], loss: 0.15182 acc: 0.98667 val_loss: 0.15835, val_acc: 0.96000\n",
            "Epoch [6840/10000], loss: 0.15171 acc: 0.98667 val_loss: 0.15826, val_acc: 0.96000\n",
            "Epoch [6850/10000], loss: 0.15161 acc: 0.98667 val_loss: 0.15817, val_acc: 0.96000\n",
            "Epoch [6860/10000], loss: 0.15150 acc: 0.98667 val_loss: 0.15807, val_acc: 0.96000\n",
            "Epoch [6870/10000], loss: 0.15139 acc: 0.98667 val_loss: 0.15798, val_acc: 0.96000\n",
            "Epoch [6880/10000], loss: 0.15129 acc: 0.98667 val_loss: 0.15789, val_acc: 0.96000\n",
            "Epoch [6890/10000], loss: 0.15118 acc: 0.98667 val_loss: 0.15780, val_acc: 0.96000\n",
            "Epoch [6900/10000], loss: 0.15108 acc: 0.98667 val_loss: 0.15771, val_acc: 0.96000\n",
            "Epoch [6910/10000], loss: 0.15097 acc: 0.98667 val_loss: 0.15761, val_acc: 0.96000\n",
            "Epoch [6920/10000], loss: 0.15086 acc: 0.98667 val_loss: 0.15752, val_acc: 0.96000\n",
            "Epoch [6930/10000], loss: 0.15076 acc: 0.98667 val_loss: 0.15743, val_acc: 0.96000\n",
            "Epoch [6940/10000], loss: 0.15065 acc: 0.98667 val_loss: 0.15734, val_acc: 0.96000\n",
            "Epoch [6950/10000], loss: 0.15055 acc: 0.98667 val_loss: 0.15725, val_acc: 0.96000\n",
            "Epoch [6960/10000], loss: 0.15045 acc: 0.98667 val_loss: 0.15716, val_acc: 0.96000\n",
            "Epoch [6970/10000], loss: 0.15034 acc: 0.98667 val_loss: 0.15707, val_acc: 0.96000\n",
            "Epoch [6980/10000], loss: 0.15024 acc: 0.98667 val_loss: 0.15698, val_acc: 0.96000\n",
            "Epoch [6990/10000], loss: 0.15013 acc: 0.98667 val_loss: 0.15689, val_acc: 0.96000\n",
            "Epoch [7000/10000], loss: 0.15003 acc: 0.98667 val_loss: 0.15680, val_acc: 0.96000\n",
            "Epoch [7010/10000], loss: 0.14993 acc: 0.98667 val_loss: 0.15671, val_acc: 0.96000\n",
            "Epoch [7020/10000], loss: 0.14983 acc: 0.98667 val_loss: 0.15662, val_acc: 0.96000\n",
            "Epoch [7030/10000], loss: 0.14972 acc: 0.98667 val_loss: 0.15653, val_acc: 0.96000\n",
            "Epoch [7040/10000], loss: 0.14962 acc: 0.98667 val_loss: 0.15644, val_acc: 0.96000\n",
            "Epoch [7050/10000], loss: 0.14952 acc: 0.98667 val_loss: 0.15636, val_acc: 0.96000\n",
            "Epoch [7060/10000], loss: 0.14942 acc: 0.98667 val_loss: 0.15627, val_acc: 0.96000\n",
            "Epoch [7070/10000], loss: 0.14931 acc: 0.98667 val_loss: 0.15618, val_acc: 0.96000\n",
            "Epoch [7080/10000], loss: 0.14921 acc: 0.98667 val_loss: 0.15609, val_acc: 0.96000\n",
            "Epoch [7090/10000], loss: 0.14911 acc: 0.98667 val_loss: 0.15600, val_acc: 0.96000\n",
            "Epoch [7100/10000], loss: 0.14901 acc: 0.98667 val_loss: 0.15592, val_acc: 0.96000\n",
            "Epoch [7110/10000], loss: 0.14891 acc: 0.98667 val_loss: 0.15583, val_acc: 0.96000\n",
            "Epoch [7120/10000], loss: 0.14881 acc: 0.98667 val_loss: 0.15574, val_acc: 0.96000\n",
            "Epoch [7130/10000], loss: 0.14871 acc: 0.98667 val_loss: 0.15565, val_acc: 0.96000\n",
            "Epoch [7140/10000], loss: 0.14861 acc: 0.98667 val_loss: 0.15557, val_acc: 0.96000\n",
            "Epoch [7150/10000], loss: 0.14851 acc: 0.98667 val_loss: 0.15548, val_acc: 0.96000\n",
            "Epoch [7160/10000], loss: 0.14841 acc: 0.98667 val_loss: 0.15540, val_acc: 0.96000\n",
            "Epoch [7170/10000], loss: 0.14831 acc: 0.98667 val_loss: 0.15531, val_acc: 0.96000\n",
            "Epoch [7180/10000], loss: 0.14821 acc: 0.98667 val_loss: 0.15522, val_acc: 0.96000\n",
            "Epoch [7190/10000], loss: 0.14811 acc: 0.98667 val_loss: 0.15514, val_acc: 0.96000\n",
            "Epoch [7200/10000], loss: 0.14801 acc: 0.98667 val_loss: 0.15505, val_acc: 0.96000\n",
            "Epoch [7210/10000], loss: 0.14792 acc: 0.98667 val_loss: 0.15497, val_acc: 0.96000\n",
            "Epoch [7220/10000], loss: 0.14782 acc: 0.98667 val_loss: 0.15488, val_acc: 0.96000\n",
            "Epoch [7230/10000], loss: 0.14772 acc: 0.98667 val_loss: 0.15480, val_acc: 0.96000\n",
            "Epoch [7240/10000], loss: 0.14762 acc: 0.98667 val_loss: 0.15471, val_acc: 0.96000\n",
            "Epoch [7250/10000], loss: 0.14752 acc: 0.98667 val_loss: 0.15463, val_acc: 0.96000\n",
            "Epoch [7260/10000], loss: 0.14743 acc: 0.98667 val_loss: 0.15455, val_acc: 0.96000\n",
            "Epoch [7270/10000], loss: 0.14733 acc: 0.98667 val_loss: 0.15446, val_acc: 0.96000\n",
            "Epoch [7280/10000], loss: 0.14723 acc: 0.98667 val_loss: 0.15438, val_acc: 0.96000\n",
            "Epoch [7290/10000], loss: 0.14714 acc: 0.98667 val_loss: 0.15429, val_acc: 0.96000\n",
            "Epoch [7300/10000], loss: 0.14704 acc: 0.98667 val_loss: 0.15421, val_acc: 0.96000\n",
            "Epoch [7310/10000], loss: 0.14694 acc: 0.98667 val_loss: 0.15413, val_acc: 0.96000\n",
            "Epoch [7320/10000], loss: 0.14685 acc: 0.98667 val_loss: 0.15404, val_acc: 0.96000\n",
            "Epoch [7330/10000], loss: 0.14675 acc: 0.98667 val_loss: 0.15396, val_acc: 0.96000\n",
            "Epoch [7340/10000], loss: 0.14666 acc: 0.98667 val_loss: 0.15388, val_acc: 0.96000\n",
            "Epoch [7350/10000], loss: 0.14656 acc: 0.98667 val_loss: 0.15380, val_acc: 0.96000\n",
            "Epoch [7360/10000], loss: 0.14646 acc: 0.98667 val_loss: 0.15371, val_acc: 0.96000\n",
            "Epoch [7370/10000], loss: 0.14637 acc: 0.98667 val_loss: 0.15363, val_acc: 0.96000\n",
            "Epoch [7380/10000], loss: 0.14627 acc: 0.98667 val_loss: 0.15355, val_acc: 0.96000\n",
            "Epoch [7390/10000], loss: 0.14618 acc: 0.98667 val_loss: 0.15347, val_acc: 0.96000\n",
            "Epoch [7400/10000], loss: 0.14609 acc: 0.98667 val_loss: 0.15339, val_acc: 0.96000\n",
            "Epoch [7410/10000], loss: 0.14599 acc: 0.98667 val_loss: 0.15331, val_acc: 0.96000\n",
            "Epoch [7420/10000], loss: 0.14590 acc: 0.98667 val_loss: 0.15323, val_acc: 0.96000\n",
            "Epoch [7430/10000], loss: 0.14580 acc: 0.98667 val_loss: 0.15314, val_acc: 0.96000\n",
            "Epoch [7440/10000], loss: 0.14571 acc: 0.98667 val_loss: 0.15306, val_acc: 0.96000\n",
            "Epoch [7450/10000], loss: 0.14562 acc: 0.98667 val_loss: 0.15298, val_acc: 0.96000\n",
            "Epoch [7460/10000], loss: 0.14552 acc: 0.98667 val_loss: 0.15290, val_acc: 0.96000\n",
            "Epoch [7470/10000], loss: 0.14543 acc: 0.98667 val_loss: 0.15282, val_acc: 0.96000\n",
            "Epoch [7480/10000], loss: 0.14534 acc: 0.98667 val_loss: 0.15274, val_acc: 0.96000\n",
            "Epoch [7490/10000], loss: 0.14525 acc: 0.98667 val_loss: 0.15266, val_acc: 0.96000\n",
            "Epoch [7500/10000], loss: 0.14515 acc: 0.98667 val_loss: 0.15258, val_acc: 0.96000\n",
            "Epoch [7510/10000], loss: 0.14506 acc: 0.98667 val_loss: 0.15250, val_acc: 0.96000\n",
            "Epoch [7520/10000], loss: 0.14497 acc: 0.98667 val_loss: 0.15243, val_acc: 0.96000\n",
            "Epoch [7530/10000], loss: 0.14488 acc: 0.98667 val_loss: 0.15235, val_acc: 0.96000\n",
            "Epoch [7540/10000], loss: 0.14479 acc: 0.98667 val_loss: 0.15227, val_acc: 0.96000\n",
            "Epoch [7550/10000], loss: 0.14470 acc: 0.98667 val_loss: 0.15219, val_acc: 0.96000\n",
            "Epoch [7560/10000], loss: 0.14460 acc: 0.98667 val_loss: 0.15211, val_acc: 0.96000\n",
            "Epoch [7570/10000], loss: 0.14451 acc: 0.98667 val_loss: 0.15203, val_acc: 0.96000\n",
            "Epoch [7580/10000], loss: 0.14442 acc: 0.98667 val_loss: 0.15195, val_acc: 0.96000\n",
            "Epoch [7590/10000], loss: 0.14433 acc: 0.98667 val_loss: 0.15188, val_acc: 0.96000\n",
            "Epoch [7600/10000], loss: 0.14424 acc: 0.98667 val_loss: 0.15180, val_acc: 0.96000\n",
            "Epoch [7610/10000], loss: 0.14415 acc: 0.98667 val_loss: 0.15172, val_acc: 0.96000\n",
            "Epoch [7620/10000], loss: 0.14406 acc: 0.98667 val_loss: 0.15164, val_acc: 0.96000\n",
            "Epoch [7630/10000], loss: 0.14397 acc: 0.98667 val_loss: 0.15157, val_acc: 0.96000\n",
            "Epoch [7640/10000], loss: 0.14388 acc: 0.98667 val_loss: 0.15149, val_acc: 0.96000\n",
            "Epoch [7650/10000], loss: 0.14379 acc: 0.98667 val_loss: 0.15141, val_acc: 0.96000\n",
            "Epoch [7660/10000], loss: 0.14370 acc: 0.98667 val_loss: 0.15134, val_acc: 0.96000\n",
            "Epoch [7670/10000], loss: 0.14362 acc: 0.98667 val_loss: 0.15126, val_acc: 0.96000\n",
            "Epoch [7680/10000], loss: 0.14353 acc: 0.98667 val_loss: 0.15118, val_acc: 0.96000\n",
            "Epoch [7690/10000], loss: 0.14344 acc: 0.98667 val_loss: 0.15111, val_acc: 0.96000\n",
            "Epoch [7700/10000], loss: 0.14335 acc: 0.98667 val_loss: 0.15103, val_acc: 0.96000\n",
            "Epoch [7710/10000], loss: 0.14326 acc: 0.98667 val_loss: 0.15096, val_acc: 0.96000\n",
            "Epoch [7720/10000], loss: 0.14317 acc: 0.98667 val_loss: 0.15088, val_acc: 0.96000\n",
            "Epoch [7730/10000], loss: 0.14309 acc: 0.98667 val_loss: 0.15080, val_acc: 0.96000\n",
            "Epoch [7740/10000], loss: 0.14300 acc: 0.98667 val_loss: 0.15073, val_acc: 0.96000\n",
            "Epoch [7750/10000], loss: 0.14291 acc: 0.98667 val_loss: 0.15065, val_acc: 0.96000\n",
            "Epoch [7760/10000], loss: 0.14282 acc: 0.98667 val_loss: 0.15058, val_acc: 0.96000\n",
            "Epoch [7770/10000], loss: 0.14274 acc: 0.98667 val_loss: 0.15050, val_acc: 0.96000\n",
            "Epoch [7780/10000], loss: 0.14265 acc: 0.98667 val_loss: 0.15043, val_acc: 0.96000\n",
            "Epoch [7790/10000], loss: 0.14256 acc: 0.98667 val_loss: 0.15036, val_acc: 0.96000\n",
            "Epoch [7800/10000], loss: 0.14248 acc: 0.98667 val_loss: 0.15028, val_acc: 0.96000\n",
            "Epoch [7810/10000], loss: 0.14239 acc: 0.98667 val_loss: 0.15021, val_acc: 0.96000\n",
            "Epoch [7820/10000], loss: 0.14230 acc: 0.98667 val_loss: 0.15013, val_acc: 0.96000\n",
            "Epoch [7830/10000], loss: 0.14222 acc: 0.98667 val_loss: 0.15006, val_acc: 0.96000\n",
            "Epoch [7840/10000], loss: 0.14213 acc: 0.98667 val_loss: 0.14999, val_acc: 0.96000\n",
            "Epoch [7850/10000], loss: 0.14205 acc: 0.98667 val_loss: 0.14991, val_acc: 0.96000\n",
            "Epoch [7860/10000], loss: 0.14196 acc: 0.98667 val_loss: 0.14984, val_acc: 0.96000\n",
            "Epoch [7870/10000], loss: 0.14188 acc: 0.98667 val_loss: 0.14977, val_acc: 0.96000\n",
            "Epoch [7880/10000], loss: 0.14179 acc: 0.98667 val_loss: 0.14969, val_acc: 0.96000\n",
            "Epoch [7890/10000], loss: 0.14171 acc: 0.98667 val_loss: 0.14962, val_acc: 0.96000\n",
            "Epoch [7900/10000], loss: 0.14162 acc: 0.98667 val_loss: 0.14955, val_acc: 0.96000\n",
            "Epoch [7910/10000], loss: 0.14154 acc: 0.98667 val_loss: 0.14948, val_acc: 0.96000\n",
            "Epoch [7920/10000], loss: 0.14145 acc: 0.98667 val_loss: 0.14940, val_acc: 0.96000\n",
            "Epoch [7930/10000], loss: 0.14137 acc: 0.98667 val_loss: 0.14933, val_acc: 0.96000\n",
            "Epoch [7940/10000], loss: 0.14128 acc: 0.98667 val_loss: 0.14926, val_acc: 0.96000\n",
            "Epoch [7950/10000], loss: 0.14120 acc: 0.98667 val_loss: 0.14919, val_acc: 0.96000\n",
            "Epoch [7960/10000], loss: 0.14112 acc: 0.98667 val_loss: 0.14912, val_acc: 0.96000\n",
            "Epoch [7970/10000], loss: 0.14103 acc: 0.98667 val_loss: 0.14904, val_acc: 0.96000\n",
            "Epoch [7980/10000], loss: 0.14095 acc: 0.98667 val_loss: 0.14897, val_acc: 0.96000\n",
            "Epoch [7990/10000], loss: 0.14087 acc: 0.98667 val_loss: 0.14890, val_acc: 0.96000\n",
            "Epoch [8000/10000], loss: 0.14078 acc: 0.98667 val_loss: 0.14883, val_acc: 0.96000\n",
            "Epoch [8010/10000], loss: 0.14070 acc: 0.98667 val_loss: 0.14876, val_acc: 0.96000\n",
            "Epoch [8020/10000], loss: 0.14062 acc: 0.98667 val_loss: 0.14869, val_acc: 0.96000\n",
            "Epoch [8030/10000], loss: 0.14054 acc: 0.98667 val_loss: 0.14862, val_acc: 0.96000\n",
            "Epoch [8040/10000], loss: 0.14045 acc: 0.98667 val_loss: 0.14855, val_acc: 0.96000\n",
            "Epoch [8050/10000], loss: 0.14037 acc: 0.98667 val_loss: 0.14848, val_acc: 0.96000\n",
            "Epoch [8060/10000], loss: 0.14029 acc: 0.98667 val_loss: 0.14841, val_acc: 0.96000\n",
            "Epoch [8070/10000], loss: 0.14021 acc: 0.98667 val_loss: 0.14834, val_acc: 0.96000\n",
            "Epoch [8080/10000], loss: 0.14013 acc: 0.98667 val_loss: 0.14827, val_acc: 0.96000\n",
            "Epoch [8090/10000], loss: 0.14004 acc: 0.98667 val_loss: 0.14820, val_acc: 0.96000\n",
            "Epoch [8100/10000], loss: 0.13996 acc: 0.98667 val_loss: 0.14813, val_acc: 0.96000\n",
            "Epoch [8110/10000], loss: 0.13988 acc: 0.98667 val_loss: 0.14806, val_acc: 0.96000\n",
            "Epoch [8120/10000], loss: 0.13980 acc: 0.98667 val_loss: 0.14799, val_acc: 0.96000\n",
            "Epoch [8130/10000], loss: 0.13972 acc: 0.98667 val_loss: 0.14792, val_acc: 0.96000\n",
            "Epoch [8140/10000], loss: 0.13964 acc: 0.98667 val_loss: 0.14785, val_acc: 0.96000\n",
            "Epoch [8150/10000], loss: 0.13956 acc: 0.98667 val_loss: 0.14778, val_acc: 0.96000\n",
            "Epoch [8160/10000], loss: 0.13948 acc: 0.98667 val_loss: 0.14771, val_acc: 0.96000\n",
            "Epoch [8170/10000], loss: 0.13940 acc: 0.98667 val_loss: 0.14765, val_acc: 0.96000\n",
            "Epoch [8180/10000], loss: 0.13932 acc: 0.98667 val_loss: 0.14758, val_acc: 0.96000\n",
            "Epoch [8190/10000], loss: 0.13924 acc: 0.98667 val_loss: 0.14751, val_acc: 0.96000\n",
            "Epoch [8200/10000], loss: 0.13916 acc: 0.98667 val_loss: 0.14744, val_acc: 0.96000\n",
            "Epoch [8210/10000], loss: 0.13908 acc: 0.98667 val_loss: 0.14737, val_acc: 0.96000\n",
            "Epoch [8220/10000], loss: 0.13900 acc: 0.98667 val_loss: 0.14731, val_acc: 0.96000\n",
            "Epoch [8230/10000], loss: 0.13892 acc: 0.98667 val_loss: 0.14724, val_acc: 0.96000\n",
            "Epoch [8240/10000], loss: 0.13884 acc: 0.98667 val_loss: 0.14717, val_acc: 0.96000\n",
            "Epoch [8250/10000], loss: 0.13876 acc: 0.98667 val_loss: 0.14710, val_acc: 0.96000\n",
            "Epoch [8260/10000], loss: 0.13869 acc: 0.98667 val_loss: 0.14704, val_acc: 0.96000\n",
            "Epoch [8270/10000], loss: 0.13861 acc: 0.98667 val_loss: 0.14697, val_acc: 0.96000\n",
            "Epoch [8280/10000], loss: 0.13853 acc: 0.98667 val_loss: 0.14690, val_acc: 0.96000\n",
            "Epoch [8290/10000], loss: 0.13845 acc: 0.98667 val_loss: 0.14684, val_acc: 0.96000\n",
            "Epoch [8300/10000], loss: 0.13837 acc: 0.98667 val_loss: 0.14677, val_acc: 0.96000\n",
            "Epoch [8310/10000], loss: 0.13829 acc: 0.98667 val_loss: 0.14670, val_acc: 0.96000\n",
            "Epoch [8320/10000], loss: 0.13822 acc: 0.98667 val_loss: 0.14664, val_acc: 0.96000\n",
            "Epoch [8330/10000], loss: 0.13814 acc: 0.98667 val_loss: 0.14657, val_acc: 0.96000\n",
            "Epoch [8340/10000], loss: 0.13806 acc: 0.98667 val_loss: 0.14650, val_acc: 0.96000\n",
            "Epoch [8350/10000], loss: 0.13798 acc: 0.98667 val_loss: 0.14644, val_acc: 0.96000\n",
            "Epoch [8360/10000], loss: 0.13791 acc: 0.98667 val_loss: 0.14637, val_acc: 0.96000\n",
            "Epoch [8370/10000], loss: 0.13783 acc: 0.98667 val_loss: 0.14631, val_acc: 0.96000\n",
            "Epoch [8380/10000], loss: 0.13775 acc: 0.98667 val_loss: 0.14624, val_acc: 0.96000\n",
            "Epoch [8390/10000], loss: 0.13768 acc: 0.98667 val_loss: 0.14618, val_acc: 0.96000\n",
            "Epoch [8400/10000], loss: 0.13760 acc: 0.98667 val_loss: 0.14611, val_acc: 0.96000\n",
            "Epoch [8410/10000], loss: 0.13752 acc: 0.98667 val_loss: 0.14605, val_acc: 0.96000\n",
            "Epoch [8420/10000], loss: 0.13745 acc: 0.98667 val_loss: 0.14598, val_acc: 0.96000\n",
            "Epoch [8430/10000], loss: 0.13737 acc: 0.98667 val_loss: 0.14592, val_acc: 0.96000\n",
            "Epoch [8440/10000], loss: 0.13730 acc: 0.98667 val_loss: 0.14585, val_acc: 0.96000\n",
            "Epoch [8450/10000], loss: 0.13722 acc: 0.98667 val_loss: 0.14579, val_acc: 0.96000\n",
            "Epoch [8460/10000], loss: 0.13714 acc: 0.98667 val_loss: 0.14572, val_acc: 0.96000\n",
            "Epoch [8470/10000], loss: 0.13707 acc: 0.98667 val_loss: 0.14566, val_acc: 0.96000\n",
            "Epoch [8480/10000], loss: 0.13699 acc: 0.98667 val_loss: 0.14559, val_acc: 0.96000\n",
            "Epoch [8490/10000], loss: 0.13692 acc: 0.98667 val_loss: 0.14553, val_acc: 0.96000\n",
            "Epoch [8500/10000], loss: 0.13684 acc: 0.98667 val_loss: 0.14547, val_acc: 0.96000\n",
            "Epoch [8510/10000], loss: 0.13677 acc: 0.98667 val_loss: 0.14540, val_acc: 0.96000\n",
            "Epoch [8520/10000], loss: 0.13669 acc: 0.98667 val_loss: 0.14534, val_acc: 0.96000\n",
            "Epoch [8530/10000], loss: 0.13662 acc: 0.98667 val_loss: 0.14528, val_acc: 0.96000\n",
            "Epoch [8540/10000], loss: 0.13654 acc: 0.98667 val_loss: 0.14521, val_acc: 0.96000\n",
            "Epoch [8550/10000], loss: 0.13647 acc: 0.98667 val_loss: 0.14515, val_acc: 0.96000\n",
            "Epoch [8560/10000], loss: 0.13640 acc: 0.98667 val_loss: 0.14509, val_acc: 0.96000\n",
            "Epoch [8570/10000], loss: 0.13632 acc: 0.98667 val_loss: 0.14502, val_acc: 0.96000\n",
            "Epoch [8580/10000], loss: 0.13625 acc: 0.98667 val_loss: 0.14496, val_acc: 0.96000\n",
            "Epoch [8590/10000], loss: 0.13617 acc: 0.98667 val_loss: 0.14490, val_acc: 0.96000\n",
            "Epoch [8600/10000], loss: 0.13610 acc: 0.98667 val_loss: 0.14483, val_acc: 0.96000\n",
            "Epoch [8610/10000], loss: 0.13603 acc: 0.98667 val_loss: 0.14477, val_acc: 0.96000\n",
            "Epoch [8620/10000], loss: 0.13595 acc: 0.98667 val_loss: 0.14471, val_acc: 0.96000\n",
            "Epoch [8630/10000], loss: 0.13588 acc: 0.98667 val_loss: 0.14465, val_acc: 0.96000\n",
            "Epoch [8640/10000], loss: 0.13581 acc: 0.98667 val_loss: 0.14459, val_acc: 0.96000\n",
            "Epoch [8650/10000], loss: 0.13574 acc: 0.98667 val_loss: 0.14452, val_acc: 0.96000\n",
            "Epoch [8660/10000], loss: 0.13566 acc: 0.98667 val_loss: 0.14446, val_acc: 0.96000\n",
            "Epoch [8670/10000], loss: 0.13559 acc: 0.98667 val_loss: 0.14440, val_acc: 0.96000\n",
            "Epoch [8680/10000], loss: 0.13552 acc: 0.98667 val_loss: 0.14434, val_acc: 0.96000\n",
            "Epoch [8690/10000], loss: 0.13545 acc: 0.98667 val_loss: 0.14428, val_acc: 0.96000\n",
            "Epoch [8700/10000], loss: 0.13537 acc: 0.98667 val_loss: 0.14422, val_acc: 0.96000\n",
            "Epoch [8710/10000], loss: 0.13530 acc: 0.98667 val_loss: 0.14415, val_acc: 0.96000\n",
            "Epoch [8720/10000], loss: 0.13523 acc: 0.98667 val_loss: 0.14409, val_acc: 0.96000\n",
            "Epoch [8730/10000], loss: 0.13516 acc: 0.98667 val_loss: 0.14403, val_acc: 0.96000\n",
            "Epoch [8740/10000], loss: 0.13509 acc: 0.98667 val_loss: 0.14397, val_acc: 0.96000\n",
            "Epoch [8750/10000], loss: 0.13501 acc: 0.98667 val_loss: 0.14391, val_acc: 0.96000\n",
            "Epoch [8760/10000], loss: 0.13494 acc: 0.98667 val_loss: 0.14385, val_acc: 0.96000\n",
            "Epoch [8770/10000], loss: 0.13487 acc: 0.98667 val_loss: 0.14379, val_acc: 0.96000\n",
            "Epoch [8780/10000], loss: 0.13480 acc: 0.98667 val_loss: 0.14373, val_acc: 0.96000\n",
            "Epoch [8790/10000], loss: 0.13473 acc: 0.98667 val_loss: 0.14367, val_acc: 0.96000\n",
            "Epoch [8800/10000], loss: 0.13466 acc: 0.98667 val_loss: 0.14361, val_acc: 0.96000\n",
            "Epoch [8810/10000], loss: 0.13459 acc: 0.98667 val_loss: 0.14355, val_acc: 0.96000\n",
            "Epoch [8820/10000], loss: 0.13452 acc: 0.98667 val_loss: 0.14349, val_acc: 0.96000\n",
            "Epoch [8830/10000], loss: 0.13445 acc: 0.98667 val_loss: 0.14343, val_acc: 0.96000\n",
            "Epoch [8840/10000], loss: 0.13438 acc: 0.98667 val_loss: 0.14337, val_acc: 0.96000\n",
            "Epoch [8850/10000], loss: 0.13431 acc: 0.98667 val_loss: 0.14331, val_acc: 0.96000\n",
            "Epoch [8860/10000], loss: 0.13424 acc: 0.98667 val_loss: 0.14325, val_acc: 0.96000\n",
            "Epoch [8870/10000], loss: 0.13417 acc: 0.98667 val_loss: 0.14319, val_acc: 0.96000\n",
            "Epoch [8880/10000], loss: 0.13410 acc: 0.98667 val_loss: 0.14313, val_acc: 0.96000\n",
            "Epoch [8890/10000], loss: 0.13403 acc: 0.98667 val_loss: 0.14308, val_acc: 0.96000\n",
            "Epoch [8900/10000], loss: 0.13396 acc: 0.98667 val_loss: 0.14302, val_acc: 0.96000\n",
            "Epoch [8910/10000], loss: 0.13389 acc: 0.98667 val_loss: 0.14296, val_acc: 0.96000\n",
            "Epoch [8920/10000], loss: 0.13382 acc: 0.98667 val_loss: 0.14290, val_acc: 0.96000\n",
            "Epoch [8930/10000], loss: 0.13375 acc: 0.98667 val_loss: 0.14284, val_acc: 0.96000\n",
            "Epoch [8940/10000], loss: 0.13368 acc: 0.98667 val_loss: 0.14278, val_acc: 0.96000\n",
            "Epoch [8950/10000], loss: 0.13361 acc: 0.98667 val_loss: 0.14272, val_acc: 0.96000\n",
            "Epoch [8960/10000], loss: 0.13354 acc: 0.98667 val_loss: 0.14266, val_acc: 0.96000\n",
            "Epoch [8970/10000], loss: 0.13347 acc: 0.98667 val_loss: 0.14261, val_acc: 0.96000\n",
            "Epoch [8980/10000], loss: 0.13341 acc: 0.98667 val_loss: 0.14255, val_acc: 0.96000\n",
            "Epoch [8990/10000], loss: 0.13334 acc: 0.98667 val_loss: 0.14249, val_acc: 0.96000\n",
            "Epoch [9000/10000], loss: 0.13327 acc: 0.98667 val_loss: 0.14243, val_acc: 0.96000\n",
            "Epoch [9010/10000], loss: 0.13320 acc: 0.98667 val_loss: 0.14238, val_acc: 0.96000\n",
            "Epoch [9020/10000], loss: 0.13313 acc: 0.98667 val_loss: 0.14232, val_acc: 0.96000\n",
            "Epoch [9030/10000], loss: 0.13307 acc: 0.98667 val_loss: 0.14226, val_acc: 0.96000\n",
            "Epoch [9040/10000], loss: 0.13300 acc: 0.98667 val_loss: 0.14220, val_acc: 0.96000\n",
            "Epoch [9050/10000], loss: 0.13293 acc: 0.98667 val_loss: 0.14215, val_acc: 0.96000\n",
            "Epoch [9060/10000], loss: 0.13286 acc: 0.98667 val_loss: 0.14209, val_acc: 0.96000\n",
            "Epoch [9070/10000], loss: 0.13280 acc: 0.98667 val_loss: 0.14203, val_acc: 0.96000\n",
            "Epoch [9080/10000], loss: 0.13273 acc: 0.98667 val_loss: 0.14198, val_acc: 0.96000\n",
            "Epoch [9090/10000], loss: 0.13266 acc: 0.98667 val_loss: 0.14192, val_acc: 0.96000\n",
            "Epoch [9100/10000], loss: 0.13259 acc: 0.98667 val_loss: 0.14186, val_acc: 0.96000\n",
            "Epoch [9110/10000], loss: 0.13253 acc: 0.98667 val_loss: 0.14181, val_acc: 0.96000\n",
            "Epoch [9120/10000], loss: 0.13246 acc: 0.98667 val_loss: 0.14175, val_acc: 0.96000\n",
            "Epoch [9130/10000], loss: 0.13239 acc: 0.98667 val_loss: 0.14169, val_acc: 0.96000\n",
            "Epoch [9140/10000], loss: 0.13233 acc: 0.98667 val_loss: 0.14164, val_acc: 0.96000\n",
            "Epoch [9150/10000], loss: 0.13226 acc: 0.98667 val_loss: 0.14158, val_acc: 0.96000\n",
            "Epoch [9160/10000], loss: 0.13220 acc: 0.98667 val_loss: 0.14153, val_acc: 0.96000\n",
            "Epoch [9170/10000], loss: 0.13213 acc: 0.98667 val_loss: 0.14147, val_acc: 0.96000\n",
            "Epoch [9180/10000], loss: 0.13206 acc: 0.98667 val_loss: 0.14141, val_acc: 0.96000\n",
            "Epoch [9190/10000], loss: 0.13200 acc: 0.98667 val_loss: 0.14136, val_acc: 0.96000\n",
            "Epoch [9200/10000], loss: 0.13193 acc: 0.98667 val_loss: 0.14130, val_acc: 0.96000\n",
            "Epoch [9210/10000], loss: 0.13187 acc: 0.98667 val_loss: 0.14125, val_acc: 0.96000\n",
            "Epoch [9220/10000], loss: 0.13180 acc: 0.98667 val_loss: 0.14119, val_acc: 0.96000\n",
            "Epoch [9230/10000], loss: 0.13174 acc: 0.98667 val_loss: 0.14114, val_acc: 0.96000\n",
            "Epoch [9240/10000], loss: 0.13167 acc: 0.98667 val_loss: 0.14108, val_acc: 0.96000\n",
            "Epoch [9250/10000], loss: 0.13160 acc: 0.98667 val_loss: 0.14103, val_acc: 0.96000\n",
            "Epoch [9260/10000], loss: 0.13154 acc: 0.98667 val_loss: 0.14097, val_acc: 0.96000\n",
            "Epoch [9270/10000], loss: 0.13147 acc: 0.98667 val_loss: 0.14092, val_acc: 0.96000\n",
            "Epoch [9280/10000], loss: 0.13141 acc: 0.98667 val_loss: 0.14086, val_acc: 0.96000\n",
            "Epoch [9290/10000], loss: 0.13135 acc: 0.98667 val_loss: 0.14081, val_acc: 0.96000\n",
            "Epoch [9300/10000], loss: 0.13128 acc: 0.98667 val_loss: 0.14075, val_acc: 0.96000\n",
            "Epoch [9310/10000], loss: 0.13122 acc: 0.98667 val_loss: 0.14070, val_acc: 0.96000\n",
            "Epoch [9320/10000], loss: 0.13115 acc: 0.98667 val_loss: 0.14065, val_acc: 0.96000\n",
            "Epoch [9330/10000], loss: 0.13109 acc: 0.98667 val_loss: 0.14059, val_acc: 0.96000\n",
            "Epoch [9340/10000], loss: 0.13102 acc: 0.98667 val_loss: 0.14054, val_acc: 0.96000\n",
            "Epoch [9350/10000], loss: 0.13096 acc: 0.98667 val_loss: 0.14048, val_acc: 0.96000\n",
            "Epoch [9360/10000], loss: 0.13090 acc: 0.98667 val_loss: 0.14043, val_acc: 0.96000\n",
            "Epoch [9370/10000], loss: 0.13083 acc: 0.98667 val_loss: 0.14038, val_acc: 0.96000\n",
            "Epoch [9380/10000], loss: 0.13077 acc: 0.98667 val_loss: 0.14032, val_acc: 0.96000\n",
            "Epoch [9390/10000], loss: 0.13070 acc: 0.98667 val_loss: 0.14027, val_acc: 0.96000\n",
            "Epoch [9400/10000], loss: 0.13064 acc: 0.98667 val_loss: 0.14022, val_acc: 0.96000\n",
            "Epoch [9410/10000], loss: 0.13058 acc: 0.98667 val_loss: 0.14016, val_acc: 0.96000\n",
            "Epoch [9420/10000], loss: 0.13051 acc: 0.98667 val_loss: 0.14011, val_acc: 0.96000\n",
            "Epoch [9430/10000], loss: 0.13045 acc: 0.98667 val_loss: 0.14006, val_acc: 0.96000\n",
            "Epoch [9440/10000], loss: 0.13039 acc: 0.98667 val_loss: 0.14000, val_acc: 0.96000\n",
            "Epoch [9450/10000], loss: 0.13033 acc: 0.98667 val_loss: 0.13995, val_acc: 0.96000\n",
            "Epoch [9460/10000], loss: 0.13026 acc: 0.98667 val_loss: 0.13990, val_acc: 0.96000\n",
            "Epoch [9470/10000], loss: 0.13020 acc: 0.98667 val_loss: 0.13984, val_acc: 0.96000\n",
            "Epoch [9480/10000], loss: 0.13014 acc: 0.98667 val_loss: 0.13979, val_acc: 0.96000\n",
            "Epoch [9490/10000], loss: 0.13008 acc: 0.98667 val_loss: 0.13974, val_acc: 0.96000\n",
            "Epoch [9500/10000], loss: 0.13001 acc: 0.98667 val_loss: 0.13969, val_acc: 0.96000\n",
            "Epoch [9510/10000], loss: 0.12995 acc: 0.98667 val_loss: 0.13963, val_acc: 0.96000\n",
            "Epoch [9520/10000], loss: 0.12989 acc: 0.98667 val_loss: 0.13958, val_acc: 0.96000\n",
            "Epoch [9530/10000], loss: 0.12983 acc: 0.98667 val_loss: 0.13953, val_acc: 0.96000\n",
            "Epoch [9540/10000], loss: 0.12976 acc: 0.98667 val_loss: 0.13948, val_acc: 0.96000\n",
            "Epoch [9550/10000], loss: 0.12970 acc: 0.98667 val_loss: 0.13943, val_acc: 0.96000\n",
            "Epoch [9560/10000], loss: 0.12964 acc: 0.98667 val_loss: 0.13937, val_acc: 0.96000\n",
            "Epoch [9570/10000], loss: 0.12958 acc: 0.98667 val_loss: 0.13932, val_acc: 0.96000\n",
            "Epoch [9580/10000], loss: 0.12952 acc: 0.98667 val_loss: 0.13927, val_acc: 0.96000\n",
            "Epoch [9590/10000], loss: 0.12946 acc: 0.98667 val_loss: 0.13922, val_acc: 0.96000\n",
            "Epoch [9600/10000], loss: 0.12940 acc: 0.98667 val_loss: 0.13917, val_acc: 0.96000\n",
            "Epoch [9610/10000], loss: 0.12933 acc: 0.98667 val_loss: 0.13912, val_acc: 0.96000\n",
            "Epoch [9620/10000], loss: 0.12927 acc: 0.98667 val_loss: 0.13907, val_acc: 0.96000\n",
            "Epoch [9630/10000], loss: 0.12921 acc: 0.98667 val_loss: 0.13901, val_acc: 0.96000\n",
            "Epoch [9640/10000], loss: 0.12915 acc: 0.98667 val_loss: 0.13896, val_acc: 0.96000\n",
            "Epoch [9650/10000], loss: 0.12909 acc: 0.98667 val_loss: 0.13891, val_acc: 0.96000\n",
            "Epoch [9660/10000], loss: 0.12903 acc: 0.98667 val_loss: 0.13886, val_acc: 0.96000\n",
            "Epoch [9670/10000], loss: 0.12897 acc: 0.98667 val_loss: 0.13881, val_acc: 0.96000\n",
            "Epoch [9680/10000], loss: 0.12891 acc: 0.98667 val_loss: 0.13876, val_acc: 0.96000\n",
            "Epoch [9690/10000], loss: 0.12885 acc: 0.98667 val_loss: 0.13871, val_acc: 0.96000\n",
            "Epoch [9700/10000], loss: 0.12879 acc: 0.98667 val_loss: 0.13866, val_acc: 0.96000\n",
            "Epoch [9710/10000], loss: 0.12873 acc: 0.98667 val_loss: 0.13861, val_acc: 0.96000\n",
            "Epoch [9720/10000], loss: 0.12867 acc: 0.98667 val_loss: 0.13856, val_acc: 0.96000\n",
            "Epoch [9730/10000], loss: 0.12861 acc: 0.98667 val_loss: 0.13851, val_acc: 0.96000\n",
            "Epoch [9740/10000], loss: 0.12855 acc: 0.98667 val_loss: 0.13846, val_acc: 0.96000\n",
            "Epoch [9750/10000], loss: 0.12849 acc: 0.98667 val_loss: 0.13841, val_acc: 0.96000\n",
            "Epoch [9760/10000], loss: 0.12843 acc: 0.98667 val_loss: 0.13836, val_acc: 0.96000\n",
            "Epoch [9770/10000], loss: 0.12837 acc: 0.98667 val_loss: 0.13831, val_acc: 0.96000\n",
            "Epoch [9780/10000], loss: 0.12831 acc: 0.98667 val_loss: 0.13826, val_acc: 0.96000\n",
            "Epoch [9790/10000], loss: 0.12825 acc: 0.98667 val_loss: 0.13821, val_acc: 0.96000\n",
            "Epoch [9800/10000], loss: 0.12819 acc: 0.98667 val_loss: 0.13816, val_acc: 0.96000\n",
            "Epoch [9810/10000], loss: 0.12813 acc: 0.98667 val_loss: 0.13811, val_acc: 0.96000\n",
            "Epoch [9820/10000], loss: 0.12808 acc: 0.98667 val_loss: 0.13806, val_acc: 0.96000\n",
            "Epoch [9830/10000], loss: 0.12802 acc: 0.98667 val_loss: 0.13801, val_acc: 0.96000\n",
            "Epoch [9840/10000], loss: 0.12796 acc: 0.98667 val_loss: 0.13796, val_acc: 0.96000\n",
            "Epoch [9850/10000], loss: 0.12790 acc: 0.98667 val_loss: 0.13791, val_acc: 0.96000\n",
            "Epoch [9860/10000], loss: 0.12784 acc: 0.98667 val_loss: 0.13786, val_acc: 0.96000\n",
            "Epoch [9870/10000], loss: 0.12778 acc: 0.98667 val_loss: 0.13782, val_acc: 0.96000\n",
            "Epoch [9880/10000], loss: 0.12772 acc: 0.98667 val_loss: 0.13777, val_acc: 0.96000\n",
            "Epoch [9890/10000], loss: 0.12767 acc: 0.98667 val_loss: 0.13772, val_acc: 0.96000\n",
            "Epoch [9900/10000], loss: 0.12761 acc: 0.98667 val_loss: 0.13767, val_acc: 0.96000\n",
            "Epoch [9910/10000], loss: 0.12755 acc: 0.98667 val_loss: 0.13762, val_acc: 0.96000\n",
            "Epoch [9920/10000], loss: 0.12749 acc: 0.98667 val_loss: 0.13757, val_acc: 0.96000\n",
            "Epoch [9930/10000], loss: 0.12743 acc: 0.98667 val_loss: 0.13752, val_acc: 0.96000\n",
            "Epoch [9940/10000], loss: 0.12738 acc: 0.98667 val_loss: 0.13748, val_acc: 0.96000\n",
            "Epoch [9950/10000], loss: 0.12732 acc: 0.98667 val_loss: 0.13743, val_acc: 0.96000\n",
            "Epoch [9960/10000], loss: 0.12726 acc: 0.98667 val_loss: 0.13738, val_acc: 0.96000\n",
            "Epoch [9970/10000], loss: 0.12720 acc: 0.98667 val_loss: 0.13733, val_acc: 0.96000\n",
            "Epoch [9980/10000], loss: 0.12715 acc: 0.98667 val_loss: 0.13728, val_acc: 0.96000\n",
            "Epoch [9990/10000], loss: 0.12709 acc: 0.98667 val_loss: 0.13724, val_acc: 0.96000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 損失と精度の確認\n",
        "\n",
        "print(f'初期状態: 損失: {history[0,3]:.5f} 精度: {history[0,4]:.5f}' )\n",
        "print(f'最終状態: 損失: {history[-1,3]:.5f} 精度: {history[-1,4]:.5f}' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQK1E_aycb1v",
        "outputId": "70e0afcf-a76d-46fa-c557-3de29275ccf8"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "初期状態: 損失: 1.09158 精度: 0.26667\n",
            "最終状態: 損失: 0.13724 精度: 0.96000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習曲線の表示 (損失)\n",
        "\n",
        "plt.plot(history[:,0], history[:,1], 'b', label='訓練')\n",
        "plt.plot(history[:,0], history[:,3], 'k', label='検証')\n",
        "plt.xlabel('繰り返し回数')\n",
        "plt.ylabel('損失')\n",
        "plt.title('学習曲線(損失)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "8EA-T4TsceI1",
        "outputId": "44572561-a88b-4de9-863b-5f727d249cfc"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習曲線の表示 (精度)\n",
        "\n",
        "plt.plot(history[:,0], history[:,2], 'b', label='訓練')\n",
        "plt.plot(history[:,0], history[:,4], 'k', label='検証')\n",
        "plt.xlabel('繰り返し回数')\n",
        "plt.ylabel('精度')\n",
        "plt.title('学習曲線(精度)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "l5_jttCCcf52",
        "outputId": "e62c9723-70b6-43bd-9afb-eac1184494fd"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 入力変数の準備\n",
        "\n",
        "# 擬似的な出力データ\n",
        "outputs_np = np.array(range(1, 13)).reshape((4,3))\n",
        "# 擬似的な正解データ\n",
        "labels_np = np.array([0, 1, 2, 0])\n",
        "\n",
        "# Tensor化\n",
        "outputs_dummy = torch.tensor(outputs_np).float()\n",
        "labels_dummy = torch.tensor(labels_np).long()\n",
        "\n",
        "# 結果確認\n",
        "print(outputs_dummy.data)\n",
        "print(labels_dummy.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cHujZGXdEEP",
        "outputId": "725e00f2-4254-4411-cf9f-d9e704fde00c"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.,  2.,  3.],\n",
            "        [ 4.,  5.,  6.],\n",
            "        [ 7.,  8.,  9.],\n",
            "        [10., 11., 12.]])\n",
            "tensor([0, 1, 2, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NLLLoss関数の呼び出し\n",
        "\n",
        "nllloss = nn.NLLLoss()\n",
        "loss = nllloss(outputs_dummy, labels_dummy)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSwj7JxYdTc3",
        "outputId": "e57a1b4d-6099-4fef-d0d2-3534ba750c59"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-6.25\n"
          ]
        }
      ]
    }
  ]
}